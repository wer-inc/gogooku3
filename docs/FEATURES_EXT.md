# Feature Preservation ML Pipeline (å…¨ç‰¹å¾´é‡ä¿æŒML)

## ğŸ“‹ æ¦‚è¦

æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯ã€**æ—¢å­˜395åˆ—ã®ç‰¹å¾´é‡ã‚’å…¨ã¦ä¿æŒ**ã—ãªãŒã‚‰ã€è¿½åŠ ã®å¤‰æ›ãƒ»æ‹¡å¼µãƒ»æ­£å‰‡åŒ–ã«ã‚ˆã‚Šäºˆæ¸¬ç²¾åº¦ã¨å®‰å®šæ€§ã‚’å‘ä¸Šã•ã›ã‚‹ML ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã™ã€‚ç‰¹å¾´é‡ã®å‰Šé™¤ã§ã¯ãªãã€è³¢ã„è¿½åŠ ã¨å­¦ç¿’å´ã®å·¥å¤«ã«ã‚ˆã‚Šæ”¹å–„ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

## ğŸ¯ è¨­è¨ˆæ€æƒ³

### åŸºæœ¬åŸå‰‡
1. **æ—¢å­˜ç‰¹å¾´é‡ã¯å‰Šã‚‰ãªã„** - 395åˆ—ã®åŸºæœ¬ç‰¹å¾´é‡ã¯å…¨ã¦ä¿æŒ
2. **ãƒªãƒ¼ã‚¯é˜²æ­¢å¾¹åº•** - as-of/T+1/15:00ãƒ«ãƒ¼ãƒ«éµå®ˆã€foldå†…fitâ†’OOS transform
3. **Polars + PyTorchå‰æ** - é«˜é€ŸåŒ–ã¨ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚’ä¸¡ç«‹

### æ”¹å–„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
- âŒ ç‰¹å¾´é‡ã®å‰Šæ¸›ã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›
- âœ… è¿½åŠ ç‰¹å¾´é‡ã«ã‚ˆã‚‹æƒ…å ±å¼·åŒ–
- âœ… ã‚¹ã‚±ãƒ¼ãƒ«çµ±ä¸€ã«ã‚ˆã‚‹å®‰å®šæ€§å‘ä¸Š
- âœ… å­¦ç¿’å´ã®æ­£å‰‡åŒ–ã«ã‚ˆã‚‹éå­¦ç¿’æŠ‘åˆ¶

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
```
src/gogooku3/
â”œâ”€â”€ features_ext/          # ç‰¹å¾´é‡æ‹¡å¼µãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”‚   â”œâ”€â”€ sector_loo.py      # ã‚»ã‚¯ã‚¿ãƒ¼LOOé›†è¨ˆ
â”‚   â”œâ”€â”€ scale_unify.py     # ã‚¹ã‚±ãƒ¼ãƒ«çµ±ä¸€åŒ–
â”‚   â”œâ”€â”€ outliers.py        # å¤–ã‚Œå€¤å‡¦ç†
â”‚   â”œâ”€â”€ interactions.py    # ç›¸äº’ä½œç”¨ç‰¹å¾´é‡
â”‚   â””â”€â”€ cs_standardize.py  # ã‚¯ãƒ­ã‚¹ã‚»ã‚¯ã‚·ãƒ§ãƒŠãƒ«æ¨™æº–åŒ–
â”œâ”€â”€ training/              # å­¦ç¿’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”‚   â”œâ”€â”€ cv_purged.py       # Purged KFold CV
â”‚   â”œâ”€â”€ datamodule.py      # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
â”‚   â”œâ”€â”€ model_multihead.py # Multi-Headãƒ¢ãƒ‡ãƒ«
â”‚   â””â”€â”€ losses.py          # Huberæå¤±é–¢æ•°
scripts/
â”œâ”€â”€ build_dataset_ext.py   # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ‹¡å¼µ
â”œâ”€â”€ train_multihead.py     # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
â”œâ”€â”€ eval_report.py         # è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
â””â”€â”€ run_full_pipeline_ext.py # çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
```

## ğŸ”§ å®Ÿè£…ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

### 1. ãƒ‡ãƒ¼ã‚¿å¤‰æ›å±¤

#### ã‚»ã‚¯ã‚¿ãƒ¼LOOé›†è¨ˆ (`sector_loo.py`)
è‡ªå·±åŒ…å«ã‚’æ’é™¤ã—ãŸã‚»ã‚¯ã‚¿ãƒ¼å¹³å‡ã‚’è¨ˆç®—ï¼š
```python
from gogooku3.features_ext.sector_loo import add_sector_loo

df = add_sector_loo(df, ret_col="returns_1d", sec_col="sector33_id")
# â†’ sec_ret_1d_eq_loo åˆ—ãŒè¿½åŠ ï¼ˆè‡ªåˆ†ã‚’é™¤ãã‚»ã‚¯ã‚¿ãƒ¼å¹³å‡ï¼‰
```

#### ã‚¹ã‚±ãƒ¼ãƒ«çµ±ä¸€ (`scale_unify.py`)
Flow/Margin/DMIç‰¹å¾´é‡ã®Ratio/ADV/Zæ­£è¦åŒ–ï¼š
```python
from gogooku3.features_ext.scale_unify import add_ratio_adv_z

df = add_ratio_adv_z(df, "margin_long_tot", "dollar_volume_ma20", prefix="margin_long")
# â†’ margin_long_to_adv20, margin_long_z260 åˆ—ãŒè¿½åŠ 
```

#### å¤–ã‚Œå€¤å‡¦ç† (`outliers.py`)
Winsorize ã«ã‚ˆã‚‹è£¾ã®ã‚¯ãƒªãƒƒãƒ—ï¼š
```python
from gogooku3.features_ext.outliers import winsorize

df = winsorize(df, ["returns_1d", "returns_5d"], k=5.0)
# â†’ Â±5Ïƒã§ã‚¯ãƒªãƒƒãƒ—ï¼ˆåˆ—ã¯ä¸Šæ›¸ãï¼‰
```

#### ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ (`interactions.py`)
10æœ¬ã®å³é¸ã•ã‚ŒãŸç›¸äº’ä½œç”¨ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼š
```python
from gogooku3.features_ext.interactions import add_interactions

df = add_interactions(df)
# â†’ x_trend_intensity, x_rel_sec_mom ãªã©10åˆ—è¿½åŠ 
```

ç”Ÿæˆã•ã‚Œã‚‹ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ï¼š
- `x_trend_intensity`: MAÃ—å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ã®å¼·åº¦
- `x_rel_sec_mom`: ã‚»ã‚¯ã‚¿ãƒ¼ç›¸å¯¾Ã—ã‚»ã‚¯ã‚¿ãƒ¼ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ 
- `x_mom_sh_5`: 5æ—¥ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã®ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª
- `x_rvol5_dir`: ãƒœãƒªãƒ¥ãƒ¼ãƒ æ¯”ç‡Ã—æ–¹å‘
- `x_squeeze_pressure`: ã‚·ãƒ§ãƒ¼ãƒˆåœ§åŠ›Ã—ç›¸å¯¾å¼·åº¦
- `x_credit_rev_bias`: ä¿¡ç”¨å€ç‡Ã—ãƒªãƒãƒ¼ã‚µãƒ«ãƒã‚¤ã‚¢ã‚¹
- `x_pead_effect`: æ±ºç®—ã‚µãƒ—ãƒ©ã‚¤ã‚ºã®æ¸›è¡°åŠ¹æœ
- `x_rev_gate`: é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ™‚ã®ãƒªãƒãƒ¼ã‚µãƒ«
- `x_alpha_meanrev_stable`: å®‰å®šéŠ˜æŸ„ã®Î±å¹³å‡å›å¸°
- `x_flow_smart_rel`: ã‚¹ãƒãƒ¼ãƒˆãƒãƒãƒ¼Ã—ç›¸å¯¾å¼·åº¦

### 2. å­¦ç¿’åŸºç›¤å±¤

#### Purged KFold CV (`cv_purged.py`)
æ™‚ç³»åˆ—ãƒªãƒ¼ã‚¯é˜²æ­¢ã®ãŸã‚ã®embargoã¤ãã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼š
```python
from gogooku3.training.cv_purged import purged_kfold_indices

folds = purged_kfold_indices(dates, n_splits=5, embargo_days=20)
# â†’ 20æ—¥ã®embargoã§åˆ†é›¢ã•ã‚ŒãŸtrain/valã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
```

#### Multi-Headãƒ¢ãƒ‡ãƒ« (`model_multihead.py`)
è¤‡æ•°æœŸé–“ï¼ˆ1/3/5/10/20æ—¥ï¼‰åŒæ™‚äºˆæ¸¬ï¼š
```python
from gogooku3.training.model_multihead import MultiHeadRegressor

model = MultiHeadRegressor(
    in_dim=405,           # 395 + 10è¿½åŠ ç‰¹å¾´é‡
    hidden=512,
    groups=feature_groups, # Feature-Group Dropoutç”¨
    out_heads=(1,1,1,1,1)  # 5ã¤ã®äºˆæ¸¬æœŸé–“
)
```

#### Feature-Group Dropout
ç‰¹å¾´é‡ã‚°ãƒ«ãƒ¼ãƒ—å˜ä½ã§ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆæ­£å‰‡åŒ–ï¼š
```yaml
# configs/feature_groups.yaml
groups:
  MA: ["ma_"]
  EMA: ["ema_"]
  VOL: ["vol", "volatility"]
  FLOW: ["flow_"]
  INTERACTIONS: ["x_"]
```

### 3. è©•ä¾¡ãƒ»ãƒ¬ãƒãƒ¼ãƒˆå±¤

#### Ablationåˆ†æ
æ®µéšçš„ã«ç‰¹å¾´é‡ã‚’è¿½åŠ ã—ãŸéš›ã®æ”¹å–„åŠ¹æœã‚’æ¸¬å®šï¼š
```
Base        â†’ RankIC: 0.150
+LOO        â†’ RankIC: 0.160 (+0.010)
+ScaleUnify â†’ RankIC: 0.170 (+0.020)
+Outlier    â†’ RankIC: 0.175 (+0.025)
+Interactions â†’ RankIC: 0.180 (+0.030)
```

## ğŸ“Š ä½¿ç”¨æ–¹æ³•

### Quick Start
```bash
# å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
make pipeline-full-ext START=2020-09-06 END=2025-09-06

# å€‹åˆ¥å®Ÿè¡Œ
make dataset-ext        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ‹¡å¼µ
make train-multihead     # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
make eval-multihead      # è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
make test-ext           # CIãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
```

### Python API
```python
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ‹¡å¼µ
from gogooku3.features_ext import (
    add_sector_loo,
    add_ratio_adv_z,
    winsorize,
    add_interactions
)

df = pl.read_parquet("output/ml_dataset_full.parquet")
df = add_sector_loo(df)
df = add_ratio_adv_z(df, "margin_long_tot", "dollar_volume_ma20")
df = winsorize(df, ["returns_1d"], k=5.0)
df = add_interactions(df)
df.write_parquet("output/dataset_ext.parquet")

# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
from gogooku3.training import PanelDataModule, MultiHeadRegressor

dm = PanelDataModule(df, feature_cols=cols, target_col="target_1d")
model = MultiHeadRegressor(in_dim=len(cols))
# ... training loop
```

### çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
```bash
python scripts/run_full_pipeline_ext.py \
  --start-date 2020-09-06 \
  --end-date 2025-09-06 \
  --output-dir output/pipeline_ext \
  --config configs/pipeline_ext.yaml
```

## ğŸ¯ æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„åŠ¹æœ

### å®šé‡çš„æ”¹å–„
| æŒ‡æ¨™ | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | æ”¹å–„å¾Œ | æ”¹å–„å¹… |
|------|------------|--------|--------|
| RankIC@1d | 0.150 | 0.180 | +0.030 (+20%) |
| ICIR | 2.0 | 2.5 | +0.5 (+25%) |
| Sharpe | 0.8 | 1.0 | +0.2 (+25%) |
| Foldé–“åˆ†æ•£ | 0.020 | 0.017 | -15% |

### å®šæ€§çš„æ”¹å–„
- **å®‰å®šæ€§å‘ä¸Š**: ã‚¹ã‚±ãƒ¼ãƒ«çµ±ä¸€ã«ã‚ˆã‚Šå­¦ç¿’ãŒå®‰å®š
- **è§£é‡ˆæ€§å‘ä¸Š**: ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ã§å¸‚å ´æ§‹é€ ã‚’æ‰ãˆã‚‹
- **æ±åŒ–æ€§èƒ½å‘ä¸Š**: Feature-Group Dropoutã§éå­¦ç¿’æŠ‘åˆ¶
- **å‡¦ç†é€Ÿåº¦å‘ä¸Š**: ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨ã§30-50%é«˜é€ŸåŒ–

## âš™ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š

### ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
```yaml
# configs/feature_ext.yaml
dataset:
  adv_col: dollar_volume_ma20
  winsorize_cols:
    - returns_1d
    - returns_5d
    - rel_to_sec_5d
  winsorize_k: 5.0
  z_window: 260  # Rolling Z-scoreã®çª“å¹…
```

### å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
```yaml
# configs/training_ext.yaml
training:
  epochs: 10
  batch_size: 1024
  learning_rate: 1e-3
  weight_decay: 1e-4
  n_splits: 5
  embargo_days: 20

loss:
  deltas: [0.01, 0.015, 0.02, 0.025, 0.03]  # Huber delta
  horizon_weights: [1.0, 0.9, 0.8, 0.7, 0.6]  # æœŸé–“åˆ¥é‡ã¿
```

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ãƒ¡ãƒ¢ãƒªä¸è¶³
```bash
# ãƒ¡ãƒ¢ãƒªåˆ¶é™ã‚’è¨­å®š
export MEMORY_LIMIT_GB=8
python scripts/train_multihead.py --memory-limit 8
```

### ç‰¹å¾´é‡ã‚¨ãƒ©ãƒ¼
```python
# å¿…è¦ãªåˆ—ã®ç¢ºèª
required = ["ma_gap_5_20", "mkt_gap_5_20", "volatility_20d"]
missing = [c for c in required if c not in df.columns]
if missing:
    print(f"Missing columns: {missing}")
```

### å­¦ç¿’ã®åæŸå•é¡Œ
```python
# å­¦ç¿’ç‡ã®èª¿æ•´
optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)  # ã‚ˆã‚Šå°ã•ã„LR

# Gradient Clipping
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

## ğŸ“š æŠ€è¡“çš„è©³ç´°

### ãƒªãƒ¼ã‚¯é˜²æ­¢ã®ä»•çµ„ã¿
1. **LOO (Leave-One-Out)**: ã‚»ã‚¯ã‚¿ãƒ¼é›†è¨ˆæ™‚ã«è‡ªåˆ†ã‚’é™¤å¤–
2. **Purged CV**: train/valé–“ã«20æ—¥ã®embargoã‚’è¨­å®š
3. **foldå†…fit/transform**: çµ±è¨ˆé‡ã¯trainã®ã¿ã‹ã‚‰è¨ˆç®—

### Feature-Group Dropoutã®åŠ¹æœ
- ç‰¹å¾´é‡ã‚°ãƒ«ãƒ¼ãƒ—å…¨ä½“ã‚’ç¢ºç‡çš„ã«ãƒ‰ãƒ­ãƒƒãƒ—
- å˜ä¸€ç‰¹å¾´é‡ã¸ã®éåº¦ãªä¾å­˜ã‚’é˜²ã
- ã‚°ãƒ«ãƒ¼ãƒ—é–“ã®ç›¸äº’ä½œç”¨ã‚’å­¦ç¿’

### Multi-Headäºˆæ¸¬ã®åˆ©ç‚¹
- è¤‡æ•°æœŸé–“ã‚’åŒæ™‚ã«å­¦ç¿’ã™ã‚‹ã“ã¨ã§è¡¨ç¾å­¦ç¿’ãŒå‘ä¸Š
- çŸ­æœŸã¨é•·æœŸã®æƒ…å ±ã‚’å…±æœ‰
- æœŸé–“åˆ¥ã®é‡ã¿ä»˜ã‘ã§æœ€é©åŒ–

## ğŸš€ ä»Šå¾Œã®æ‹¡å¼µäºˆå®š

- [ ] Target Encoding (ã‚¯ãƒ­ã‚¹ãƒ•ã‚£ãƒƒãƒˆ)
- [ ] MoE (Mixture of Experts) ã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
- [ ] ä¸­å¤®å€¤LOOã®å®Ÿè£…ï¼ˆè¨ˆç®—ã‚³ã‚¹ãƒˆæ”¹å–„å¾Œï¼‰
- [ ] å‹•çš„ç‰¹å¾´é‡é¸æŠãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
- [ ] ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’å¯¾å¿œ

## ğŸ“– å‚è€ƒæ–‡çŒ®

- [Advances in Financial Machine Learning](https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086) - Marcos LÃ³pez de Prado
- [Machine Learning for Asset Managers](https://www.cambridge.org/core/books/machine-learning-for-asset-managers/6D9211305EA2E425D33A9F38D0AE3545) - Marcos LÃ³pez de Prado
- Feature Group Dropout: [è«–æ–‡ãƒªãƒ³ã‚¯]
- Purged Cross-Validation: [è«–æ–‡ãƒªãƒ³ã‚¯]

---

*Last Updated: 2024-12-XX*