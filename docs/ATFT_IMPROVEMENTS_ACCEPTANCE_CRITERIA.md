# ATFT-GAT-FAN Improvements 受け入れ基準

## 概要
ATFT-GAT-FANモデルの改善実装を受け入れるための基準と評価手順を定義します。

## 主要評価指標

### 1. 短期予測精度向上
- **RankIC@1d**: Spearman相関係数 ≥ **+0.01** 以上改善
- **Q5-Q1スプレッド**: 上位/下位5%の平均リターン差 ≥ **+5%** 以上改善

### 2. 予測安定性
- **Pred.std / Target.std 比**: **0.6-1.2** の範囲内
- **勾配ノルム**: **≤ 5.0** で安定
- **損失関数**: NaN/Infが発生しない

### 3. 計算効率
- **1ステップ時間**: **10%** 以上改善
- **Peakメモリ使用量**: **10%** 以上削減
- **OOM発生率**: **0%**（既存データでの学習が可能）

## 詳細な受け入れ基準

### 必須基準（全て満たすこと）
| 項目 | 基準 | 重要度 |
|------|------|--------|
| RankIC@1d | ≥ +0.01 改善 | 高 |
| Pred.std比 | 0.6-1.2 範囲内 | 高 |
| 学習安定性 | 勾配NaN/Infなし | 高 |
| OOM対策 | 既存バッチサイズで学習可能 | 高 |
| 再現性 | seed固定で結果一致 | 中 |

### 推奨基準（可能な限り達成）
| 項目 | 基準 | 重要度 |
|------|------|--------|
| Q5-Q1スプレッド | ≥ +5% 改善 | 中 |
| ステップ時間 | ≥ 10% 改善 | 中 |
| メモリ使用量 | ≥ 10% 削減 | 中 |
| 多ホライズン | h1,h5,h10全て改善 | 中 |

## 評価手順

### Phase 1: スモークテスト（15分）
```bash
# 最小データで1エポック学習
python scripts/smoke_test.py

# 確認項目
- [ ] モデル初期化成功
- [ ] フォワードパス成功
- [ ] 損失計算正常
- [ ] トレーニングステップ成功
- [ ] OOMなし
- [ ] 勾配NaN/Infなし
```

### Phase 2: 性能比較テスト（2-3時間）
```bash
# 改善前後比較
python scripts/validate_improvements.py --data path/to/data.parquet

# 評価項目
- [ ] RankIC@1d ≥ +0.01
- [ ] Pred.std比 ∈ [0.6, 1.2]
- [ ] 学習時間変化
- [ ] メモリ使用量変化
- [ ] 学習曲線の安定性
```

### Phase 3: 本番データテスト（4-6時間）
```bash
# 本番規模データでの評価
python src/training/integrated_trainer.py

# 確認項目
- [ ] フルデータでの学習完了
- [ ] 検証指標の向上
- [ ] メモリ使用量の安定
- [ ] ログ出力の正常性
```

## ロールバック基準

### 即時ロールバック（検証フェーズで確認）
- **OOM発生**: 既存のバッチサイズで学習不可
- **学習不安定**: 損失がNaN/Inf化
- **性能劣化**: RankIC@1d が -0.02 以上悪化
- **計算効率劣化**: ステップ時間が 20% 以上増加

### 条件付きロールバック（本番フェーズで確認）
- **短期予測精度**: RankIC@1d が +0.005 未満の改善
- **メモリ効率**: メモリ使用量が 5% 未満の削減
- **安定性**: 学習中に不安定な挙動（振動、発散）

## 改善の優先順位

### 高優先度（必須実装）
1. **Huber多ホライズン損失** - 短期重視重み付け
2. **出力ヘッドsmall-init + LayerScale** - 初期化改善
3. **EMA Teacher** - 学習安定化
4. **ParamGroup最適化** - 効率的な学習

### 中優先度（推奨実装）
1. **GAT温度τ + EdgeDropout** - 注意機構改善
2. **FreqDropout** - 周波数適応正則化
3. **PyArrowストリーミング** - データ効率化
4. **W&B + TensorBoard** - 監視強化

### 低優先度（オプション）
1. **torch.compile** - 計算最適化
2. **RobustExecutor** - エラーハンドリング
3. **設定統一** - 保守性向上

## リスク評価

### 高リスク項目
- **torch.compile**: 互換性問題の可能性
- **EMA**: メモリ使用量増加
- **FreqDropout**: 収束速度低下の可能性

### 中リスク項目
- **GAT温度**: アテンション品質への影響
- **ParamGroup**: 学習ダイナミクスの変化
- **オンライン正規化**: データ分布変化への影響

### 低リスク項目
- **LayerScale**: 既存アーキテクチャと互換
- **EdgeDropout**: ドロップアウト手法の拡張
- **監視強化**: 既存機能への追加

## 移行戦略

### Phase 1: 機能フラグ導入（1-2日）
- 全ての改善機能をfeature flagで制御
- デフォルトOFFで後方互換確保
- 個別機能のON/OFFテスト

### Phase 2: 段階的有効化（1週間）
- 高優先度機能から順次有効化
- 各段階で性能検証
- 問題発生時の迅速な無効化

### Phase 3: 本番移行（2-3日）
- 全機能有効化
- 包括的な性能テスト
- モニタリング体制の確立

## 監視項目

### 学習時監視
- 損失関数の収束挙動
- 勾配ノルムの安定性
- 各レイヤーのアクティベーション分布
- メモリ使用量の推移

### 推論時監視
- 予測値の分布特性
- RankICの時系列安定性
- Q5-Q1スプレッドの維持
- レイテンシの安定性

## 最終判定基準

### 合格条件（3つ以上満たす）
1. **性能向上**: RankIC@1d ≥ +0.01
2. **安定性確保**: Pred.std比 ∈ [0.6, 1.2]
3. **効率改善**: メモリ使用量 ≥ 10% 削減
4. **堅牢性向上**: OOM発生なし

### 不合格条件（1つでも該当）
1. **性能劣化**: RankIC@1d ≤ -0.01
2. **不安定化**: 学習発散またはNaN発生
3. **効率劣化**: メモリ使用量 20% 以上増加
4. **互換性破壊**: 既存API/インターフェース変更

---

*最終更新: 2024年*
