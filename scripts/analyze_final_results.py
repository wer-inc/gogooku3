#!/usr/bin/env python3
"""
æœ€çµ‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã®è©³ç´°åˆ†æ
"""

import logging
from datetime import datetime

import matplotlib.pyplot as plt
import pandas as pd

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def load_training_metrics(log_path: str = "logs/ml_training.log"):
    """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ­ã‚°ã‹ã‚‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æŠ½å‡º"""
    metrics = {
        "epochs": [],
        "train_loss": [],
        "val_loss": [],
        "train_sharpe": [],
        "val_sharpe": [],
        "train_ic": [],
        "val_ic": [],
        "train_rankic": [],
        "val_rankic": [],
        "lr": [],
    }

    with open(log_path) as f:
        lines = f.readlines()

    for line in lines:
        if "Epoch" in line and "Train Loss" in line:
            try:
                # Extract epoch info
                parts = line.split()
                epoch_info = [p for p in parts if "/" in p and p[0].isdigit()][0]
                epoch = int(epoch_info.split("/")[0])

                # Extract losses
                train_loss = float(line.split("Train Loss=")[1].split(",")[0])
                val_loss = float(line.split("Val Loss=")[1].split(",")[0])
                lr = float(line.split("LR=")[1].strip())

                metrics["epochs"].append(epoch)
                metrics["train_loss"].append(train_loss)
                metrics["val_loss"].append(val_loss)
                metrics["lr"].append(lr)
            except:
                continue

        elif "Train Metrics" in line:
            try:
                sharpe = float(line.split("Sharpe:")[1].split(",")[0])
                ic = float(line.split("IC:")[1].split(",")[0])
                rankic = float(line.split("RankIC:")[1].strip())

                metrics["train_sharpe"].append(sharpe)
                metrics["train_ic"].append(ic)
                metrics["train_rankic"].append(rankic)
            except:
                continue

        elif "Val Metrics" in line:
            try:
                sharpe = float(line.split("Sharpe:")[1].split(",")[0])
                ic = float(line.split("IC:")[1].split(",")[0])
                rankic = float(line.split("RankIC:")[1].strip())

                metrics["val_sharpe"].append(sharpe)
                metrics["val_ic"].append(ic)
                metrics["val_rankic"].append(rankic)
            except:
                continue

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
    df = pd.DataFrame(metrics)
    return df


def analyze_improvement_trajectory(df: pd.DataFrame):
    """æ”¹å–„ã®è»Œè·¡ã‚’åˆ†æ"""
    logger.info("=== æ”¹å–„ã®è»Œè·¡åˆ†æ ===")

    # æœ€åˆã¨æœ€å¾Œã®æ¯”è¼ƒ
    if len(df) > 0:
        first_val_sharpe = df["val_sharpe"].iloc[0]
        last_val_sharpe = df["val_sharpe"].iloc[-1]
        best_val_sharpe = df["val_sharpe"].max()

        logger.info(f"åˆå›Val Sharpe: {first_val_sharpe:.4f}")
        logger.info(f"æœ€çµ‚Val Sharpe: {last_val_sharpe:.4f}")
        logger.info(f"æœ€é«˜Val Sharpe: {best_val_sharpe:.4f}")
        logger.info(
            f"æ”¹å–„ç‡: {(last_val_sharpe - first_val_sharpe) / abs(first_val_sharpe) * 100:.1f}%"
        )

        # ICã®æ”¹å–„
        first_val_ic = df["val_ic"].iloc[0]
        last_val_ic = df["val_ic"].iloc[-1]
        logger.info(f"\nVal ICæ”¹å–„: {first_val_ic:.4f} â†’ {last_val_ic:.4f}")

        # éå­¦ç¿’ã®ç¢ºèª
        train_sharpe_trend = df["train_sharpe"].iloc[-10:].mean()
        val_sharpe_trend = df["val_sharpe"].iloc[-10:].mean()
        logger.info("\néå­¦ç¿’ãƒã‚§ãƒƒã‚¯:")
        logger.info(
            f"æœ€è¿‘10ã‚¨ãƒãƒƒã‚¯ã®å¹³å‡ - Train: {train_sharpe_trend:.4f}, Val: {val_sharpe_trend:.4f}"
        )

        if train_sharpe_trend > val_sharpe_trend * 2:
            logger.warning("è­¦å‘Š: éå­¦ç¿’ã®å…†å€™ãŒã‚ã‚Šã¾ã™")


def plot_training_curves(
    df: pd.DataFrame, save_path: str = "output/training_curves.png"
):
    """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ›²ç·šã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # Loss curves
    axes[0, 0].plot(df["epochs"], df["train_loss"], label="Train Loss")
    axes[0, 0].plot(df["epochs"], df["val_loss"], label="Val Loss")
    axes[0, 0].set_xlabel("Epoch")
    axes[0, 0].set_ylabel("Loss")
    axes[0, 0].set_title("Loss Curves")
    axes[0, 0].legend()
    axes[0, 0].grid(True)

    # Sharpe curves
    axes[0, 1].plot(df["epochs"], df["val_sharpe"], label="Val Sharpe", color="green")
    axes[0, 1].axhline(y=0.849, color="red", linestyle="--", label="Target (0.849)")
    axes[0, 1].set_xlabel("Epoch")
    axes[0, 1].set_ylabel("Sharpe Ratio")
    axes[0, 1].set_title("Validation Sharpe Ratio")
    axes[0, 1].legend()
    axes[0, 1].grid(True)

    # IC curves
    axes[1, 0].plot(df["epochs"], df["train_ic"], label="Train IC")
    axes[1, 0].plot(df["epochs"], df["val_ic"], label="Val IC")
    axes[1, 0].set_xlabel("Epoch")
    axes[1, 0].set_ylabel("IC")
    axes[1, 0].set_title("Information Coefficient")
    axes[1, 0].legend()
    axes[1, 0].grid(True)

    # Learning rate
    axes[1, 1].plot(df["epochs"], df["lr"], label="Learning Rate", color="orange")
    axes[1, 1].set_xlabel("Epoch")
    axes[1, 1].set_ylabel("Learning Rate")
    axes[1, 1].set_title("Learning Rate Schedule")
    axes[1, 1].set_yscale("log")
    axes[1, 1].grid(True)

    plt.tight_layout()
    plt.savefig(save_path)
    logger.info(f"Training curves saved to {save_path}")


def generate_recommendations(df: pd.DataFrame):
    """æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
    logger.info("\n=== æ¨å¥¨äº‹é … ===")

    recommendations = []

    # Sharpeæ¯”ã®çŠ¶æ³ã«åŸºã¥ãæ¨å¥¨
    if len(df) > 0:
        last_val_sharpe = df["val_sharpe"].iloc[-1]

        if last_val_sharpe > 0.5:
            recommendations.append(
                "âœ… Sharpeæ¯”ãŒè‰¯å¥½ã§ã™ã€‚ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
            )
        elif last_val_sharpe > 0.2:
            recommendations.append(
                "ğŸ“ˆ Sharpeæ¯”ãŒæ”¹å–„ã—ã¦ã„ã¾ã™ã€‚ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¾®èª¿æ•´ã‚’æ¨å¥¨ã€‚"
            )
        elif last_val_sharpe > 0:
            recommendations.append(
                "ğŸ”„ Sharpeæ¯”ãŒãƒ—ãƒ©ã‚¹ã§ã™ã€‚ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ã‚’é©ç”¨ã—ã¦ãã ã•ã„ã€‚"
            )
        else:
            recommendations.append(
                "âš ï¸ Sharpeæ¯”ãŒã¾ã ãƒã‚¤ãƒŠã‚¹ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿å“è³ªã®å†ç¢ºèªãŒå¿…è¦ã€‚"
            )

        # éå­¦ç¿’ãƒã‚§ãƒƒã‚¯
        if len(df) > 20:
            train_loss_trend = df["train_loss"].iloc[-10:].diff().mean()
            val_loss_trend = df["val_loss"].iloc[-10:].diff().mean()

            if train_loss_trend < 0 and val_loss_trend > 0:
                recommendations.append("âš ï¸ éå­¦ç¿’ã®å…†å€™ã€‚æ­£å‰‡åŒ–ã‚’å¼·åŒ–ã—ã¦ãã ã•ã„ã€‚")

        # IC/RankICãƒã‚§ãƒƒã‚¯
        last_val_ic = df["val_ic"].iloc[-1]
        if abs(last_val_ic) < 0.01:
            recommendations.append(
                "ğŸ“Š ICãŒä½ã™ãã¾ã™ã€‚ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®è¦‹ç›´ã—ã‚’ã€‚"
            )

    # ç›®æ¨™é”æˆã¾ã§ã®é“ç­‹
    target_sharpe = 0.849
    if last_val_sharpe > 0:
        gap = target_sharpe - last_val_sharpe
        improvement_needed = gap / last_val_sharpe * 100
        recommendations.append(
            f"ğŸ¯ ç›®æ¨™é”æˆã¾ã§: ã‚ã¨{improvement_needed:.0f}%ã®æ”¹å–„ãŒå¿…è¦"
        )

    for i, rec in enumerate(recommendations, 1):
        logger.info(f"{i}. {rec}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    logger.info("=== æœ€çµ‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµæœåˆ†æ ===")
    logger.info(f"åˆ†æé–‹å§‹: {datetime.now()}")

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿
    try:
        df = load_training_metrics()
        logger.info(f"èª­ã¿è¾¼ã‚“ã ã‚¨ãƒãƒƒã‚¯æ•°: {len(df)}")

        if len(df) > 0:
            # æ”¹å–„ã®è»Œè·¡ã‚’åˆ†æ
            analyze_improvement_trajectory(df)

            # ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
            plot_training_curves(df)

            # æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
            generate_recommendations(df)

            # çµæœã‚’CSVã«ä¿å­˜
            output_path = f"output/training_metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            df.to_csv(output_path, index=False)
            logger.info(f"\nãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¿å­˜: {output_path}")

        else:
            logger.warning("ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    except Exception as e:
        logger.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


if __name__ == "__main__":
    main()
