# ğŸš¨ gogooku3-standalone Operations Runbook

## Overview

This runbook provides operational procedures for maintaining, troubleshooting, and scaling the gogooku3-standalone application. It covers common issues, preventive maintenance, and emergency procedures.

## ğŸ“‹ Table of Contents

1. [Quick Reference](#quick-reference)
2. [Health Checks](#health-checks)
3. [Common Issues & Solutions](#common-issues--solutions)
4. [Maintenance Procedures](#maintenance-procedures)
5. [Emergency Procedures](#emergency-procedures)
6. [Scaling Procedures](#scaling-procedures)
7. [Backup & Recovery](#backup--recovery)
8. [Monitoring & Alerts](#monitoring--alerts)

## ğŸ” Quick Reference

### Service Status Check
```bash
# Overall health check
python ops/health_check.py health

# Readiness check
python ops/health_check.py ready

# Liveness check
python ops/health_check.py live

# Metrics endpoint
python ops/metrics_exporter.py --once
```

### Log Locations
- Main logs: `logs/main.log`
- ML training logs: `logs/ml_training.log`
- Safe training logs: `logs/safe_training.log`
- Docker logs: `docker logs gogooku3-minio`

### Configuration Files
- Main config: `pyproject.toml`
- Docker: `docker-compose.yml` / `docker-compose.override.yml`
- Environment: `.env` (create from `.env.example`)

## ğŸ¥ Health Checks

### Automated Health Checks

1. **System Health Check**
   ```bash
   python ops/health_check.py health --format json
   ```

2. **Readiness Check** (for load balancers)
   ```bash
   python ops/health_check.py ready
   ```

3. **Liveness Check** (for orchestrators)
   ```bash
   python ops/health_check.py live
   ```

### Manual Health Verification

1. **Database Connectivity**
   ```bash
   # Check ClickHouse
   docker exec gogooku3-clickhouse clickhouse-client --query "SELECT 1"

   # Check Redis
   docker exec gogooku3-redis redis-cli ping
   ```

2. **Storage Connectivity**
   ```bash
   # Check MinIO
   docker exec gogooku3-minio mc ls gogooku
   ```

3. **Dependencies**
   ```bash
   python -c "import polars, torch, pandas; print('Dependencies OK')"
   ```

## ğŸ”§ Common Issues & Solutions

### Issue 1: Memory Exhaustion

**Symptoms:**
- Application becomes unresponsive
- High memory usage alerts
- Out of memory errors in logs

**Solutions:**

1. **Immediate Actions:**
   ```bash
   # Check memory usage
   python ops/health_check.py health | grep memory

   # Restart application
   docker compose restart
   ```

2. **Root Cause Analysis:**
   ```bash
   # Check process memory
   ps aux --sort=-%mem | head -10

   # Analyze logs for memory leaks
   tail -f logs/main.log | grep -i memory
   ```

3. **Preventive Measures:**
   - Increase memory limits in docker-compose.yml
   - Enable memory profiling: `PERF_MEMORY_PROFILE=1`
   - Implement memory limits: `docker run --memory=16g`

### Issue 2: Training Pipeline Failures

**Symptoms:**
- Training jobs fail with errors
- No model outputs generated
- Error messages in training logs

**Solutions:**

1. **Check Data Availability:**
   ```bash
   # Verify data files exist
   ls -la data/processed/

   # Check data quality
   python -c "import polars as pl; df = pl.read_parquet('data/processed/dataset.parquet'); print(df.shape)"
   ```

2. **Validate Configuration:**
   ```bash
   # Check environment variables
   env | grep -E "(MINIO|CLICKHOUSE|REDIS)"

   # Validate training config
   python main.py safe-training --mode quick --dry-run
   ```

3. **Restart Training:**
   ```bash
   # Clean previous state
   rm -rf output/checkpoints/*
   rm -rf logs/ml_training.log

   # Restart with verbose logging
   LOG_LEVEL=DEBUG python main.py safe-training --mode full
   ```

### Issue 3: Database Connection Issues

**Symptoms:**
- ClickHouse connection errors
- Data loading failures
- Timeout errors

**Solutions:**

1. **Check Database Status:**
   ```bash
   # Check ClickHouse health
   docker ps | grep clickhouse

   # Test connection
   docker exec gogooku3-clickhouse clickhouse-client --query "SELECT version()"
   ```

2. **Restart Database:**
   ```bash
   # Restart ClickHouse
   docker compose restart clickhouse

   # Check logs
   docker logs gogooku3-clickhouse
   ```

3. **Connection Pool Issues:**
   ```bash
   # Check connection limits
   docker exec gogooku3-clickhouse clickhouse-client --query "SELECT * FROM system.settings WHERE name LIKE '%max_%'"
   ```

### Issue 4: Storage Issues

**Symptoms:**
- MinIO connection failures
- File upload/download errors
- Storage quota exceeded

**Solutions:**

1. **Check Storage Status:**
   ```bash
   # Check MinIO status
   docker ps | grep minio

   # Test storage access
   docker exec gogooku3-minio mc ls gogooku
   ```

2. **Storage Cleanup:**
   ```bash
   # Check storage usage
   docker exec gogooku3-minio mc du gogooku/

   # Clean old files (if applicable)
   docker exec gogooku3-minio mc rm --older-than 30d gogooku/backups/
   ```

3. **Increase Storage:**
   ```yaml
   # docker-compose.yml
   minio:
     volumes:
       - minio_data:/data
   # Add more storage space to host system
   ```

## ğŸ› ï¸ Maintenance Procedures

### Weekly Maintenance

1. **Log Rotation Check:**
   ```bash
   # Check log sizes
   du -sh logs/*.log

   # Force log rotation if needed
   sudo logrotate -f /etc/logrotate.d/gogooku3
   ```

2. **Disk Space Monitoring:**
   ```bash
   # Check disk usage
   df -h /

   # Clean old logs
   find logs/ -name "*.log" -mtime +7 -delete
   ```

3. **Backup Verification:**
   ```bash
   # List recent backups
   ls -la backups/

   # Verify backup integrity
   tar -tzf backups/latest.tar.gz | head -10
   ```

### Monthly Maintenance

1. **Security Updates:**
   ```bash
   # Update Python packages
   pip list --outdated
   pip install --upgrade -r requirements.txt

   # Update Docker images
   docker compose pull
   ```

2. **Performance Tuning:**
   ```bash
   # Analyze performance metrics
   python ops/metrics_exporter.py --once

   # Check system resources
   python ops/health_check.py health
   ```

3. **Data Quality Assessment:**
   ```bash
   # Run data quality checks
   python -m pytest tests/ -k "quality"

   # Validate data integrity
   python scripts/data/validate_dataset.py
   ```

## ğŸš¨ Emergency Procedures

### Application Down (Critical)

1. **Immediate Assessment:**
   ```bash
   # Check application status
   python ops/health_check.py health

   # Check system resources
   htop

   # Review recent logs
   tail -f logs/main.log
   ```

2. **Recovery Steps:**
   ```bash
   # Attempt graceful restart
   docker compose restart

   # If restart fails, force recreate
   docker compose up --force-recreate

   # Check logs after restart
   docker logs --tail 50 gogooku3-app
   ```

3. **Escalation:**
   - If issue persists > 30 minutes: Notify on-call engineer
   - If data loss suspected: Initiate backup recovery procedure
   - If security incident suspected: Follow security incident response

### Data Loss (High Priority)

1. **Assess Impact:**
   ```bash
   # Check what data is missing
   ls -la data/
   ls -la output/

   # Check backup status
   ls -la backups/
   ```

2. **Recovery Process:**
   ```bash
   # Stop application to prevent corruption
   docker compose stop

   # Restore from backup
   tar -xzf backups/latest.tar.gz -C /

   # Verify data integrity
   python scripts/data/validate_dataset.py

   # Restart application
   docker compose start
   ```

3. **Post-Incident Review:**
   - Document root cause
   - Update backup procedures
   - Implement preventive measures

## ğŸ“ˆ Scaling Procedures

### Horizontal Scaling

1. **Add More Workers:**
   ```yaml
   # docker-compose.yml
   services:
     worker:
       image: gogooku3:latest
       deploy:
         replicas: 3
       environment:
         - WORKER_TYPE=training
   ```

2. **Load Balancer Configuration:**
   ```yaml
   # Add to docker-compose.yml
   lb:
     image: nginx:alpine
     ports:
       - "80:80"
     volumes:
       - ./nginx.conf:/etc/nginx/nginx.conf
   ```

### Vertical Scaling

1. **Increase Resources:**
   ```yaml
   # docker-compose.yml
   services:
     app:
       deploy:
         resources:
           limits:
             cpus: '4.0'
             memory: 16G
           reservations:
             cpus: '2.0'
             memory: 8G
   ```

2. **Optimize Configuration:**
   ```bash
   # Environment variables
   export PERF_POLARS_STREAM=1
   export PERF_MEMORY_OPTIMIZATION=1
   ```

## ğŸ’¾ Backup & Recovery

### Automated Backup

1. **Database Backup:**
   ```bash
   # ClickHouse backup
   docker exec gogooku3-clickhouse clickhouse-client --query "BACKUP DATABASE gogooku3 TO Disk('backups', 'backup_$(date +%Y%m%d_%H%M%S)')"

   # Redis backup
   docker exec gogooku3-redis redis-cli SAVE
   ```

2. **File System Backup:**
   ```bash
   # Create backup archive
   tar -czf backups/data_$(date +%Y%m%d).tar.gz data/ output/ configs/

   # Clean old backups (keep last 7 days)
   find backups/ -name "data_*.tar.gz" -mtime +7 -delete
   ```

### Manual Recovery

1. **Complete Recovery:**
   ```bash
   # Stop services
   docker compose down

   # Restore data
   tar -xzf backups/latest.tar.gz -C /

   # Restore databases
   docker exec gogooku3-clickhouse clickhouse-client --query "RESTORE DATABASE gogooku3 FROM Disk('backups', 'latest_backup')"

   # Start services
   docker compose up -d
   ```

2. **Partial Recovery:**
   ```bash
   # Restore specific files
   tar -xzf backups/data_20231201.tar.gz data/specific_file.parquet

   # Verify integrity
   python scripts/data/validate_dataset.py
   ```

## ğŸ“Š Monitoring & Alerts

### Key Metrics to Monitor

1. **Application Metrics:**
   - Response times
   - Error rates
   - Throughput

2. **System Metrics:**
   - CPU usage
   - Memory usage
   - Disk I/O

3. **Business Metrics:**
   - Training completion rate
   - Model accuracy
   - Data processing volume

### Alert Response

1. **Warning Alerts:**
   - Review logs
   - Check system resources
   - Plan capacity upgrades

2. **Critical Alerts:**
   - Immediate investigation
   - Stakeholder notification
   - Emergency response team activation

3. **Info Alerts:**
   - Log for trend analysis
   - Plan preventive maintenance

## ğŸš¨ éšœå®³å¯¾å¿œæ‰‹é †

### ç·Šæ€¥åœæ­¢ãƒ»å†èµ·å‹•æ‰‹é †

```bash
# å³æ™‚åœæ­¢ï¼ˆç·Šæ€¥æ™‚ï¼‰
docker compose down --timeout 30

# å®‰å…¨åœæ­¢ï¼ˆé€šå¸¸æ™‚ï¼‰
docker compose down --timeout 300

# å¼·åˆ¶å†ä½œæˆï¼ˆè¨­å®šå¤‰æ›´æ™‚ï¼‰
docker compose up -d --force-recreate

# ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆï¼ˆæ®µéšçš„ï¼‰
docker compose up -d --scale app=2 --no-deps app

# ãƒ­ã‚°ç¢ºèª
tail -f logs/main.log
```

### ã‚µãƒ¼ãƒ“ã‚¹åˆ¥éšœå®³å¯¾å¿œ

#### MinIO (Object Storage) éšœå®³æ™‚

**ç—‡çŠ¶ç¢ºèª:**
```bash
# MinIOã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
docker ps | grep minio

# MinIOãƒ­ã‚°ç¢ºèª
docker logs gogooku3-minio | tail -50

# MinIOãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl -f http://localhost:9000/minio/health/live
```

**å›å¾©æ‰‹é †:**
```bash
# MinIOå†èµ·å‹•
docker compose restart minio

# MinIOè¨­å®šç¢ºèª
docker exec gogooku3-minio mc admin info local

# ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
docker exec gogooku3-minio mc ls gogooku/
```

#### ClickHouse (Database) éšœå®³æ™‚

**ç—‡çŠ¶ç¢ºèª:**
```bash
# ClickHouseã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
docker ps | grep clickhouse

# ClickHouseãƒ­ã‚°ç¢ºèª
docker logs gogooku3-clickhouse | tail -50

# ClickHouseæ¥ç¶šãƒ†ã‚¹ãƒˆ
docker exec gogooku3-clickhouse clickhouse-client --query "SELECT 1"
```

**å›å¾©æ‰‹é †:**
```bash
# ClickHouseå†èµ·å‹•
docker compose restart clickhouse

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹ç¢ºèª
docker exec gogooku3-clickhouse clickhouse-client --query "SHOW DATABASES"

# ãƒ†ãƒ¼ãƒ–ãƒ«æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
docker exec gogooku3-clickhouse clickhouse-client --query "SHOW TABLES FROM gogooku3"
```

#### Redis (Cache) éšœå®³æ™‚

**ç—‡çŠ¶ç¢ºèª:**
```bash
# Redisã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
docker ps | grep redis

# Redisãƒ­ã‚°ç¢ºèª
docker logs gogooku3-redis | tail -50

# Redisæ¥ç¶šãƒ†ã‚¹ãƒˆ
docker exec gogooku3-redis redis-cli ping
```

**å›å¾©æ‰‹é †:**
```bash
# Rediså†èµ·å‹•
docker compose restart redis

# Redisãƒ‡ãƒ¼ã‚¿ç¢ºèª
docker exec gogooku3-redis redis-cli dbsize

# Redisãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç¢ºèª
docker exec gogooku3-redis redis-cli info stats
```

#### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³éšœå®³æ™‚

**ç—‡çŠ¶ç¢ºèª:**
```bash
# ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
ps aux | grep python

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
python ops/health_check.py health

# ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³
htop -p $(pgrep -f main.py)
```

**å›å¾©æ‰‹é †:**
```bash
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å†èµ·å‹•
docker compose restart app

# ãƒ¡ãƒ¢ãƒªè§£æ”¾ï¼ˆOOMæ™‚ï¼‰
echo 1 > /proc/sys/vm/drop_caches

# ãƒ­ã‚°åˆ†æ
grep -i error logs/main.log | tail -20
```

### ãƒ‡ãƒ¼ã‚¿ç ´æãƒ»æå¤±æ™‚ã®å¯¾å¿œ

#### ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç ´ææ™‚

```bash
# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç¢ºèª
ls -la backups/

# ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
python -c "
import pandas as pd
try:
    df = pd.read_parquet('data/processed/dataset.parquet')
    print(f'Data integrity OK: {len(df)} rows')
except Exception as e:
    print(f'Data corruption detected: {e}')
"

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®ãƒªã‚¹ãƒˆã‚¢
tar -xzf backups/data_$(date +%Y%m%d).tar.gz -C /
```

#### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç ´ææ™‚

```bash
# ClickHouseãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç¢ºèª
docker exec gogooku3-clickhouse clickhouse-client --query "SHOW BACKUPS"

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®ãƒªã‚¹ãƒˆã‚¢
docker exec gogooku3-clickhouse clickhouse-client --query "
RESTORE DATABASE gogooku3 FROM Disk('backups', 'latest_backup')
"

# ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼
docker exec gogooku3-clickhouse clickhouse-client --query "
SELECT COUNT(*) FROM gogooku3.prices
"
```

### å®¹é‡é€¼è¿«æ™‚ã®å¯¾å¿œ

#### ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡é€¼è¿«

**ç›£è¦–:**
```bash
# ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨çŠ¶æ³
df -h /

# å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ç‰¹å®š
find / -type f -size +100M -exec ls -lh {} \; | head -10

# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
du -sh logs/*.log
```

**å¯¾å¿œ:**
```bash
# ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
sudo logrotate -f /etc/logrotate.d/gogooku3

# ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
find /tmp -name "*.tmp" -mtime +1 -delete

# Dockerã‚¤ãƒ¡ãƒ¼ã‚¸æ•´ç†
docker system prune -f

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤ï¼ˆ7æ—¥ä»¥ä¸Šå‰ï¼‰
find backups/ -name "*.tar.gz" -mtime +7 -delete
```

#### ãƒ¡ãƒ¢ãƒªå®¹é‡é€¼è¿«

**ç›£è¦–:**
```bash
# ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³
free -h

# ãƒ—ãƒ­ã‚»ã‚¹åˆ¥ãƒ¡ãƒ¢ãƒªä½¿ç”¨
ps aux --sort=-%mem | head -10

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨ãƒˆãƒ¬ãƒ³ãƒ‰
python ops/health_check.py health | grep memory
```

**å¯¾å¿œ:**
```bash
# ãƒ¡ãƒ¢ãƒªè§£æ”¾
echo 1 > /proc/sys/vm/drop_caches
echo 2 > /proc/sys/vm/drop_caches
echo 3 > /proc/sys/vm/drop_caches

# å¤§é‡ãƒ¡ãƒ¢ãƒªä½¿ç”¨ãƒ—ãƒ­ã‚»ã‚¹ç‰¹å®š
ps aux --sort=-%mem | head -5

# Dockerã‚³ãƒ³ãƒ†ãƒŠãƒ¡ãƒ¢ãƒªåˆ¶é™èª¿æ•´
docker compose up -d --scale app=1
```

#### CPUå®¹é‡é€¼è¿«

**ç›£è¦–:**
```bash
# CPUä½¿ç”¨çŠ¶æ³
top -b -n 1 | head -10

# CPUä½¿ç”¨ãƒˆãƒ¬ãƒ³ãƒ‰
python ops/health_check.py health | grep cpu
```

**å¯¾å¿œ:**
```bash
# CPUä½¿ç”¨ãƒ—ãƒ­ã‚»ã‚¹ç‰¹å®š
ps aux --sort=-%cpu | head -5

# è² è·è»½æ¸›ã®ãŸã‚ã®ä¸¦åˆ—å‡¦ç†ç„¡åŠ¹åŒ–
unset PERF_PARALLEL_PROCESSING

# Docker CPUåˆ¶é™èª¿æ•´
docker update --cpus 2 gogooku3-app
```

### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯éšœå®³æ™‚ã®å¯¾å¿œ

#### å¤–éƒ¨APIæ¥ç¶šéšœå®³

```bash
# J-Quants APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
curl -I https://api.jquants.com/v1/

# DNSè§£æ±ºç¢ºèª
nslookup api.jquants.com

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç–é€šç¢ºèª
ping -c 3 api.jquants.com
```

**å¯¾å¿œ:**
```bash
# ãƒªãƒˆãƒ©ã‚¤è¨­å®šå¤‰æ›´
export API_RETRY_ATTEMPTS=5
export API_RETRY_DELAY=60

# ä»£æ›¿ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¨­å®šï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
export JQUANTS_BASE_URL=https://backup-api.jquants.com/v1/
```

### ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œãƒ•ãƒ­ãƒ¼

#### 1. æ¤œçŸ¥ãƒ»è©•ä¾¡ï¼ˆDetection & Assessmentï¼‰

```bash
# ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ¤œçŸ¥
python ops/health_check.py health

# å½±éŸ¿ç¯„å›²è©•ä¾¡
docker compose ps
docker stats

# ãƒ­ã‚°åˆ†æ
grep -i error logs/*.log | tail -20
```

#### 2. å¯¾å¿œãƒ»å›å¾©ï¼ˆResponse & Recoveryï¼‰

```bash
# ä¸€æ¬¡å¯¾å¿œ
docker compose restart

# è©³ç´°èª¿æŸ»
tail -f logs/main.log

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç¢ºèª
ls -la backups/
```

#### 3. å¾©æ—§ç¢ºèªï¼ˆVerificationï¼‰

```bash
# ã‚µãƒ¼ãƒ“ã‚¹æ­£å¸¸æ€§ç¢ºèª
python ops/health_check.py health

# æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
python main.py safe-training --mode quick

# ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç¢ºèª
curl http://localhost:8000/metrics
```

#### 4. åŸå› åˆ†æãƒ»å¯¾ç­–ï¼ˆAnalysis & Preventionï¼‰

```bash
# æ ¹æœ¬åŸå› åˆ†æ
# 1. ãƒ­ã‚°åˆ†æ
# 2. ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æ
# 3. è¨­å®šå¤‰æ›´å±¥æ­´ç¢ºèª
# 4. ä¾å­˜é–¢ä¿‚æ›´æ–°ç¢ºèª

# å¯¾ç­–å®Ÿæ–½
# 1. è¨­å®šæœ€é©åŒ–
# 2. ç›£è¦–å¼·åŒ–
# 3. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ”¹å–„
# 4. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°
```

## ğŸ“ Contact Information

### On-Call Schedule
- Primary: [Engineer Name] - [Phone/Slack]
- Secondary: [Engineer Name] - [Phone/Slack]
- Escalation: [Manager Name] - [Phone/Slack]

### External Resources
- Documentation: [Internal Wiki]
- Monitoring Dashboard: [Grafana URL]
- Incident Management: [Tool URL]

---

**Last Updated:** $(date +%Y-%m-%d)
**Version:** 1.0
**Review Cycle:** Monthly
