#!/usr/bin/env python
"""
Production-optimized training script based on PDF analysis.

This script implements all recommended improvements:
1. Multi-worker DataLoader (ALLOW_UNSAFE_DATALOADER=1)
2. Increased model capacity (hidden_size=256)
3. Loss function optimization (RankIC/Sharpe focus)
4. torch.compile enabled
5. Feature grouping alignment
6. Plateau learning rate scheduling
"""

import os
import sys
import subprocess
import json
from pathlib import Path
from typing import Dict, Any, Optional
import logging

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def setup_optimized_environment() -> Dict[str, str]:
    """
    Set up environment based on PDF analysis and current implementation status.
    """

    env = os.environ.copy()

    # ============================================================================
    # 1. Enable multi-worker DataLoader (PDF critical requirement)
    # ============================================================================
    env.update({
        "ALLOW_UNSAFE_DATALOADER": "1",  # Override safety guard
        "NUM_WORKERS": "8",
        "PERSISTENT_WORKERS": "1",
        "PREFETCH_FACTOR": "4",
        "PIN_MEMORY": "1",
    })

    # ============================================================================
    # 2. Optimize loss function weights (PDF: current Sharpe/IC flat)
    # ============================================================================
    env.update({
        # Enable RankIC optimization
        "USE_RANKIC": "1",
        "RANKIC_WEIGHT": "0.2",

        # Increase CS-IC weight
        "USE_CS_IC": "1",
        "CS_IC_WEIGHT": "0.15",  # Increased from 0.05

        # Focus on Sharpe
        "SHARPE_WEIGHT": "0.3",

        # Phase-based loss weights (gradual shift to financial metrics)
        "PHASE_LOSS_WEIGHTS": (
            "0:huber=0.3,quantile=1.0,sharpe=0.1;"
            "1:quantile=0.7,sharpe=0.3,rankic=0.1;"
            "2:quantile=0.5,sharpe=0.4,rankic=0.2,t_nll=0.3;"
            "3:quantile=0.3,sharpe=0.5,rankic=0.3,cs_ic=0.2"
        ),

        # Early stopping on RankIC
        "EARLY_STOP_METRIC": "val_rank_ic_5d",
    })

    # ============================================================================
    # 3. PyTorch optimizations (PDF recommendations)
    # ============================================================================
    env.update({
        # Memory optimization
        "PYTORCH_CUDA_ALLOC_CONF": "expandable_segments:True",

        # cuDNN optimization
        "TORCH_BACKENDS_CUDNN_BENCHMARK": "1",
        "CUDNN_BENCHMARK": "1",

        # TF32 optimization (already implemented but ensure enabled)
        "TF32_ENABLED": "1",

        # torch.compile settings
        "ENABLE_TORCH_COMPILE": "1",
        "TORCH_COMPILE_MODE": "max-autotune",

        # CUDA settings
        "CUDA_LAUNCH_BLOCKING": "0",  # Async operations
    })

    # ============================================================================
    # 4. Training configuration
    # ============================================================================
    env.update({
        # Model configuration
        "MODEL_HIDDEN_SIZE": "256",  # Increased from 64

        # Batch configuration
        "BATCH_SIZE": "2048",
        "ACCUMULATE_GRAD_BATCHES": "2",  # Effective batch = 4096

        # Optimizer
        "LEARNING_RATE": "5e-4",
        "WEIGHT_DECAY": "1e-5",

        # Scheduler (plateau instead of cosine)
        "SCHEDULER_TYPE": "plateau",
        "SCHEDULER_PATIENCE": "7",

        # Training duration
        "MAX_EPOCHS": "120",  # Extended for better convergence

        # SWA and snapshot ensemble
        "USE_SWA": "1",
        "SNAPSHOT_ENS": "1",
    })

    # ============================================================================
    # 5. Data configuration
    # ============================================================================
    env.update({
        # Walk-forward validation
        "N_SPLITS": "5",
        "EMBARGO_DAYS": "20",

        # Feature selection
        "FEATURE_CATEGORIES_CONFIG": str(PROJECT_ROOT / "configs/atft/feature_categories.yaml"),
    })

    # ============================================================================
    # 6. Monitoring and debugging
    # ============================================================================
    env.update({
        "LOG_LEVEL": "INFO",
        "MONITOR_GPU": "1",
        "TRACK_GRAD_NORM": "1",
    })

    return env


def validate_environment(env: Dict[str, str]) -> bool:
    """Validate that critical settings are properly configured."""

    critical_vars = [
        ("ALLOW_UNSAFE_DATALOADER", "1"),
        ("USE_RANKIC", "1"),
        ("MODEL_HIDDEN_SIZE", "256"),
    ]

    all_valid = True
    for var, expected in critical_vars:
        actual = env.get(var)
        if actual != expected:
            logger.warning(f"‚ùå {var}: expected={expected}, actual={actual}")
            all_valid = False
        else:
            logger.info(f"‚úÖ {var}={expected}")

    return all_valid


def check_data_availability() -> Optional[Path]:
    """Check for available dataset."""

    possible_paths = [
        PROJECT_ROOT / "output/ml_dataset_latest_full.parquet",
        PROJECT_ROOT / "output/batch/ml_dataset_full.parquet",
        PROJECT_ROOT / "output/ml_dataset_full.parquet",
    ]

    for path in possible_paths:
        if path.exists():
            logger.info(f"‚úÖ Dataset found: {path}")
            return path

    logger.error("‚ùå No dataset found. Run: make dataset-full START=2020-09-06 END=2025-09-06")
    return None


def run_training(config_name: str = "config_production_optimized", dry_run: bool = False) -> int:
    """
    Run training with optimized configuration.
    """

    # Set up environment
    env = setup_optimized_environment()

    # Validate settings
    if not validate_environment(env):
        logger.warning("‚ö†Ô∏è Some settings may not be optimal")

    # Check data
    data_path = check_data_availability()
    if not data_path:
        return 1

    # Build command
    cmd = [
        sys.executable,
        str(PROJECT_ROOT / "scripts/integrated_ml_training_pipeline.py"),
        "--config-path", str(PROJECT_ROOT / "configs/atft"),
        "--config-name", config_name,
    ]

    # Pass dataset and training params via integrated_ml_training_pipeline.py CLI flags
    cmd.extend([
        "--data-path", str(data_path),
        "--batch-size", env['BATCH_SIZE'],
        "--lr", env['LEARNING_RATE'],
        "--max-epochs", env['MAX_EPOCHS'],
    ])

    # Avoid raw Hydra overrides here to prevent parser conflicts.
    # The integrated pipeline will translate CLI flags to safe overrides and
    # the optimized config already sets hidden_size/compile_model.

    # Log command
    logger.info("\n" + "="*60)
    logger.info("üöÄ PRODUCTION OPTIMIZED TRAINING")
    logger.info("="*60)
    logger.info("\nCommand:")
    logger.info(" ".join(cmd))

    if dry_run:
        logger.info("\n[DRY RUN] Would execute with environment:")
        for key, value in sorted(env.items()):
            if key.startswith(("ALLOW_", "USE_", "CS_", "RANKIC_", "SHARPE_", "MODEL_", "NUM_")):
                logger.info(f"  {key}={value}")
        return 0

    # Run training
    logger.info("\n" + "-"*60)
    logger.info("Starting training...")
    logger.info("-"*60 + "\n")

    try:
        result = subprocess.run(cmd, env=env, check=True)
        logger.info("\n‚úÖ Training completed successfully!")
        return 0
    except subprocess.CalledProcessError as e:
        logger.error(f"\n‚ùå Training failed: {e}")
        return 1
    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è Training interrupted by user")
        return 2


def generate_report():
    """Generate a report of applied optimizations."""

    print("\n" + "="*60)
    print("üìä OPTIMIZATION REPORT (Based on PDF Analysis)")
    print("="*60)

    report = """
‚úÖ COMPLETED OPTIMIZATIONS:
1. Multi-worker DataLoader: ALLOW_UNSAFE_DATALOADER=1, NUM_WORKERS=8
2. Model capacity: hidden_size increased 64‚Üí256 (~20M params)
3. Loss weights: RankIC=0.2, CS-IC=0.15, Sharpe=0.3
4. torch.compile: Enabled with max-autotune mode
5. Feature grouping: 189 features mapped to categories
6. Scheduler: Plateau (adaptive) instead of Cosine

üîÑ PARTIAL IMPLEMENTATIONS:
1. Feature categories: Auto-detection + manual mapping hybrid
2. Phase training: Gradual shift to financial metrics

‚ùå NOT IMPLEMENTED (Future work):
1. DDP: Multi-GPU training (torchrun + DistributedSampler)
2. GPU driver tuning: nvidia-smi power management

üìà EXPECTED IMPROVEMENTS:
- Training speed: 2-3x faster (DataLoader + torch.compile)
- Model capacity: 8x larger (better pattern learning)
- Financial metrics: Direct optimization of IC/RankIC/Sharpe
- Convergence: Better with Plateau scheduler

‚ö†Ô∏è NOTES:
- Requires PyTorch 2.x for torch.compile
- May need to adjust NUM_WORKERS based on CPU cores
- Monitor GPU utilization with nvidia-smi dmon
"""
    print(report)


def main():
    """Main entry point."""

    import argparse
    parser = argparse.ArgumentParser(
        description="Run production-optimized training based on PDF analysis"
    )
    parser.add_argument(
        "--config",
        default="config_production_optimized",
        help="Config name to use"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show configuration without running"
    )
    parser.add_argument(
        "--report",
        action="store_true",
        help="Generate optimization report"
    )

    args = parser.parse_args()

    if args.report:
        generate_report()
        return 0

    return run_training(args.config, args.dry_run)


if __name__ == "__main__":
    sys.exit(main())
