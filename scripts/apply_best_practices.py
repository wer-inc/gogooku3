#!/usr/bin/env python3
"""
Apply Best Practices to gogooku3
gogooku3ã«ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’é©ç”¨ã™ã‚‹çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import sys
import logging
import json
from pathlib import Path
from typing import Dict
from datetime import datetime
import polars as pl

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

# ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from scripts.data_optimizer import DataOptimizer, DataValidator
from scripts.performance_optimizer import PerformanceOptimizer, DataPipelineOptimizer
from scripts.monitoring_system import MetricsCollector, ModelMonitor, DataQualityMonitor

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("logs/best_practices.log"), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


class BestPracticesApplier:
    """ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹é©ç”¨ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.base_dir = Path(".")
        self.output_dir = self.base_dir / "output"
        self.logs_dir = self.base_dir / "logs"
        self.logs_dir.mkdir(exist_ok=True)

        # å„æœ€é©åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆæœŸåŒ–
        self.data_optimizer = DataOptimizer()
        self.data_validator = DataValidator()
        self.performance_optimizer = PerformanceOptimizer()
        self.pipeline_optimizer = DataPipelineOptimizer()

        # ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        self.metrics_collector = MetricsCollector()
        self.model_monitor = ModelMonitor(self.metrics_collector)
        self.data_monitor = DataQualityMonitor(self.metrics_collector)

        # é©ç”¨çµæœã®è¨˜éŒ²
        self.application_results = {
            "timestamp": datetime.now().isoformat(),
            "phases": {},
            "overall_success": True,
            "recommendations": [],
        }

    def apply_all_best_practices(self) -> Dict:
        """ã™ã¹ã¦ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’é©ç”¨"""
        logger.info("ğŸš€ Starting best practices application...")

        try:
            # Phase 1: ãƒ‡ãƒ¼ã‚¿ç®¡ç†æœ€é©åŒ–
            self._apply_data_optimization()

            # Phase 2: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
            self._apply_performance_optimization()

            # Phase 3: ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
            self._apply_monitoring_system()

            # Phase 4: çµ±åˆãƒ†ã‚¹ãƒˆ
            self._run_integration_tests()

            # Phase 5: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            self._generate_final_report()

            logger.info("âœ… All best practices applied successfully!")
            return self.application_results

        except Exception as e:
            logger.error(f"âŒ Best practices application failed: {e}")
            self.application_results["overall_success"] = False
            self.application_results["error"] = str(e)
            return self.application_results

    def _apply_data_optimization(self):
        """ãƒ‡ãƒ¼ã‚¿ç®¡ç†æœ€é©åŒ–ã®é©ç”¨"""
        logger.info("ğŸ“Š Applying data optimization best practices...")

        phase_results = {"success": True, "optimizations": [], "errors": []}

        try:
            # 1. parquetãƒ•ã‚¡ã‚¤ãƒ«æœ€é©åŒ–
            logger.info("ğŸ”§ Optimizing parquet files...")
            optimization_results = self.data_optimizer.optimize_parquet_files(
                "output/atft_data"
            )
            phase_results["optimizations"].append(
                {"type": "parquet_optimization", "results": optimization_results}
            )

            # 2. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            logger.info("ğŸ“‹ Creating data metadata...")
            metadata = self.data_optimizer.create_data_metadata("output/atft_data")
            phase_results["optimizations"].append(
                {"type": "metadata_creation", "results": metadata}
            )

            # 3. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            logger.info("ğŸ§¹ Cleaning up old cache...")
            deleted_count = self.data_optimizer.cleanup_cache()
            phase_results["optimizations"].append(
                {"type": "cache_cleanup", "deleted_files": deleted_count}
            )

            # 4. ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼
            logger.info("ğŸ” Validating data quality...")
            sample_file = next(Path("output/atft_data").rglob("*.parquet"), None)
            if sample_file:
                df = pl.read_parquet(sample_file)
                validation_results = self.data_validator.validate_dataset(df)
                phase_results["optimizations"].append(
                    {"type": "data_validation", "results": validation_results}
                )

            logger.info("âœ… Data optimization completed successfully")

        except Exception as e:
            logger.error(f"âŒ Data optimization failed: {e}")
            phase_results["success"] = False
            phase_results["errors"].append(str(e))

        self.application_results["phases"]["data_optimization"] = phase_results

    def _apply_performance_optimization(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®é©ç”¨"""
        logger.info("âš¡ Applying performance optimization best practices...")

        phase_results = {"success": True, "optimizations": [], "errors": []}

        try:
            # 1. ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
            logger.info("ğŸ“Š Getting system performance metrics...")
            metrics = self.performance_optimizer.get_performance_metrics()
            phase_results["optimizations"].append(
                {"type": "system_metrics", "results": metrics}
            )

            # 2. ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
            logger.info("ğŸ§¹ Optimizing memory usage...")
            memory_usage = self.performance_optimizer.optimize_memory_usage()
            phase_results["optimizations"].append(
                {"type": "memory_optimization", "memory_usage_gb": memory_usage}
            )

            # 3. ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æœ€é©åŒ–è¨­å®š
            logger.info("ğŸ”§ Configuring pipeline optimization...")
            pipeline_config = {
                "use_parallel": True,
                "use_chunk": True,
                "use_batch": True,
                "use_cache": True,
            }
            pipeline_results = self.pipeline_optimizer.optimize_pipeline(
                pipeline_config
            )
            phase_results["optimizations"].append(
                {"type": "pipeline_optimization", "results": pipeline_results}
            )

            logger.info("âœ… Performance optimization completed successfully")

        except Exception as e:
            logger.error(f"âŒ Performance optimization failed: {e}")
            phase_results["success"] = False
            phase_results["errors"].append(str(e))

        self.application_results["phases"]["performance_optimization"] = phase_results

    def _apply_monitoring_system(self):
        """ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®é©ç”¨"""
        logger.info("ğŸ“Š Applying monitoring system best practices...")

        phase_results = {"success": True, "configurations": [], "errors": []}

        try:
            # 1. ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†é–‹å§‹
            logger.info("ğŸ“ˆ Starting metrics collection...")
            self.metrics_collector.start_collection(interval_seconds=60)
            phase_results["configurations"].append(
                {
                    "type": "metrics_collection",
                    "status": "started",
                    "interval_seconds": 60,
                }
            )

            # 2. ã‚µãƒ³ãƒ—ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
            logger.info("ğŸ“Š Collecting sample metrics...")
            import numpy as np
            import polars as pl

            # ãƒ¢ãƒ‡ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒ³ãƒ—ãƒ«
            predictions = np.random.randn(100) * 0.01
            actual_returns = np.random.randn(100) * 0.01
            model_metrics = self.model_monitor.monitor_model_performance(
                predictions, actual_returns
            )
            phase_results["configurations"].append(
                {
                    "type": "model_monitoring",
                    "sample_metrics": {
                        "sharpe_ratio": model_metrics.sharpe_ratio,
                        "max_drawdown": model_metrics.max_drawdown,
                        "win_rate": model_metrics.win_rate,
                    },
                }
            )

            # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒ³ãƒ—ãƒ«
            sample_data = pl.DataFrame(
                {
                    "code": ["1234"] * 50,
                    "date": [f"2024-01-{i:02d}" for i in range(1, 51)],
                    "close": np.random.randn(50) * 100 + 1000,
                }
            )
            data_metrics = self.data_monitor.monitor_data_quality(sample_data)
            phase_results["configurations"].append(
                {
                    "type": "data_quality_monitoring",
                    "sample_metrics": {
                        "total_records": data_metrics.total_records,
                        "null_ratio": data_metrics.null_ratio,
                        "validation_errors": data_metrics.validation_errors,
                    },
                }
            )

            logger.info("âœ… Monitoring system configured successfully")

        except Exception as e:
            logger.error(f"âŒ Monitoring system configuration failed: {e}")
            phase_results["success"] = False
            phase_results["errors"].append(str(e))

        self.application_results["phases"]["monitoring_system"] = phase_results

    def _run_integration_tests(self):
        """çµ±åˆãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
        logger.info("ğŸ§ª Running integration tests...")

        phase_results = {"success": True, "tests": [], "errors": []}

        try:
            # 1. ãƒ‡ãƒ¼ã‚¿æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
            logger.info("ğŸ“Š Testing data optimization...")
            test_results = self._test_data_optimization()
            phase_results["tests"].append(
                {
                    "name": "data_optimization",
                    "success": test_results["success"],
                    "details": test_results,
                }
            )

            # 2. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
            logger.info("âš¡ Testing performance optimization...")
            test_results = self._test_performance_optimization()
            phase_results["tests"].append(
                {
                    "name": "performance_optimization",
                    "success": test_results["success"],
                    "details": test_results,
                }
            )

            # 3. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
            logger.info("ğŸ“ˆ Testing monitoring system...")
            test_results = self._test_monitoring_system()
            phase_results["tests"].append(
                {
                    "name": "monitoring_system",
                    "success": test_results["success"],
                    "details": test_results,
                }
            )

            # å…¨ä½“ã®æˆåŠŸåˆ¤å®š
            all_tests_passed = all(test["success"] for test in phase_results["tests"])
            phase_results["success"] = all_tests_passed

            if all_tests_passed:
                logger.info("âœ… All integration tests passed")
            else:
                logger.warning("âš ï¸ Some integration tests failed")

        except Exception as e:
            logger.error(f"âŒ Integration tests failed: {e}")
            phase_results["success"] = False
            phase_results["errors"].append(str(e))

        self.application_results["phases"]["integration_tests"] = phase_results

    def _test_data_optimization(self) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        try:
            # æœ€é©åŒ–ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            compressed_dir = self.output_dir / "compressed"
            if compressed_dir.exists():
                file_count = len(list(compressed_dir.rglob("*.parquet")))
                return {"success": file_count > 0, "compressed_files": file_count}
            return {"success": False, "error": "No compressed files found"}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def _test_performance_optimization(self) -> Dict:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        try:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å–å¾—
            metrics = self.performance_optimizer.get_performance_metrics()
            return {
                "success": True,
                "cpu_usage": metrics["cpu"]["usage_percent"],
                "memory_usage_gb": metrics["memory"]["usage_gb"],
            }
        except Exception as e:
            return {"success": False, "error": str(e)}

    def _test_monitoring_system(self) -> Dict:
        """ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å­˜åœ¨ç¢ºèª
            db_path = Path("monitoring.db")
            if db_path.exists():
                return {"success": True, "database_exists": True}
            return {"success": False, "error": "Monitoring database not found"}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def _generate_final_report(self):
        """æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        logger.info("ğŸ“‹ Generating final report...")

        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜
        report_file = (
            self.output_dir
            / f"best_practices_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        with open(report_file, "w") as f:
            json.dump(self.application_results, f, indent=2, default=str)

        # æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
        self._generate_recommendations()

        logger.info(f"ğŸ“„ Final report saved: {report_file}")

    def _generate_recommendations(self):
        """æ¨å¥¨äº‹é …ã®ç”Ÿæˆ"""
        recommendations = []

        # ãƒ‡ãƒ¼ã‚¿æœ€é©åŒ–ã®æ¨å¥¨äº‹é …
        data_phase = self.application_results["phases"].get("data_optimization", {})
        if data_phase.get("success", False):
            recommendations.append("âœ… Data optimization completed successfully")
        else:
            recommendations.append("âš ï¸ Consider reviewing data optimization settings")

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®æ¨å¥¨äº‹é …
        perf_phase = self.application_results["phases"].get(
            "performance_optimization", {}
        )
        if perf_phase.get("success", False):
            recommendations.append("âœ… Performance optimization completed successfully")
        else:
            recommendations.append("âš ï¸ Consider adjusting performance settings")

        # ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®æ¨å¥¨äº‹é …
        monitor_phase = self.application_results["phases"].get("monitoring_system", {})
        if monitor_phase.get("success", False):
            recommendations.append("âœ… Monitoring system configured successfully")
        else:
            recommendations.append("âš ï¸ Review monitoring system configuration")

        # çµ±åˆãƒ†ã‚¹ãƒˆã®æ¨å¥¨äº‹é …
        test_phase = self.application_results["phases"].get("integration_tests", {})
        if test_phase.get("success", False):
            recommendations.append("âœ… All integration tests passed")
        else:
            recommendations.append("âš ï¸ Some integration tests failed - review system")

        # è¿½åŠ ã®æ¨å¥¨äº‹é …
        recommendations.extend(
            [
                "ğŸ“Š Monitor system performance regularly",
                "ğŸ”„ Schedule regular cache cleanup",
                "ğŸ“ˆ Review model performance metrics",
                "ğŸ”§ Consider implementing automated alerts",
            ]
        )

        self.application_results["recommendations"] = recommendations


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ gogooku3 Best Practices Application")
    print("=" * 50)

    # ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹é©ç”¨
    applier = BestPracticesApplier()
    results = applier.apply_all_best_practices()

    # çµæœã®è¡¨ç¤º
    print("\nğŸ“Š Application Results:")
    print("=" * 30)

    if results["overall_success"]:
        print("âœ… Overall Status: SUCCESS")
    else:
        print("âŒ Overall Status: FAILED")
        if "error" in results:
            print(f"Error: {results['error']}")

    print(f"\nğŸ“… Applied at: {results['timestamp']}")

    # ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥çµæœ
    print("\nğŸ“‹ Phase Results:")
    for phase_name, phase_result in results["phases"].items():
        status = "âœ…" if phase_result.get("success", False) else "âŒ"
        print(f"{status} {phase_name.replace('_', ' ').title()}")

    # æ¨å¥¨äº‹é …
    if "recommendations" in results:
        print("\nğŸ’¡ Recommendations:")
        for rec in results["recommendations"]:
            print(f"  {rec}")

    print("\nğŸ‰ Best practices application completed!")


if __name__ == "__main__":
    main()
