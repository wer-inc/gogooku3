"""
ATFT-GAT-FAN „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ÂÆüË£Ö
Adaptive Temporal Fusion Transformer with Graph Attention and Frequency Adaptive Normalization
"""
import logging
import os
import re

# import pytorch_lightning as pl  # DISABLED due to std::bad_alloc error
import torch
import torch.nn as nn
from omegaconf import DictConfig

from src.training.curriculum import (
    CurriculumScheduler,
    create_research_curriculum,
    create_simple_curriculum,
)

from ..components import (
    FreqDropout1D,
    FrequencyAdaptiveNorm,
    MultiLayerGAT,
    SliceAdaptiveNorm,
    TemporalFusionTransformer,
    VariableSelectionNetwork,
)

logger = logging.getLogger(__name__)


class ATFT_GAT_FAN(nn.Module):  # Changed from pl.LightningModule due to import issues
    """
    ATFT-GAT-FAN: Adaptive Temporal Fusion Transformer with Graph Attention and Frequency Adaptive Normalization

    ÁâπÂæ¥:
    - Temporal Fusion Transformer (TFT): ÊôÇÁ≥ªÂàóÁâπÂæ¥Èáè„ÅÆËûçÂêà
    - Graph Attention Network (GAT): ÈäòÊüÑÈñìÈñ¢‰øÇ„ÅÆ„É¢„Éá„É™„É≥„Ç∞
    - Frequency Adaptive Normalization (FAN): Âë®Ê≥¢Êï∞ÈÅ©ÂøúÊ≠£Ë¶èÂåñ
    - Slice Adaptive Normalization (SAN): „Çπ„É©„Ç§„ÇπÈÅ©ÂøúÊ≠£Ë¶èÂåñ
    """

    _TARGET_KEY_PATTERNS = [
        re.compile(
            r"^(?:return|returns|ret|target|targets|tgt|y)_(\d+)(?:d)?$", re.IGNORECASE
        ),
        re.compile(r"^label_ret_(\d+)_bps$", re.IGNORECASE),
        re.compile(r"^horizon_(\d+)(?:d)?$", re.IGNORECASE),
        re.compile(r"^point_horizon_(\d+)$", re.IGNORECASE),
        re.compile(r"^h(\d+)$", re.IGNORECASE),
        re.compile(r"^(\d+)(?:d)?$", re.IGNORECASE),
    ]

    def __init__(self, config: DictConfig):
        super().__init__()
        self.config = config
        # self.save_hyperparameters()  # ‰∏ÄÊôÇÁöÑ„Å´ÁÑ°ÂäπÂåñÔºà„ÉÜ„Çπ„ÉàÁî®Ôºâ

        # ÁâπÂæ¥ÈáèÊ¨°ÂÖÉ„ÅÆË®àÁÆó
        self._calculate_feature_dims()

        # „É¢„Éá„É´„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà„ÅÆÊßãÁØâ
        self._build_model()

        # ÊêçÂ§±Èñ¢Êï∞
        self._setup_loss_functions()

        logger.info(
            f"ATFT-GAT-FAN initialized with {self.n_dynamic_features} dynamic features"
        )

        # Curriculum scheduler (optional)
        self.curriculum_scheduler = self._build_curriculum()
        self.curriculum_horizon_weights: dict[int, float] | None = None
        self.curriculum_active_horizons: set[str] | None = None
        self._target_warning_logged = False

    def _canonicalize_target_key(self, key: object) -> str | None:
        """Map various target key aliases to the canonical 'horizon_{n}d' string."""
        if isinstance(key, int):
            return f"horizon_{int(key)}d"
        if isinstance(key, str):
            stripped = key.strip()
            for pattern in self._TARGET_KEY_PATTERNS:
                match = pattern.match(stripped)
                if match:
                    return f"horizon_{int(match.group(1))}d"
        return None

    def _extract_targets(
        self, batch: dict[str, torch.Tensor]
    ) -> dict[str, torch.Tensor]:
        """Collect target tensors keyed by canonical horizon name from the batch."""

        targets_map: dict[str, torch.Tensor] = {}
        if not isinstance(batch, dict):
            return targets_map

        raw_targets = batch.get("targets")
        if isinstance(raw_targets, dict):
            for key, value in raw_targets.items():
                if not torch.is_tensor(value):
                    continue
                canonical = self._canonicalize_target_key(key)
                if canonical is not None:
                    targets_map[canonical] = value

        # Some collate pipelines may already place horizon keys at the top level
        for key, value in batch.items():
            if key == "targets" or not torch.is_tensor(value):
                continue
            canonical = self._canonicalize_target_key(key)
            if canonical is not None:
                targets_map.setdefault(canonical, value)

        return targets_map

    def _fetch_target_tensor(
        self,
        targets_map: dict[str, torch.Tensor],
        horizon_key: str,
        reference: torch.Tensor,
    ) -> torch.Tensor | None:
        """Get a target tensor aligned with the prediction tensor device/dtype."""

        target = targets_map.get(horizon_key)
        if target is None and horizon_key.endswith("d"):
            # Allow lookup without the trailing 'd' if present in the map
            alt_key = horizon_key[:-1]
            target = targets_map.get(alt_key)
        if target is None:
            return None

        target_tensor = target.to(reference.device, dtype=reference.dtype)
        if target_tensor.dim() > 1:
            target_tensor = target_tensor.squeeze(-1)
        return target_tensor

    def _calculate_feature_dims(self):
        """ÁâπÂæ¥ÈáèÊ¨°ÂÖÉ„ÅÆË®àÁÆóÔºàconfig„ÅÆÂÖ•ÂäõÊ¨°ÂÖÉÂÆöÁæ©„ÇíÂ∞äÈáçÔºâ"""

        def _cfg_get(obj: object, key: str, default: int | None = None) -> int | None:
            """Safely extract scalar values from OmegaConf nodes or dicts."""
            try:
                if obj is None:
                    return default
                if hasattr(obj, key):
                    value = getattr(obj, key)
                elif isinstance(obj, dict):
                    value = obj.get(key, default)
                else:
                    from omegaconf import OmegaConf

                    value = OmegaConf.select(obj, key, default=default)  # type: ignore[arg-type]
                if value is None:
                    return default
                return int(value)
            except Exception:
                return default

        manual_dims = getattr(self.config.model, "input_dims", None)

        total_features = _cfg_get(manual_dims, "total_features")
        if total_features is None:
            raise ValueError(
                "model.input_dims.total_features must be specified in config. "
                "Feature category auto-detection has been disabled."
            )

        historical_override = _cfg_get(manual_dims, "historical_features", 0) or 0
        current_features = total_features - historical_override
        if current_features <= 0:
            current_features = total_features

        self.n_current_features = current_features
        self.n_historical_features = historical_override
        self.n_dynamic_features = total_features

        static_features = _cfg_get(manual_dims, "static_features", 0) or 0
        categorical_features = _cfg_get(manual_dims, "categorical_features", 0) or 0
        self.n_static_features = static_features + categorical_features

        logger.info(
            "‚úÖ Feature dimensions resolved from config: total=%d, current=%d, "
            "historical=%d, static=%d",
            self.n_dynamic_features,
            self.n_current_features,
            self.n_historical_features,
            self.n_static_features,
        )

    def _build_model(self):
        """„É¢„Éá„É´„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆÊßãÁØâ"""

        self.hidden_size = int(getattr(self.config.model, "hidden_size", 128))
        self.gat_output_dim = 0
        self.gat_edge_weight = 0.0
        self.gat_entropy_weight = 0.0
        self.gat_output_norm: nn.LayerNorm | None = None
        self.gat_residual_clip: float = 0.0

        # Variable Selection Network (feature-wise gating)
        self.variable_selection = self._build_variable_selection()

        # ÂÖ•ÂäõÊäïÂΩ±Â±§ÔºàVSNÂá∫ÂäõÂæå„ÅÆË™øÊï¥Ôºâ
        self.input_projection = self._build_input_projection()

        # Temporal Fusion Transformer backbone
        self.tft = self._build_tft()

        # Graph Attention Network (ÈäòÊüÑÈñì„É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞)
        self.gat = (
            self._build_gat()
            if getattr(self.config.model.gat, "enabled", False)
            else None
        )

        self.combined_feature_dim = self.hidden_size + (
            self.gat_output_dim if self.gat is not None else 0
        )
        self.backbone_projection = nn.Linear(
            self.combined_feature_dim, self.hidden_size
        )

        self.enable_nan_guard = os.getenv("ENABLE_ATFT_NAN_GUARD", "1") == "1"
        self.nan_guard_max_log = int(os.getenv("ATFT_NAN_GUARD_MAX_LOG", "5"))
        self._nan_guard_counts: dict[str, int] = {}

        # GAT Residual Bypass‰øÆÊ≠£ (Phase 2)
        if self.gat is not None:
            with torch.no_grad():
                # GATÈÉ®ÂàÜ„ÅÆÈáç„Åø„Çí3ÂÄç„Çπ„Ç±„Éº„É™„É≥„Ç∞ÔºàÂãæÈÖç„Éï„É≠„Éº‰øùË®ºÔºâ
                gat_start_idx = self.hidden_size
                self.backbone_projection.weight.data[:, gat_start_idx:] *= 3.0
            # ResidualÊé•Á∂öÁî®„ÅÆÂ≠¶ÁøíÂèØËÉΩ„Å™„Ç≤„Éº„ÉàÔºàŒ±ÂàùÊúüÂÄ§=0.5Ôºâ
            self.gat_residual_gate = nn.Parameter(torch.tensor(0.0))  # sigmoid(0)=0.5
            # GATÂá∫Âäõ„ÅÆÂÆâÂÆöÂåñ: LayerNorm + optional clamp
            self.gat_output_norm = nn.LayerNorm(self.gat_output_dim)
            clip_cfg = None
            try:
                clip_cfg = self.config.model.gat.residual_clip
            except Exception:
                clip_cfg = None
            if clip_cfg is None:
                clip_cfg = os.getenv("GAT_RESIDUAL_CLIP", "10.0")
            try:
                self.gat_residual_clip = float(clip_cfg) if clip_cfg else 0.0
            except (TypeError, ValueError):
                self.gat_residual_clip = 10.0
            logger.info(
                "‚úÖ [GAT-FIX] Applied 3x weight scaling + residual gate (Œ±=0.5)"
            )

        # ÈÅ©ÂøúÊ≠£Ë¶èÂåñ (FAN/SAN)
        self.adaptive_norm = self._build_adaptive_normalization()

        # Âë®Ê≥¢Êï∞DropoutÔºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ
        self.freq_dropout = self._build_freq_dropout()

        # ‰∫àÊ∏¨„Éò„ÉÉ„ÉâÔºàRegimeMoE / Multi-horizon Á≠âÔºâ
        self.prediction_head = self._build_prediction_head()

        # „É©„É≥„Çø„Ç§„É†„ÅßÊõ¥Êñ∞„Åô„ÇãÊ≠£ÂâáÂåñ„É°„Éà„É™„ÇØ„Çπ„ÅÆÂàùÊúüÂåñ
        self._vsn_sparsity_loss = torch.tensor(0.0)
        self._last_variable_gates: torch.Tensor | None = None
        self._gat_attention_entropy: torch.Tensor | None = None
        self._gat_edge_reg_value: torch.Tensor | None = None
        self._last_attention_weights = None

    def _get_training_config(self):
        if hasattr(self.config, "training") and self.config.training is not None:
            return self.config.training
        if hasattr(self.config, "train") and self.config.train is not None:
            return self.config.train
        from omegaconf import OmegaConf

        return OmegaConf.create({})

    def _build_variable_selection(self) -> VariableSelectionNetwork:
        """Variable Selection Network„ÅÆÊßãÁØâ"""
        # Safely get tft config
        try:
            tft_cfg = getattr(self.config.model, "tft", None)
        except Exception:
            tft_cfg = None

        # Handle None or non-dict values
        if tft_cfg is None or not hasattr(tft_cfg, "__getitem__"):
            vsn_cfg = {}
        else:
            try:
                vsn_cfg = (
                    tft_cfg.get("variable_selection", {})
                    if hasattr(tft_cfg, "get")
                    else tft_cfg.get("variable_selection")
                    if callable(getattr(tft_cfg, "get", None))
                    else {}
                )
            except Exception:
                vsn_cfg = {}

        dropout = float(
            getattr(vsn_cfg, "dropout", 0.1)
            if hasattr(vsn_cfg, "__getattr__")
            else vsn_cfg.get("dropout", 0.1)
            if isinstance(vsn_cfg, dict)
            else 0.1
        )
        use_sigmoid = bool(
            getattr(vsn_cfg, "use_sigmoid", True)
            if hasattr(vsn_cfg, "__getattr__")
            else vsn_cfg.get("use_sigmoid", True)
            if isinstance(vsn_cfg, dict)
            else True
        )
        sparsity_coeff = float(
            getattr(vsn_cfg, "sparsity_coefficient", 0.0)
            if hasattr(vsn_cfg, "__getattr__")
            else vsn_cfg.get("sparsity_coefficient", 0.0)
            if isinstance(vsn_cfg, dict)
            else 0.0
        )

        self.vsn_sparsity_weight = sparsity_coeff

        return VariableSelectionNetwork(
            input_size=1,
            num_features=self.n_dynamic_features,
            hidden_size=self.hidden_size,
            dropout=dropout,
            use_sigmoid=use_sigmoid,
            sparsity_coefficient=sparsity_coeff,
        )

    def _reconfigure_dynamic_feature_dim(
        self, new_dim: int, device: torch.device
    ) -> None:
        """Rebuild feature-dependent modules when runtime feature dimension differs."""
        if new_dim <= 0:
            raise ValueError("new_dim must be positive")
        if new_dim == self.n_dynamic_features:
            return
        logger.warning(
            "Dynamic feature dimension mismatch detected (expected %d, got %d). "
            "Rebuilding variable selection network.",
            self.n_dynamic_features,
            new_dim,
        )
        self.n_dynamic_features = new_dim
        self.variable_selection = self._build_variable_selection().to(device)

    def _ensure_backbone_projection(self, input_dim: int, device: torch.device) -> None:
        """Resize backbone projection when combined features dimensionality shifts."""
        if input_dim == self.combined_feature_dim and hasattr(
            self, "backbone_projection"
        ):
            return
        logger.warning(
            "Adjusting backbone projection input dim from %d to %d",
            getattr(self, "combined_feature_dim", -1),
            input_dim,
        )
        self.combined_feature_dim = input_dim
        self.backbone_projection = nn.Linear(input_dim, self.hidden_size).to(device)

    def _build_input_projection(self) -> nn.Module:
        """VSNÂæå„ÅÆÊ≠£Ë¶èÂåñ„ÉªDropout „ÇíÂê´„ÇÄÊäïÂΩ±Â±§"""
        proj_cfg = getattr(self.config.model, "input_projection", None)
        if proj_cfg is None:
            use_layer_norm = True
            dropout = 0.1
        else:
            use_layer_norm = bool(getattr(proj_cfg, "use_layer_norm", True))
            dropout = float(getattr(proj_cfg, "dropout", 0.1))

        layers: list[nn.Module] = [nn.Linear(self.hidden_size, self.hidden_size)]
        if use_layer_norm:
            layers.append(nn.LayerNorm(self.hidden_size))
        layers.append(nn.Dropout(dropout))
        return nn.Sequential(*layers)

    def _build_tft(self) -> TemporalFusionTransformer:
        """Temporal Fusion Transformer„ÅÆÊßãÁØâ"""
        tft_cfg = getattr(self.config.model, "tft", {})
        lstm_cfg = getattr(tft_cfg, "lstm", {})
        att_cfg = getattr(tft_cfg, "attention", {})
        temporal_cfg = getattr(tft_cfg, "temporal", {})

        num_layers = int(getattr(lstm_cfg, "layers", 1))
        dropout = float(getattr(lstm_cfg, "dropout", 0.1))
        num_heads = int(getattr(att_cfg, "heads", 4))
        att_dropout = float(getattr(att_cfg, "dropout", dropout))
        use_positional = bool(getattr(temporal_cfg, "use_positional_encoding", True))
        max_seq_len = int(getattr(temporal_cfg, "max_sequence_length", 64))

        return TemporalFusionTransformer(
            input_size=self.hidden_size,
            hidden_size=self.hidden_size,
            num_heads=num_heads,
            num_layers=num_layers,
            dropout=max(dropout, att_dropout),
            use_positional_encoding=use_positional,
            max_sequence_length=max_seq_len,
        )

    def _build_gat(self) -> MultiLayerGAT | None:
        """Graph Attention Network„ÅÆÊßãÁØâ"""
        gat_cfg = getattr(self.config.model, "gat", None)
        if gat_cfg is None or not getattr(gat_cfg, "enabled", False):
            return None

        arch_cfg = getattr(gat_cfg, "architecture", {})
        hidden_channels = list(getattr(arch_cfg, "hidden_channels", [self.hidden_size]))
        heads = list(getattr(arch_cfg, "heads", [4] * len(hidden_channels)))
        concat = list(getattr(arch_cfg, "concat", [True] * len(hidden_channels)))
        num_layers = int(getattr(arch_cfg, "num_layers", len(hidden_channels)))

        layer_cfg = getattr(gat_cfg, "layer_config", {})
        dropout = float(getattr(layer_cfg, "dropout", 0.2))
        edge_dropout = float(getattr(layer_cfg, "edge_dropout", 0.1))
        edge_cfg = getattr(gat_cfg, "edge_features", {})
        edge_dim = int(getattr(edge_cfg, "edge_dim", 0)) or None

        reg_cfg = getattr(gat_cfg, "regularization", {})
        edge_penalty = float(getattr(reg_cfg, "edge_weight_penalty", 0.0))
        entropy_penalty = float(getattr(reg_cfg, "attention_entropy_penalty", 0.0))

        self.gat_output_dim = hidden_channels[-1] * (heads[-1] if concat[-1] else 1)
        self.gat_entropy_weight = entropy_penalty
        self.gat_edge_weight = edge_penalty

        # üîß DEBUG (2025-10-06): Log initialized GAT weights
        import logging

        logger = logging.getLogger(__name__)
        logger.info(
            f"[GAT-INIT] gat_entropy_weight={self.gat_entropy_weight}, gat_edge_weight={self.gat_edge_weight}, gat_output_dim={self.gat_output_dim}"
        )

        return MultiLayerGAT(
            num_layers=num_layers,
            in_channels=self.hidden_size,
            hidden_channels=hidden_channels,
            heads=heads,
            concat_list=concat,
            dropout=dropout,
            edge_dropout=edge_dropout,
            edge_dim=edge_dim,
            edge_weight_penalty=edge_penalty,
            attention_entropy_penalty=entropy_penalty,
            use_graph_norm=True,
        )

    def _build_adaptive_normalization(self) -> nn.Module:
        """ÈÅ©ÂøúÊ≠£Ë¶èÂåñÂ±§„ÅÆÊßãÁØâ (FAN -> SAN)"""
        norm_cfg = getattr(self.config.model, "adaptive_normalization", {})
        fan_cfg = getattr(norm_cfg, "fan", {})
        san_cfg = getattr(norm_cfg, "san", {})

        fan_enabled = bool(getattr(fan_cfg, "enabled", True))
        san_enabled = bool(getattr(san_cfg, "enabled", True))

        fan = (
            FrequencyAdaptiveNorm(
                num_features=self.hidden_size,
                window_sizes=list(getattr(fan_cfg, "window_sizes", [5, 10, 20])),
                aggregation=str(getattr(fan_cfg, "aggregation", "weighted_mean")),
                learn_weights=bool(getattr(fan_cfg, "learn_weights", True)),
            )
            if fan_enabled
            else nn.Identity()
        )

        san = (
            SliceAdaptiveNorm(
                num_features=self.hidden_size,
                num_slices=int(getattr(san_cfg, "num_slices", 3)),
                overlap=float(getattr(san_cfg, "overlap", 0.5)),
                slice_aggregation=str(getattr(san_cfg, "slice_aggregation", "learned")),
            )
            if san_enabled
            else nn.Identity()
        )

        return nn.Sequential(fan, san)

    def _build_freq_dropout(self) -> nn.Module | None:
        """Âë®Ê≥¢Êï∞È†òÂüü„ÅÆDropoutË®≠ÂÆö"""
        # Try to get freq_dropout_p from improvements section first, then from root
        if hasattr(self.config, "improvements") and hasattr(
            self.config.improvements, "freq_dropout_p"
        ):
            freq_dropout_p = self.config.improvements.freq_dropout_p
        else:
            freq_dropout_p = getattr(self.config, "freq_dropout_p", 0.0)

        # Handle None values
        if freq_dropout_p is None:
            freq_dropout_p = 0.0

        freq_dropout_p = float(freq_dropout_p)
        if freq_dropout_p <= 0:
            return None

        # Try to get min/max width from improvements section first
        if hasattr(self.config, "improvements"):
            min_width = getattr(
                self.config.improvements, "freq_dropout_min_width", 0.05
            )
            max_width = getattr(self.config.improvements, "freq_dropout_max_width", 0.2)
        else:
            min_width = getattr(self.config, "freq_dropout_min_width", 0.05)
            max_width = getattr(self.config, "freq_dropout_max_width", 0.2)

        return FreqDropout1D(
            p=freq_dropout_p,
            min_width=float(min_width) if min_width is not None else 0.05,
            max_width=float(max_width) if max_width is not None else 0.2,
        )

    def _build_curriculum(self) -> CurriculumScheduler | None:
        """Build curriculum scheduler if enabled in config."""
        training_cfg = self._get_training_config()
        curriculum_cfg = getattr(training_cfg, "curriculum", None)
        if curriculum_cfg is None or not getattr(curriculum_cfg, "enabled", False):
            return None

        trainer_cfg = getattr(training_cfg, "trainer", None)
        max_epochs = int(getattr(trainer_cfg, "max_epochs", 100))
        profile = str(getattr(curriculum_cfg, "profile", "research")).lower()

        if profile == "simple":
            scheduler = create_simple_curriculum(max_epochs=max_epochs)
        else:
            scheduler = create_research_curriculum(max_epochs=max_epochs)

        logger.info("Curriculum scheduler enabled (%s)", profile)
        return scheduler

    def _build_prediction_head(self):
        """‰∫àÊ∏¨„Éò„ÉÉ„Éâ„ÅÆÊßãÁØâÔºàMulti-horizon / RegimeMoE ÂØæÂøúÔºâ"""
        # Detect requested head type; default to multi-horizon for backward compatibility
        head_type = getattr(self.config.model.prediction_head, "type", "multi_horizon")

        if head_type == "regime_moe":
            # Lazy import to avoid circulars
            from .regime_moe import RegimeMoEPredictionHeads

            return RegimeMoEPredictionHeads(
                hidden_size=self.config.model.hidden_size, config=self.config.model
            )

        # Multi-horizon prediction headÔºàÂæìÊù•Ôºâ
        training_cfg = self._get_training_config()
        use_multi_horizon = getattr(training_cfg, "use_multi_horizon_heads", True)
        if use_multi_horizon:
            return MultiHorizonPredictionHeads(
                hidden_size=self.config.model.hidden_size,
                config=self.config.model.prediction_head,
                training_cfg=training_cfg,
            )
        else:
            # Backward compatibility: single horizon head
            return PredictionHead(
                hidden_size=self.config.model.hidden_size,
                config=self.config.model.prediction_head,
            )

    def _setup_loss_functions(self):
        """ÊêçÂ§±Èñ¢Êï∞„ÅÆË®≠ÂÆö"""
        # Quantile LossÔºà„É°„Ç§„É≥Ôºâ
        quantiles = (
            self.config.model.prediction_head.output.quantile_prediction.quantiles
        )
        self.quantile_loss = QuantileLoss(quantiles)

        # ‰∏≠Â§ÆÂàÜ‰ΩçÁÇπ„ÅÆ„Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÔºàRankÊêçÂ§±Áî®„ÅÆ„Çπ„Ç≥„Ç¢ÊäΩÂá∫Ôºâ
        try:
            # ÊúÄ„ÇÇ0.5„Å´Ëøë„ÅÑÂàÜ‰ΩçÁÇπ„ÇíÊé°Áî®
            q_list = list(float(q) for q in quantiles)
            self._median_q_idx = min(
                range(len(q_list)), key=lambda i: abs(q_list[i] - 0.5)
            )
        except Exception:
            self._median_q_idx = 0

        training_cfg = self._get_training_config()
        loss_cfg = getattr(training_cfg, "loss", None)
        aux_cfg = getattr(loss_cfg, "auxiliary", None) if loss_cfg is not None else None

        # Ë£úÂä©ÊêçÂ§±
        sharpe_cfg = (
            getattr(aux_cfg, "sharpe_loss", None) if aux_cfg is not None else None
        )
        if getattr(sharpe_cfg, "enabled", False):
            self.sharpe_loss = SharpeLoss(
                weight=float(getattr(sharpe_cfg, "weight", 0.1)),
                min_periods=int(getattr(sharpe_cfg, "min_periods", 20)),
            )
        else:
            self.sharpe_loss = None

        # „É©„É≥„Ç≠„É≥„Ç∞ÊêçÂ§±Ôºà‰ªªÊÑèÔºâ
        try:
            rk_cfg = getattr(aux_cfg, "ranking_loss", None)
            if getattr(rk_cfg, "enabled", False):
                from ....losses.pairwise_rank_loss import PairwiseRankLoss

                scale = float(getattr(rk_cfg, "scale", getattr(rk_cfg, "margin", 5.0)))
                topk = int(getattr(rk_cfg, "topk", 0))
                self.rank_loss = PairwiseRankLoss(s=scale, topk=topk)
                self.rank_loss_weight = float(getattr(rk_cfg, "weight", 0.1))
            else:
                self.rank_loss = None
                self.rank_loss_weight = 0.0
        except Exception:
            self.rank_loss = None
            self.rank_loss_weight = 0.0

        # ÊÑèÊÄùÊ±∫ÂÆöÂ±§Ôºà‰ªªÊÑèÔºâ
        try:
            dl_cfg = getattr(aux_cfg, "decision_layer", None)
            if getattr(dl_cfg, "enabled", False):
                from ....losses.decision_layer import DecisionLayer, DecisionLossConfig

                self.decision_layer = DecisionLayer(
                    DecisionLossConfig(
                        alpha=float(getattr(dl_cfg, "alpha", 2.0)),
                        method=str(getattr(dl_cfg, "method", "tanh")),
                        sharpe_weight=float(getattr(dl_cfg, "sharpe_weight", 0.1)),
                        pos_l2=float(getattr(dl_cfg, "pos_l2", 1e-3)),
                        fee_abs=float(getattr(dl_cfg, "fee_abs", 0.0)),
                        detach_signal=bool(getattr(dl_cfg, "detach_signal", True)),
                    )
                )

                # Decision Layer „Çπ„Ç±„Ç∏„É•„Éº„É©ÔºàÊúâÂäπ„Å™Â†¥ÂêàÔºâ
                sched_cfg = {}
                if aux_cfg is not None:
                    sched_cfg = getattr(aux_cfg, "decision_layer_schedule", {})
                if sched_cfg.get("enabled", False):
                    from ....training.decision_scheduler import (
                        create_decision_scheduler_from_config,
                    )

                    self.decision_scheduler = create_decision_scheduler_from_config(
                        self.config, self.decision_layer
                    )
                    logger.info("Decision Layer scheduler enabled")
                else:
                    self.decision_scheduler = None
            else:
                self.decision_layer = None
                self.decision_scheduler = None
        except Exception as e:
            logger.warning(f"Decision Layer initialization failed: {e}")
            self.decision_layer = None
            self.decision_scheduler = None

    def forward(self, batch: dict[str, torch.Tensor]) -> dict[str, torch.Tensor]:
        """
        Enhanced forward pass with regime features support
        """
        if torch.is_tensor(batch):
            batch = {"dynamic_features": batch}
        elif not isinstance(batch, dict):
            raise TypeError(
                "ATFT_GAT_FAN.forward expects a dict batch or feature tensor"
            )

        # ÂÖ•Âäõ„Éá„Éº„Çø„ÅÆÂ±ïÈñã
        dynamic_features = batch.get("dynamic_features")
        if dynamic_features is None and "features" in batch:
            dynamic_features = batch["features"]
        if dynamic_features is None:
            raise KeyError("Batch must contain 'dynamic_features' or 'features'")
        if dynamic_features.dim() == 2:
            dynamic_features = dynamic_features.unsqueeze(0)
        dynamic_features = dynamic_features.to(torch.float32)
        current_feature_dim = dynamic_features.size(-1)
        if current_feature_dim != self.n_dynamic_features:
            self._reconfigure_dynamic_feature_dim(
                current_feature_dim, dynamic_features.device
            )
        static_features = batch.get("static_features", None)  # [batch, n_static]
        edge_index = batch.get("edge_index", None)
        edge_attr = batch.get("edge_attr", None)

        # „É¨„Ç∏„Éº„É†ÁâπÂæ¥ÈáèÔºàJ-UVX + KAMA/VIDYA + market regimesÔºâ
        regime_features = batch.get("regime_features", None)  # [batch, regime_dim]

        # Variable Selection Network (feature gating)
        vsn_input = dynamic_features.unsqueeze(-1)
        selected_features, feature_gates, sparsity_loss = self.variable_selection(
            vsn_input
        )
        self._vsn_sparsity_loss = sparsity_loss
        self._last_variable_gates = feature_gates.detach()

        # ÂÖ•ÂäõÊäïÂΩ±
        projected = self.input_projection(selected_features)

        # Temporal Fusion Transformer
        # FIX: Always compute attention (train/eval mode consistency)
        # Loss is only added during training, but forward behavior should be identical
        return_attention = self.gat is not None and self.gat_entropy_weight > 0

        # üîß DEBUG (2025-10-07): Log return_attention decision
        import logging

        logger = logging.getLogger(__name__)
        logger.debug(
            f"[RETURN-ATT] self.training={self.training}, gat_is_not_none={self.gat is not None}, entropy_weight={self.gat_entropy_weight} ‚Üí return_attention={return_attention}"
        )

        tft_output, attn_weights = self.tft(
            projected,
            return_attention_weights=return_attention,
        )
        self._last_tft_attention = attn_weights

        # Graph Attention NetworkÔºàÊúâÂäπ„Å™Â†¥ÂêàÔºâ
        gat_features = None
        gat_residual_base: torch.Tensor | None = None
        self._gat_attention_entropy = None
        self._gat_edge_reg_value = None
        if self.gat is not None and edge_index is not None:
            # üîß DEBUG (2025-10-06): Log GAT execution
            logger.debug(
                f"[GAT-EXEC] GAT layer executing with edge_index.shape={edge_index.shape}"
            )

            last_step = tft_output[:, -1, :]  # [batch, hidden]
            self._nan_guard(last_step, "last_step_before_gat")
            if return_attention:
                logger.debug(
                    "[RETURN-ATT] Taking return_attention=True branch - computing GAT loss metrics"
                )
                gat_emb, attention_weights = self.gat(
                    last_step, edge_index, edge_attr, return_attention_weights=True
                )
                self._gat_attention_entropy = self.gat.get_attention_entropy(
                    attention_weights
                )
                # Use final layer attention weights for edge regularization proxy
                _, att_tensor = attention_weights[-1]
                self._gat_edge_reg_value = att_tensor.pow(2).mean()
                self._last_attention_weights = attention_weights
                logger.debug(
                    f"[RETURN-ATT] Set _gat_attention_entropy={self._gat_attention_entropy.item():.6f}, _gat_edge_reg_value={self._gat_edge_reg_value.item():.6f}"
                )
            else:
                logger.debug(
                    "[RETURN-ATT] Taking return_attention=False branch - GAT loss metrics will be None"
                )
                gat_emb = self.gat(last_step, edge_index, edge_attr)
                self._last_attention_weights = None

            if self.gat_output_norm is not None:
                gat_emb = self.gat_output_norm(gat_emb)
            if self.gat_residual_clip > 0:
                gat_emb = torch.clamp(
                    gat_emb, -self.gat_residual_clip, self.gat_residual_clip
                )
            self._nan_guard(gat_emb, "gat_emb_post_norm")
            gat_residual_base = gat_emb
            # üîß FIX (2025-10-20): use repeat instead of expand to keep gradient flow
            gat_features = (
                gat_emb.unsqueeze(1).repeat(1, tft_output.size(1), 1).contiguous()
            )
            logger.debug(
                f"[GAT-EXEC] GAT output shape={gat_emb.shape}, repeated={gat_features.shape}"
            )
            # üîß DEBUG (2025-10-06): Verify gat_features status
            logger.debug(f"[GAT-DEBUG] gat_features is None: {gat_features is None}")
            if gat_features is not None:
                logger.debug(
                    f"[GAT-DEBUG] gat_features.shape={gat_features.shape}, requires_grad={gat_features.requires_grad}"
                )
            self._nan_guard(gat_features, "gat_features_expanded")

        # Combine temporal and graph context
        # üîß FIX (2025-10-06): Always use consistent dimensions to prevent backbone_projection recreation
        # When GAT is skipped, pad with zeros to maintain dimension=hidden_size+gat_output_dim
        # üîß DEBUG (2025-10-06): Log which branch is taken
        import logging

        logger = logging.getLogger(__name__)
        logger.debug(
            f"[GAT-DEBUG] Checking concatenation: gat_features is not None = {gat_features is not None}"
        )
        if gat_features is not None:
            logger.debug(
                f"[GAT-DEBUG] Using GAT features branch, combined shape will be {tft_output.size()[-1] + gat_features.size()[-1]}"
            )
            combined_features = torch.cat([tft_output, gat_features], dim=-1)
        else:
            logger.debug("[GAT-DEBUG] Using zero-padding branch")
            # GAT disabled or no edges: pad with zeros to match expected dimension
            if self.gat is not None:
                # GAT exists but not executed: use gat_output_dim for padding
                zero_pad = torch.zeros(
                    tft_output.size(0),
                    tft_output.size(1),
                    self.gat_output_dim,
                    device=tft_output.device,
                    dtype=tft_output.dtype,
                )
                combined_features = torch.cat([tft_output, zero_pad], dim=-1)
            else:
                # GAT completely disabled: no padding needed
                combined_features = tft_output

        # FreqDropoutÈÅ©Áî®Ôºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ
        if self.freq_dropout is not None and self.training:
            combined_features = self.freq_dropout(combined_features)

        # Project back to hidden size
        projected_features = self.backbone_projection(combined_features)
        self._nan_guard(projected_features, "projected_features")

        # Apply adaptive normalization (operates on temporal backbone features)
        normalized_features = self.adaptive_norm(projected_features)
        self._nan_guard(normalized_features, "normalized_features_pre_residual")

        # GAT Residual BypassÈÅ©Áî® (Phase 2) - post-normalization so FAN/SAN do not zero-out GAT signal
        if (
            self.gat is not None
            and gat_residual_base is not None
            and hasattr(self, "gat_residual_gate")
        ):
            alpha = torch.sigmoid(self.gat_residual_gate)
            gat_residual = (
                gat_residual_base.unsqueeze(1)
                .repeat(1, normalized_features.size(1), 1)
                .contiguous()
            )
            if self.gat_residual_clip > 0:
                gat_residual = torch.clamp(
                    gat_residual,
                    -self.gat_residual_clip,
                    self.gat_residual_clip,
                )

            if self.training:
                gate_raw = self.gat_residual_gate.item()
                alpha_val = alpha.item()
                gat_norm = gat_residual.norm().item()
                norm_feat = normalized_features.norm().item()
                logger.info(
                    f"[GAT-FLOW] gate_raw={gate_raw:.4f}, alpha={alpha_val:.4f}, "
                    f"(1-alpha)={1-alpha_val:.4f}, gat_norm={gat_norm:.2e}, "
                    f"norm_feat_norm={norm_feat:.2e}"
                )

            normalized_before = normalized_features
            normalized_features = (
                alpha * normalized_features + (1 - alpha) * gat_residual
            )

            if self.training:
                combined_norm_after = normalized_features.norm().item()
                gat_contribution = ((1 - alpha) * gat_residual).norm().item()
                proj_contribution = (alpha * normalized_before).norm().item()
                logger.info(
                    f"[GAT-FLOW] combined_norm={combined_norm_after:.2e}, "
                    f"gat_contrib={gat_contribution:.2e}, proj_contrib={proj_contribution:.2e}"
                )

            if self.training and hasattr(gat_residual_base, "register_hook"):

                def log_gat_grad(grad):
                    if grad is not None:
                        grad_norm = grad.norm().item()
                        if grad_norm < 1e-8:
                            logger.warning(
                                f"[GAT-GRAD] Low gradient detected: {grad_norm:.2e}"
                            )
                        else:
                            logger.info(f"[GAT-GRAD] gradient norm: {grad_norm:.2e}")

                gat_residual_base.register_hook(log_gat_grad)
        self._nan_guard(normalized_features, "normalized_features_post_residual")
        # üîß DEBUG (2025-10-06): Check gradient flow
        logger.debug(
            f"[GAT-DEBUG] projected_features.requires_grad={projected_features.requires_grad}, normalized.requires_grad={normalized_features.requires_grad}"
        )

        # ‰∫àÊ∏¨ÔºàMulti-horizonÂØæÂøú + „É¨„Ç∏„Éº„É†ÁâπÂæ¥ÈáèÂØæÂøúÔºâ
        if (
            hasattr(self.prediction_head, "forward")
            and "regime_features" in self.prediction_head.forward.__code__.co_varnames
        ):
            # Enhanced RegimeMoE prediction head
            predictions = self.prediction_head(normalized_features, regime_features)
        else:
            # Standard prediction head (backward compatibility)
            predictions = self.prediction_head(normalized_features)

        # Multi-horizon vs single-horizon „ÅÆÁµêÊûúÁµ±‰∏Ä
        if isinstance(predictions, dict):
            # Multi-horizon: {horizon_1d: tensor, horizon_5d: tensor, ...}
            output_type = "multi_horizon"
            predictions = {
                key: self._sanitize_prediction_tensor(val, key)
                for key, val in predictions.items()
            }
        else:
            # Single-horizon (backward compatibility)
            output_type = "single_horizon"
            predictions = {
                "single": self._sanitize_prediction_tensor(predictions, "single")
            }

        # Âá∫Âäõ„Å´„É¨„Ç∏„Éº„É†ÁâπÂæ¥Èáè„ÇÇÂê´„ÇÅ„ÇãÔºàÂàÜÊûêÁî®Ôºâ
        output = {
            "predictions": predictions,
            "features": normalized_features,
            "output_type": output_type,
        }

        if regime_features is not None:
            output["regime_features"] = regime_features

        # MoE„Ç≤„Éº„ÉàÂàÜÊûêÊÉÖÂ†±ÔºàÂà©Áî®ÂèØËÉΩ„Å™Â†¥ÂêàÔºâ
        if hasattr(self.prediction_head, "get_gate_analysis"):
            try:
                gate_analysis = self.prediction_head.get_gate_analysis()
                output["gate_analysis"] = gate_analysis
            except:
                pass

        return output

    def _nan_guard(self, tensor: torch.Tensor | None, name: str) -> None:
        if not self.enable_nan_guard or tensor is None:
            return
        if torch.isfinite(tensor).all():
            return
        nan_count = torch.isnan(tensor).sum().item()
        inf_count = torch.isinf(tensor).sum().item()
        total = tensor.numel()
        if self._nan_guard_counts.get(name, 0) < self.nan_guard_max_log:
            logger.error(
                f"[NAN-GUARD] {name}: non-finite detected "
                f"(nan={nan_count}, inf={inf_count}, total={total})"
            )
            self._nan_guard_counts[name] = self._nan_guard_counts.get(name, 0) + 1
        with torch.no_grad():
            tensor.copy_(torch.nan_to_num(tensor, nan=0.0, posinf=1e6, neginf=-1e6))

    def _sanitize_prediction_tensor(
        self, tensor: torch.Tensor, name: str
    ) -> torch.Tensor:
        if not torch.is_tensor(tensor):
            return tensor
        if not self.enable_nan_guard:
            return torch.nan_to_num(tensor, nan=0.0, posinf=1e6, neginf=-1e6)
        if torch.isfinite(tensor).all():
            return tensor
        self._nan_guard(tensor, f"prediction[{name}]")
        return tensor

    # Removed Lightning callback - will be called manually from training loop if needed
    # def on_train_epoch_start(self) -> None:
    #     if self.curriculum_scheduler is None:
    #         return
    #     phase = self.curriculum_scheduler.get_phase_config(self.current_epoch)
    #     self.curriculum_horizon_weights = phase.horizon_weights
    #     self.curriculum_active_horizons = {f'horizon_{h}d' for h in phase.prediction_horizons}

    def training_step(
        self, batch: dict[str, torch.Tensor], batch_idx: int, current_epoch: int = 0
    ):
        """Â≠¶Áøí„Çπ„ÉÜ„ÉÉ„ÉóÔºàMulti-horizonÂØæÂøúÔºâ

        Args:
            batch: Batch data dictionary
            batch_idx: Batch index
            current_epoch: Current training epoch (replaces self.current_epoch from Lightning)
        """
        # Decision Layer „Çπ„Ç±„Ç∏„É•„Éº„É©Êõ¥Êñ∞Ôºà„Ç®„Éù„ÉÉ„ÇØÈñãÂßãÊôÇ„Å´‰∏ÄÂ∫¶„Å†„ÅëÔºâ
        if (
            hasattr(self, "decision_scheduler")
            and self.decision_scheduler is not None
            and batch_idx == 0
        ):  # „Ç®„Éù„ÉÉ„ÇØ„ÅÆÊúÄÂàù„ÅÆ„Éê„ÉÉ„ÉÅ„Åß„ÅÆ„ÅøÊõ¥Êñ∞
            scheduled_params = self.decision_scheduler.step(
                current_epoch, self.decision_layer
            )
            # Note: scheduled_params logging removed (was Lightning self.log)

        outputs = self.forward(batch)
        predictions = outputs["predictions"]
        output_type = outputs["output_type"]
        targets_map = self._extract_targets(batch)
        if not targets_map and not self._target_warning_logged:
            logger.warning(
                "No target tensors were found in batch; training loss will be zero."
            )
            self._target_warning_logged = True

        total_loss = 0.0
        horizon_losses = {}

        if output_type == "multi_horizon":
            # Multi-horizon training: ÂêÑhorizon„Åß„ÅÆÊêçÂ§±Ë®àÁÆó
            # Horizon weights (curriculumÂÑ™ÂÖà)
            if self.curriculum_horizon_weights:
                horizon_weights = {
                    f"horizon_{h}d": w
                    for h, w in self.curriculum_horizon_weights.items()
                }
            elif hasattr(self.config.training, "prediction") and hasattr(
                self.config.training.prediction, "horizons"
            ):
                horizons_cfg = list(self.config.training.prediction.horizons)
                weight_list = list(
                    getattr(
                        self.config.training.prediction,
                        "horizon_weights",
                        [1.0] * len(horizons_cfg),
                    )
                )
                horizon_weights = {
                    f"horizon_{h}d": w for h, w in zip(horizons_cfg, weight_list)
                }
            else:
                # „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ: ÂæìÊù•„ÅÆË®≠ÂÆö„Åæ„Åü„ÅØ„Éá„Éï„Ç©„É´„Éà
                horizon_weights = getattr(
                    self.config.training,
                    "horizon_weights",
                    {
                        "horizon_1d": 1.0,
                        "horizon_5d": 0.8,
                        "horizon_10d": 0.6,
                        "horizon_20d": 0.4,
                    },
                )

            for horizon_key, pred in predictions.items():
                if (
                    self.curriculum_active_horizons
                    and horizon_key not in self.curriculum_active_horizons
                ):
                    continue

                target_tensor = self._fetch_target_tensor(
                    targets_map, horizon_key, pred
                )
                if target_tensor is None:
                    continue

                # Horizon-specific loss
                horizon_loss = self.quantile_loss(pred, target_tensor)

                # Apply horizon weighting (emphasize short-term)
                weight = horizon_weights.get(horizon_key, 0.5)
                weighted_loss = horizon_loss * weight

                total_loss += weighted_loss
                horizon_losses[f"train_loss_{horizon_key}"] = horizon_loss
                # Note: horizon loss logging removed (was Lightning self.log)

        else:
            # Single-horizon training (backward compatibility)
            target_tensor = next(iter(targets_map.values()), None)
            if target_tensor is None:
                raise RuntimeError(
                    "No target tensor available for single-horizon training"
                )
            target_tensor = target_tensor.to(
                predictions["single"].device, dtype=predictions["single"].dtype
            )
            if target_tensor.dim() > 1:
                target_tensor = target_tensor.squeeze(-1)
            main_loss = self.quantile_loss(predictions["single"], target_tensor)
            total_loss = main_loss
            # Note: main loss logging removed (was Lightning self.log)

        # Auxiliary losses (applied to all horizons)
        if hasattr(self, "sharpe_loss") and output_type == "multi_horizon":
            # Apply Sharpe loss to primary horizon (usually 1d or 5d)
            primary_horizon = getattr(
                self.config.training, "primary_horizon", "horizon_1d"
            )
            if primary_horizon in predictions:
                target_tensor = self._fetch_target_tensor(
                    targets_map, primary_horizon, predictions[primary_horizon]
                )
                if target_tensor is not None:
                    sharpe_loss = self.sharpe_loss(
                        predictions[primary_horizon], target_tensor
                    )
                    total_loss = total_loss + sharpe_loss
                    # Note: sharpe loss logging removed (was Lightning self.log)

        # RankÊêçÂ§±Ôºà‰∏ª„Éõ„É©„Ç§„Ç∫„É≥„ÅÆ‰∏≠Â§ÆÂÄ§„Çπ„Ç≥„Ç¢„Åß„Éö„Ç¢„ÉØ„Ç§„Ç∫Ôºâ
        if (
            output_type == "multi_horizon"
            and self.rank_loss is not None
            and self.rank_loss_weight > 0
        ):
            primary_horizon = getattr(
                self.config.training, "primary_horizon", "horizon_1d"
            )
            if primary_horizon in predictions:
                pred_q = predictions[primary_horizon]
                target_tensor = self._fetch_target_tensor(
                    targets_map, primary_horizon, pred_q
                )
                if (
                    target_tensor is not None
                    and pred_q.dim() == 2
                    and pred_q.size(1) > self._median_q_idx
                ):
                    z = pred_q[:, self._median_q_idx]
                    y = target_tensor.view(-1)
                    rk = self.rank_loss(z.view(-1), y) * self.rank_loss_weight
                    total_loss = total_loss + rk
                    # Note: rank loss logging removed (was Lightning self.log)

        # ÊÑèÊÄùÊ±∫ÂÆöÂ±§„É≠„ÇπÔºà‰∏ª„Éõ„É©„Ç§„Ç∫„É≥„ÅÆÂàÜ‰ΩçÁÇπÔºâ
        if output_type == "multi_horizon" and self.decision_layer is not None:
            primary_horizon = getattr(
                self.config.training, "primary_horizon", "horizon_1d"
            )
            if primary_horizon in predictions:
                q = predictions[primary_horizon]
                target_tensor = self._fetch_target_tensor(
                    targets_map, primary_horizon, q
                )
                if target_tensor is not None:
                    dl_total, comps = self.decision_layer(q, target_tensor.view(-1))
                    total_loss = total_loss + dl_total
                    # Note: decision layer metrics logging removed (was Lightning self.log)

        # Variable selection sparsityÊ≠£ÂâáÂåñ
        if (
            isinstance(self._vsn_sparsity_loss, torch.Tensor)
            and self._vsn_sparsity_loss.numel() > 0
        ):
            total_loss = total_loss + self._vsn_sparsity_loss
            # Note: VSN sparsity logging removed (was Lightning self.log)

        # GATÊ≠£ÂâáÂåñ (edge weight / attention entropy)
        if self.gat is not None:
            # üîß DEBUG (2025-10-07): Log condition checks
            import logging

            logger = logging.getLogger(__name__)
            logger.debug(
                f"[GAT-LOSS-CHECK] edge_reg_value is None: {self._gat_edge_reg_value is None}, is Tensor: {isinstance(self._gat_edge_reg_value, torch.Tensor) if self._gat_edge_reg_value is not None else 'N/A'}, weight > 0: {self.gat_edge_weight > 0}"
            )
            logger.debug(
                f"[GAT-LOSS-CHECK] attention_entropy is None: {self._gat_attention_entropy is None}, is Tensor: {isinstance(self._gat_attention_entropy, torch.Tensor) if self._gat_attention_entropy is not None else 'N/A'}, weight > 0: {self.gat_entropy_weight > 0}"
            )

            if (
                self._gat_edge_reg_value is not None
                and isinstance(self._gat_edge_reg_value, torch.Tensor)
                and self.gat_edge_weight > 0
            ):
                edge_reg = self.gat_edge_weight * self._gat_edge_reg_value
                total_loss = total_loss + edge_reg
                # Note: GAT edge penalty logging removed (was Lightning self.log)
                # üîß DEBUG (2025-10-06): Log GAT edge regularization
                logger.debug(
                    f"[GAT-LOSS] Adding edge_reg={edge_reg.item():.6f} (weight={self.gat_edge_weight})"
                )
            else:
                logger.debug("[GAT-LOSS] Skipping edge_reg (condition not met)")

            if (
                self._gat_attention_entropy is not None
                and isinstance(self._gat_attention_entropy, torch.Tensor)
                and self.gat_entropy_weight > 0
            ):
                entropy_reg = -self.gat_entropy_weight * self._gat_attention_entropy
                total_loss = total_loss + entropy_reg
                # Note: GAT entropy logging removed (was Lightning self.log)
                # üîß DEBUG (2025-10-06): Log GAT entropy regularization
                logger.debug(
                    f"[GAT-LOSS] Adding entropy_reg={entropy_reg.item():.6f} (weight={self.gat_entropy_weight})"
                )
            else:
                logger.debug("[GAT-LOSS] Skipping entropy_reg (condition not met)")

        # Note: train_loss logging removed (was Lightning self.log)

        # MoE load-balanceÊ≠£ÂâáÂåñÔºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ
        try:
            moe_cfg = getattr(self.config.model.prediction_head, "moe", None)
            lb_lambda = (
                float(getattr(moe_cfg, "balance_lambda", 0.0))
                if moe_cfg is not None
                else 0.0
            )
        except Exception:
            lb_lambda = 0.0

        if lb_lambda > 0 and hasattr(self.prediction_head, "last_gate_probs"):
            # Lazy import to avoid cost when not needed
            try:
                from .regime_moe import moe_load_balance_penalty

                lb_loss = lb_lambda * moe_load_balance_penalty(
                    self.prediction_head.last_gate_probs
                )
                total_loss = total_loss + lb_loss
                # Note: MoE load balance loss logging removed (was Lightning self.log)
            except Exception:
                pass

        return total_loss

    def validation_step(self, batch: dict[str, torch.Tensor], batch_idx: int):
        """Ê§úË®º„Çπ„ÉÜ„ÉÉ„ÉóÔºàMulti-horizonÂØæÂøúÔºâ"""
        outputs = self.forward(batch)
        predictions = outputs["predictions"]
        output_type = outputs["output_type"]
        targets_map = self._extract_targets(batch)

        total_loss = 0.0

        if output_type == "multi_horizon":
            # Multi-horizon validation
            for horizon_key, pred in predictions.items():
                if (
                    self.curriculum_active_horizons
                    and horizon_key not in self.curriculum_active_horizons
                ):
                    continue
                target_tensor = self._fetch_target_tensor(
                    targets_map, horizon_key, pred
                )
                if target_tensor is None:
                    continue

                val_loss = self.quantile_loss(pred, target_tensor)
                total_loss += val_loss
                # Note: individual horizon validation loss logging removed (was Lightning self.log)

        else:
            # Single-horizon validation
            target_tensor = next(iter(targets_map.values()), None)
            if target_tensor is None:
                raise RuntimeError(
                    "No target tensor available for single-horizon validation"
                )
            target_tensor = target_tensor.to(
                predictions["single"].device, dtype=predictions["single"].dtype
            )
            if target_tensor.dim() > 1:
                target_tensor = target_tensor.squeeze(-1)
            val_loss = self.quantile_loss(predictions["single"], target_tensor)
            total_loss = val_loss

        # Note: val_loss logging removed (was Lightning self.log)
        return total_loss

    def _calculate_financial_metrics(
        self, predictions: torch.Tensor, targets: torch.Tensor
    ):
        """ÈáëËûçÊåáÊ®ô„ÅÆË®àÁÆó"""
        # SharpeÊØî
        returns = targets.mean(dim=-1)  # ÂêÑ„Éõ„É©„Ç§„Ç∫„É≥„ÅÆÂπ≥Âùá
        if returns.std() > 0:
            sharpe = returns.mean() / returns.std() * torch.sqrt(torch.tensor(252.0))
        else:
            sharpe = torch.tensor(0.0)

        # ÊúÄÂ§ß„Éâ„É≠„Éº„ÉÄ„Ç¶„É≥ÔºàÁ∞°ÊòìË®àÁÆóÔºâ
        cumulative_returns = torch.cumprod(1 + returns, dim=0)
        running_max = torch.maximum.accumulate(cumulative_returns)
        drawdown = (cumulative_returns - running_max) / running_max
        max_drawdown = drawdown.min()

        # ÂãùÁéá
        pred_direction = (predictions > 0).float()
        true_direction = (targets > 0).float()
        hit_rate = (pred_direction == true_direction).float().mean()

        return {
            "sharpe_ratio": sharpe,
            "max_drawdown": max_drawdown,
            "hit_rate": hit_rate,
        }

    # NOTE: configure_optimizers was a Lightning-specific method.
    # Optimizer and scheduler creation has been moved to train_atft.py.
    # This method is no longer used when running with standard PyTorch training loop.
    #
    # def configure_optimizers(self):
    #     """„Ç™„Éó„ÉÜ„Ç£„Éû„Ç§„Ç∂„Éº„ÅÆË®≠ÂÆö - DEPRECATED, moved to train_atft.py"""
    #     pass


class PredictionHead(nn.Module):
    """ÊîπÂñÑÁâà‰∫àÊ∏¨„Éò„ÉÉ„ÉâÔºàsingle-horizonÁî®„ÄÅbackward compatibilityÔºâ"""

    def __init__(
        self,
        hidden_size: int,
        config: DictConfig,
        output_std: float = 0.01,
        layer_scale_gamma: float = 0.1,
    ):
        super().__init__()
        self.config = config

        # Èö†„ÇåÂ±§
        layers = []
        current_size = hidden_size
        for hidden_dim in config.architecture.hidden_layers:
            layers.extend(
                [
                    nn.Linear(current_size, hidden_dim),
                    nn.ReLU(),
                    nn.Dropout(config.architecture.dropout),
                ]
            )
            current_size = hidden_dim

        # Âá∫ÂäõÂ±§ÔºàÊîπÂñÑÁâàÂàùÊúüÂåñÔºâ
        quantiles = config.output.quantile_prediction.quantiles
        self.output_layer = nn.Linear(current_size, len(quantiles))

        # small-init + zero bias
        nn.init.trunc_normal_(self.output_layer.weight, std=output_std)
        nn.init.zeros_(self.output_layer.bias)

        # LayerScale
        self.layer_scale = nn.Parameter(torch.ones(len(quantiles)) * layer_scale_gamma)

        self.layers = nn.Sequential(*layers)

    def forward(self, x: torch.Tensor):
        # ÊúÄÂæå„ÅÆ„Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó„Çí‰ΩøÁî®
        x = x[:, -1, :]  # [batch, hidden_size]

        # Èö†„ÇåÂ±§Âá¶ÁêÜ
        x = self.layers(x)

        # Âá∫Âäõ + LayerScale
        output = self.output_layer(x)
        return output * self.layer_scale


class MultiHorizonPredictionHeads(nn.Module):
    """Multi-horizon prediction heads - ÂêÑ‰∫àÊ∏¨ÊúüÈñìÂ∞ÇÁî®„ÅÆÂá∫ÂäõÂ±§"""

    def __init__(
        self,
        hidden_size: int,
        config: DictConfig,
        training_cfg: DictConfig | None = None,
        output_std: float = 0.01,
        layer_scale_gamma: float = 0.1,
    ):
        super().__init__()
        self.config = config

        # ‰∫àÊ∏¨ÂØæË±°ÊúüÈñì„ÅÆË®≠ÂÆö (Êñ∞„Åó„ÅÑconfigÊßãÈÄ†„Çí„Çµ„Éù„Éº„Éà)
        self._training_cfg = training_cfg or getattr(config, "training", None)

        def _extract_horizons(cfg: DictConfig | None) -> list[int] | None:
            if cfg is None:
                return None
            try:
                if hasattr(cfg, "prediction") and hasattr(cfg.prediction, "horizons"):
                    return list(int(h) for h in cfg.prediction.horizons)
                if hasattr(cfg, "prediction_horizons"):
                    return list(int(h) for h in cfg.prediction_horizons)
            except Exception:
                return None
            return None

        horizons = _extract_horizons(self._training_cfg)
        if horizons is None:
            horizons = _extract_horizons(getattr(config, "training", None))
        if horizons is None and hasattr(config, "prediction_horizons"):
            try:
                horizons = list(int(h) for h in config.prediction_horizons)
            except Exception:
                horizons = None
        if horizons is None:
            horizons = [1, 5, 10, 20]

        self.prediction_horizons = horizons

        # ÂÖ±ÊúâÁâπÂæ¥ÊäΩÂá∫Â±§ÔºàÂêÑhorizon„ÅßÂÖ±Êúâ„Åï„Çå„Çã‰∏≠ÈñìË°®ÁèæÔºâ
        self.shared_encoder = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(config.architecture.dropout),
            nn.LayerNorm(hidden_size // 2),
        )

        # ÂêÑhorizonÂ∞ÇÁî®„ÅÆÂá∫Âäõ„Éò„ÉÉ„Éâ
        self.horizon_heads = nn.ModuleDict()
        quantiles = config.output.quantile_prediction.quantiles

        for horizon in self.prediction_horizons:
            # Horizon-specific architecture
            horizon_layers = []
            current_size = hidden_size // 2

            # HorizonÂ∞ÇÁî®„ÅÆÈö†„ÇåÂ±§ÔºàÁü≠Êúü„Å®Èï∑Êúü„ÅßÁï∞„Å™„ÇãarchitectureÔºâ
            if horizon <= 5:  # Short-term horizons (1d, 5d)
                # „Çà„ÇäÁ¥∞„Åã„ÅÑÁâπÂæ¥ÊäΩÂá∫ - „Éé„Ç§„Ç∫„ÅåÈáçË¶Å
                horizon_layers.extend(
                    [
                        nn.Linear(current_size, current_size),
                        nn.ReLU(),
                        nn.Dropout(
                            config.architecture.dropout * 0.5
                        ),  # Lower dropout for short-term
                    ]
                )
            else:  # Long-term horizons (10d, 20d)
                # „Çà„Çä„Çπ„É†„Éº„Ç∫„Å™ÁâπÂæ¥ÊäΩÂá∫ - „Éà„É¨„É≥„Éâ„ÅåÈáçË¶Å
                horizon_layers.extend(
                    [
                        nn.Linear(current_size, current_size // 2),
                        nn.ReLU(),
                        nn.Dropout(
                            config.architecture.dropout * 1.5
                        ),  # Higher dropout for long-term
                        nn.Linear(current_size // 2, current_size),
                        nn.ReLU(),
                    ]
                )

            # ÊúÄÁµÇÂá∫ÂäõÂ±§
            horizon_layers.append(nn.Linear(current_size, len(quantiles)))

            # Initialize head
            head = nn.Sequential(*horizon_layers)

            # Horizon-specific initialization
            for layer in head:
                if isinstance(layer, nn.Linear):
                    # Short-term: smaller init (less certainty)
                    # Long-term: larger init (more trend confidence)
                    std = output_std * (0.5 if horizon <= 5 else 1.0)
                    nn.init.trunc_normal_(layer.weight, std=std)
                    nn.init.zeros_(layer.bias)

            self.horizon_heads[f"horizon_{horizon}d"] = head

        # Horizon-specific LayerScale parameters
        self.layer_scales = nn.ParameterDict()
        for horizon in self.prediction_horizons:
            # Short-term: smaller scale (less confident)
            # Long-term: larger scale (more trend confident)
            scale = layer_scale_gamma * (0.8 if horizon <= 5 else 1.2)
            self.layer_scales[f"horizon_{horizon}d"] = nn.Parameter(
                torch.ones(len(quantiles)) * scale
            )

    def forward(self, x: torch.Tensor) -> dict[str, torch.Tensor]:
        """
        Args:
            x: [batch_size, sequence_length, hidden_size]

        Returns:
            Dictionary mapping horizon names to predictions
            {
                'horizon_1d': [batch_size, n_quantiles],
                'horizon_5d': [batch_size, n_quantiles],
                'horizon_10d': [batch_size, n_quantiles],
                'horizon_20d': [batch_size, n_quantiles],
            }
        """
        # ÊúÄÂæå„ÅÆ„Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó„Çí‰ΩøÁî® (3D input) or „Åù„ÅÆ„Åæ„Åæ‰ΩøÁî® (2D input)
        if x.dim() == 3:
            x = x[:, -1, :]  # [batch_size, hidden_size]
        elif x.dim() == 2:
            pass  # Already [batch_size, hidden_size]
        else:
            raise ValueError(f"Expected 2D or 3D input, got {x.dim()}D")

        # ÂÖ±Êúâ„Ç®„É≥„Ç≥„Éº„ÉÄ„Åß‰∏≠ÈñìË°®Áèæ„ÇíÁç≤Âæó
        shared_features = self.shared_encoder(x)  # [batch_size, hidden_size//2]

        # ÂêÑhorizonÂ∞ÇÁî®„Éò„ÉÉ„Éâ„Åß‰∫àÊ∏¨
        predictions = {}
        for horizon in self.prediction_horizons:
            horizon_key = f"horizon_{horizon}d"

            # HorizonÂ∞ÇÁî®„ÅÆÂá¶ÁêÜ
            horizon_output = self.horizon_heads[horizon_key](shared_features)

            # LayerScaleÈÅ©Áî®
            scaled_output = horizon_output * self.layer_scales[horizon_key]

            predictions[horizon_key] = scaled_output

        return predictions

    def get_single_horizon_prediction(
        self, x: torch.Tensor, horizon: int
    ) -> torch.Tensor:
        """ÁâπÂÆö„ÅÆhorizon„ÅÆ‰∫àÊ∏¨„ÅÆ„Åø„ÇíÂèñÂæóÔºàÂäπÁéáÁöÑÔºâ"""
        x = x[:, -1, :]
        shared_features = self.shared_encoder(x)

        horizon_key = f"horizon_{horizon}d"
        if horizon_key not in self.horizon_heads:
            raise ValueError(
                f"Horizon {horizon}d not supported. Available: {list(self.horizon_heads.keys())}"
            )

        horizon_output = self.horizon_heads[horizon_key](shared_features)
        return horizon_output * self.layer_scales[horizon_key]


class QuantileLoss(nn.Module):
    """Quantile Loss"""

    def __init__(self, quantiles: list[float]):
        super().__init__()
        self.quantiles = torch.tensor(quantiles)

    def forward(self, predictions: torch.Tensor, targets: torch.Tensor):
        # Á∞°ÊòìÁöÑ„Å™Quantile LossÂÆüË£Ö
        errors = targets.unsqueeze(-1) - predictions
        quantile_loss = torch.maximum(
            self.quantiles * errors, (self.quantiles - 1) * errors
        )
        return quantile_loss.mean()


class SharpeLoss(nn.Module):
    """SharpeÊØîÊúÄÂ§ßÂåñÊêçÂ§±"""

    def __init__(self, weight: float = 0.1, min_periods: int = 20):
        super().__init__()
        self.weight = weight
        self.min_periods = min_periods

    def forward(self, predictions: torch.Tensor, targets: torch.Tensor):
        # Á∞°ÊòìÁöÑ„Å™SharpeÊØîË®àÁÆó
        returns = targets.mean(dim=-1)
        if len(returns) >= self.min_periods and returns.std() > 0:
            sharpe = returns.mean() / returns.std()
            # SharpeÊØî„ÇíÊúÄÂ§ßÂåñ„Åô„Çã„Åü„ÇÅ„ÅÆÊêçÂ§±ÔºàË≤†„ÅÆSharpeÊØîÔºâ
            return -self.weight * sharpe
        else:
            return torch.tensor(0.0)
