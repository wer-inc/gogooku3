#!/usr/bin/env python3
# DEPRECATED: Moved to scripts/_archive on 2025-09-04
"""
TOPIXå¸‚å ´ç‰¹å¾´é‡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å¸‚å ´ç‰¹å¾´é‡ã®æ€§èƒ½æ”¹å–„ã‚’è©•ä¾¡:
- RankIC@1d, 3d ã®æ”¹å–„ç‡æ¸¬å®š
- Î±ç³»åˆ—ã®æœ‰åŠ¹æ€§ç¢ºèªï¼ˆç›¸é–¢åˆ†æï¼‰
- ãƒ¬ã‚¸ãƒ¼ãƒ ãƒ•ãƒ©ã‚°ã®äºˆæ¸¬åŠ›æ¤œè¨¼

ä½¿ç”¨æ–¹æ³•:
python scripts/benchmark_market_features.py --data-path data/processed/ml_dataset_enhanced.parquet
"""

import argparse
import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Any

import numpy as np
import pandas as pd
import polars as pl

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class MarketFeaturesBenchmark:
    """å¸‚å ´ç‰¹å¾´é‡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã‚¯ãƒ©ã‚¹"""

    def __init__(self, data_path: Path, output_dir: Path = None):
        """
        Args:
            data_path: è©•ä¾¡å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.data_path = Path(data_path)
        self.output_dir = output_dir or Path("benchmark_results")
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # çµæœä¿å­˜ç”¨
        self.results = {
            'timestamp': datetime.now().isoformat(),
            'data_info': {},
            'rank_ic_analysis': {},
            'feature_importance': {},
            'regime_effectiveness': {},
            'performance_summary': {}
        }

    def run_full_benchmark(self) -> dict[str, Any]:
        """ãƒ•ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        logger.info("ğŸš€ Starting TOPIX Market Features Benchmark")

        # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        df = self.load_data()
        self.results['data_info'] = self.analyze_data_info(df)

        # 2. RankICåˆ†æ
        self.results['rank_ic_analysis'] = self.analyze_rank_ic(df)

        # 3. ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ
        self.results['feature_importance'] = self.analyze_feature_importance(df)

        # 4. ãƒ¬ã‚¸ãƒ¼ãƒ æœ‰åŠ¹æ€§åˆ†æ
        self.results['regime_effectiveness'] = self.analyze_regime_effectiveness(df)

        # 5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼
        self.results['performance_summary'] = self.create_performance_summary()

        # 6. çµæœä¿å­˜
        self.save_results()

        logger.info("âœ… Benchmark completed successfully")
        return self.results

    def load_data(self) -> pl.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        logger.info(f"Loading data from {self.data_path}")

        if self.data_path.suffix == '.parquet':
            df = pl.read_parquet(self.data_path)
        elif self.data_path.suffix == '.csv':
            df = pl.read_csv(self.data_path)
        else:
            raise ValueError(f"Unsupported file format: {self.data_path.suffix}")

        logger.info(f"Loaded {len(df)} rows, {len(df.columns)} columns")
        return df

    def analyze_data_info(self, df: pl.DataFrame) -> dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æƒ…å ±åˆ†æ"""
        info = {
            'total_rows': len(df),
            'total_features': len(df.columns),
            'date_range': {
                'start': df.select('date').min().item().isoformat(),
                'end': df.select('date').max().item().isoformat()
            },
            'unique_stocks': df.select('Code').nunique(),
            'market_features_count': len([col for col in df.columns if col.startswith('mkt_')]),
            'cross_features_count': len([col for col in df.columns if col.startswith(('beta_', 'alpha_', 'rel_'))]),
            'target_features': [col for col in df.columns if 'target_' in col]
        }

        logger.info(f"Data analysis: {info['unique_stocks']} stocks, {info['market_features_count']} market features")
        return info

    def analyze_rank_ic(self, df: pl.DataFrame) -> dict[str, Any]:
        """RankICåˆ†æ"""
        logger.info("Analyzing RankIC performance")

        results = {}

        # åˆ©ç”¨å¯èƒ½ãªã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ç¢ºèª
        target_cols = [col for col in df.columns if col.startswith('target_')]
        market_features = [col for col in df.columns if col.startswith(('mkt_', 'beta_', 'alpha_', 'rel_'))]

        if not target_cols:
            logger.warning("No target columns found for RankIC analysis")
            return results

        # å„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«å¯¾ã—ã¦RankICã‚’è¨ˆç®—
        for target_col in target_cols:
            if target_col not in df.columns:
                continue

            target_results = {}

            # å¸‚å ´ç‰¹å¾´é‡ã¨ã®RankIC
            market_ic_results = []
            for feature in market_features:
                if feature in df.columns:
                    ic = self.calculate_rank_ic(df, feature, target_col)
                    if ic is not None:
                        market_ic_results.append({
                            'feature': feature,
                            'ic': ic,
                            'abs_ic': abs(ic)
                        })

            # æœ€ã‚‚ç›¸é–¢ã®é«˜ã„ç‰¹å¾´é‡ãƒˆãƒƒãƒ—10
            market_ic_results.sort(key=lambda x: x['abs_ic'], reverse=True)
            target_results['top_market_features'] = market_ic_results[:10]

            # RankICçµ±è¨ˆ
            if market_ic_results:
                ic_values = [r['ic'] for r in market_ic_results]
                target_results['market_ic_stats'] = {
                    'mean': np.mean(ic_values),
                    'std': np.std(ic_values),
                    'max': max(ic_values),
                    'min': min(ic_values),
                    'significant_count': sum(1 for ic in ic_values if abs(ic) > 0.05)
                }

            results[target_col] = target_results

        return results

    def calculate_rank_ic(self, df: pl.DataFrame, feature_col: str, target_col: str,
                         min_periods: int = 50) -> float | None:
        """RankICè¨ˆç®—"""
        try:
            # æ—¥ä»˜ã”ã¨ã«RankICã‚’è¨ˆç®—
            ic_values = []

            # æ—¥ä»˜ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            for date_group in df.group_by('date'):
                date_data = date_group[1]

                # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ç¢ºèª
                if len(date_data) < min_periods:
                    continue

                # æ¬ æå€¤é™¤å»
                valid_data = date_data.select([feature_col, target_col]).drop_nulls()
                if len(valid_data) < min_periods:
                    continue

                # ãƒ©ãƒ³ã‚¯ç›¸é–¢ä¿‚æ•°è¨ˆç®—
                feature_vals = valid_data.select(feature_col).to_series().to_numpy()
                target_vals = valid_data.select(target_col).to_series().to_numpy()

                # ãƒ©ãƒ³ã‚¯ã«å¤‰æ›
                feature_ranks = pd.Series(feature_vals).rank(method='average')
                target_ranks = pd.Series(target_vals).rank(method='average')

                # ç›¸é–¢ä¿‚æ•°
                corr = feature_ranks.corr(target_ranks)
                if not np.isnan(corr):
                    ic_values.append(corr)

            # å¹³å‡RankICã‚’è¿”ã™
            if ic_values:
                return np.mean(ic_values)
            else:
                return None

        except Exception as e:
            logger.error(f"Error calculating RankIC for {feature_col}: {e}")
            return None

    def analyze_feature_importance(self, df: pl.DataFrame) -> dict[str, Any]:
        """ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ"""
        logger.info("Analyzing feature importance")

        results = {}

        # åˆ©ç”¨å¯èƒ½ãªã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ç¢ºèª
        target_cols = [col for col in df.columns if col.startswith('target_')]
        market_features = [col for col in df.columns if col.startswith(('mkt_', 'beta_', 'alpha_', 'rel_'))]

        if not target_cols or not market_features:
            return results

        # å„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«å¯¾ã™ã‚‹ç‰¹å¾´é‡é‡è¦åº¦
        for target_col in target_cols:
            if target_col not in df.columns:
                continue

            # ç‰¹å¾´é‡é‡è¦åº¦ã®æ¨å®šï¼ˆç›¸é–¢ä¿‚æ•°ã®çµ¶å¯¾å€¤ã‚’ä½¿ç”¨ï¼‰
            importance_scores = []
            for feature in market_features:
                if feature in df.columns:
                    ic = self.calculate_rank_ic(df, feature, target_col)
                    if ic is not None:
                        importance_scores.append({
                            'feature': feature,
                            'importance': abs(ic),
                            'ic': ic
                        })

            # é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆ
            importance_scores.sort(key=lambda x: x['importance'], reverse=True)

            results[target_col] = {
                'top_features': importance_scores[:20],  # ãƒˆãƒƒãƒ—20
                'importance_distribution': {
                    'high_importance': sum(1 for s in importance_scores if s['importance'] > 0.1),
                    'medium_importance': sum(1 for s in importance_scores if 0.05 <= s['importance'] <= 0.1),
                    'low_importance': sum(1 for s in importance_scores if s['importance'] < 0.05)
                }
            }

        return results

    def analyze_regime_effectiveness(self, df: pl.DataFrame) -> dict[str, Any]:
        """ãƒ¬ã‚¸ãƒ¼ãƒ æœ‰åŠ¹æ€§åˆ†æ"""
        logger.info("Analyzing regime effectiveness")

        results = {}

        # ãƒ¬ã‚¸ãƒ¼ãƒ ãƒ•ãƒ©ã‚°ã‚’ç¢ºèª
        regime_flags = ['mkt_bull_200', 'mkt_trend_up', 'mkt_high_vol', 'mkt_squeeze']
        available_regimes = [flag for flag in regime_flags if flag in df.columns]

        if not available_regimes:
            logger.warning("No regime flags found")
            return results

        # å„ãƒ¬ã‚¸ãƒ¼ãƒ ã®æœ‰åŠ¹æ€§ã‚’åˆ†æ
        for regime in available_regimes:
            regime_results = {}

            # ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ã®ãƒªã‚¿ãƒ¼ãƒ³åˆ†å¸ƒ
            regime_data = df.select([regime, 'return_1d', 'mkt_ret_1d']).drop_nulls()

            if len(regime_data) == 0:
                continue

            # ãƒ¬ã‚¸ãƒ¼ãƒ ON/OFFã§ã®çµ±è¨ˆ
            regime_on = regime_data.filter(pl.col(regime) == 1)
            regime_off = regime_data.filter(pl.col(regime) == 0)

            if len(regime_on) > 0 and len(regime_off) > 0:
                regime_results['return_stats'] = {
                    'regime_on': {
                        'mean_return': regime_on.select('return_1d').mean().item(),
                        'volatility': regime_on.select('return_1d').std().item(),
                        'count': len(regime_on)
                    },
                    'regime_off': {
                        'mean_return': regime_off.select('return_1d').mean().item(),
                        'volatility': regime_off.select('return_1d').std().item(),
                        'count': len(regime_off)
                    }
                }

                # ãƒ¬ã‚¸ãƒ¼ãƒ ã®äºˆæ¸¬åŠ›ï¼ˆå¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ã®å·®ï¼‰
                return_diff = (regime_results['return_stats']['regime_on']['mean_return'] -
                             regime_results['return_stats']['regime_off']['mean_return'])

                regime_results['predictive_power'] = {
                    'return_difference': return_diff,
                    'effect_size': abs(return_diff) / regime_off.select('return_1d').std().item()
                }

            results[regime] = regime_results

        return results

    def create_performance_summary(self) -> dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼ä½œæˆ"""
        summary = {
            'market_features_count': self.results['data_info'].get('market_features_count', 0),
            'cross_features_count': self.results['data_info'].get('cross_features_count', 0),
            'rank_ic_insights': {},
            'regime_insights': {},
            'recommendations': []
        }

        # RankICåˆ†æã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        rank_ic_data = self.results.get('rank_ic_analysis', {})
        if rank_ic_data:
            summary['rank_ic_insights'] = {
                'targets_analyzed': len(rank_ic_data),
                'significant_features_found': sum(
                    len(target_data.get('market_ic_stats', {}).get('significant_count', 0))
                    for target_data in rank_ic_data.values()
                )
            }

        # ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†æã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        regime_data = self.results.get('regime_effectiveness', {})
        if regime_data:
            predictive_regimes = [
                regime for regime, data in regime_data.items()
                if data.get('predictive_power', {}).get('effect_size', 0) > 0.1
            ]
            summary['regime_insights'] = {
                'effective_regimes': predictive_regimes,
                'effectiveness_count': len(predictive_regimes)
            }

        # ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
        if summary['market_features_count'] >= 24:
            summary['recommendations'].append("âœ… å¸‚å ´ç‰¹å¾´é‡ãŒååˆ†ã«å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™")
        else:
            summary['recommendations'].append("âš ï¸ å¸‚å ´ç‰¹å¾´é‡ã®æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™")

        if summary['cross_features_count'] >= 8:
            summary['recommendations'].append("âœ… ã‚¯ãƒ­ã‚¹ç‰¹å¾´é‡ãŒååˆ†ã«å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™")
        else:
            summary['recommendations'].append("âš ï¸ ã‚¯ãƒ­ã‚¹ç‰¹å¾´é‡ã®æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™")

        significant_features = summary['rank_ic_insights'].get('significant_features_found', 0)
        if significant_features > 10:
            summary['recommendations'].append(f"âœ… {significant_features}å€‹ã®æœ‰æ„ãªç‰¹å¾´é‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        else:
            summary['recommendations'].append(f"âš ï¸ æœ‰æ„ãªç‰¹å¾´é‡ãŒå°‘ãªã„ã§ã™ï¼ˆ{significant_features}å€‹ï¼‰")

        return summary

    def save_results(self):
        """çµæœä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result_file = self.output_dir / f"market_features_benchmark_{timestamp}.json"

        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False, default=str)

        logger.info(f"Results saved to {result_file}")

        # ç°¡æ˜“ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
        self.print_summary_report()

    def print_summary_report(self):
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›"""
        print("\n" + "="*70)
        print("ğŸ“Š TOPIXå¸‚å ´ç‰¹å¾´é‡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ")
        print("="*70)

        data_info = self.results.get('data_info', {})
        print("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿æƒ…å ±:")
        print(f"   â€¢ ç·è¡Œæ•°: {data_info.get('total_rows', 0):,}")
        print(f"   â€¢ ç‰¹å¾´é‡æ•°: {data_info.get('total_features', 0)}")
        print(f"   â€¢ éŠ˜æŸ„æ•°: {data_info.get('unique_stocks', 0)}")
        print(f"   â€¢ å¸‚å ´ç‰¹å¾´é‡: {data_info.get('market_features_count', 0)}")
        print(f"   â€¢ ã‚¯ãƒ­ã‚¹ç‰¹å¾´é‡: {data_info.get('cross_features_count', 0)}")

        rank_ic = self.results.get('rank_ic_analysis', {})
        if rank_ic:
            print("\nğŸ¯ RankICåˆ†æ:")
            for target, data in rank_ic.items():
                stats = data.get('market_ic_stats', {})
                if stats:
                    print(f"   â€¢ {target}: å¹³å‡IC={stats.get('mean', 0):.4f}, æœ‰æ„ç‰¹å¾´é‡={stats.get('significant_count', 0)}")

        regime = self.results.get('regime_effectiveness', {})
        if regime:
            print("\nâš¡ ãƒ¬ã‚¸ãƒ¼ãƒ æœ‰åŠ¹æ€§:")
            for regime_name, data in regime.items():
                power = data.get('predictive_power', {})
                effect_size = power.get('effect_size', 0)
                if effect_size > 0.1:
                    print(f"   â€¢ {regime_name}: åŠ¹æœé‡={effect_size:.3f} âœ…")
                else:
                    print(f"   â€¢ {regime_name}: åŠ¹æœé‡={effect_size:.3f}")

        recommendations = self.results.get('performance_summary', {}).get('recommendations', [])
        if recommendations:
            print("\nğŸ’¡ ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³:")
            for rec in recommendations:
                print(f"   â€¢ {rec}")

        print("="*70)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description='TOPIXå¸‚å ´ç‰¹å¾´é‡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡')
    parser.add_argument('--data-path', type=str, required=True,
                       help='è©•ä¾¡å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹')
    parser.add_argument('--output-dir', type=str, default='benchmark_results',
                       help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')

    args = parser.parse_args()

    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    benchmark = MarketFeaturesBenchmark(
        data_path=args.data_path,
        output_dir=Path(args.output_dir)
    )

    benchmark.run_full_benchmark()

    logger.info("Benchmark completed successfully!")


if __name__ == "__main__":
    main()
