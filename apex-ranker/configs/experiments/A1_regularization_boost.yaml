# Experiment A1: Regularization Boost
# Purpose: Suppress overfitting with increased dropout + weight_decay
# Expected: Improved generalization, Sharpe recovery toward v0_enhanced level

version: 0
description: "A1: 89 features + dropout 0.3 + wd 5e-4 (regularization boost)"

data:
  parquet_path: output/ml_dataset_latest_clean_with_adv.parquet
  metadata_path: null
  feature_groups_config: apex-ranker/configs/feature_groups_v0_latest_89.yaml
  feature_aliases_yaml: apex-ranker/configs/feature_aliases_compat.yaml
  feature_groups:
  - core50
  - plus30
  - dmi_focus
  optional_groups: []
  use_plus30: false
  lookback: 180
  min_stocks_per_day: 80
  date_column: Date
  code_column: Code
  target_columns:
    1: target_1d
    5: target_5d
    10: target_10d
    20: target_20d

normalization:
  mode: cross_section_z
  clip_sigma: 5.0

train:
  horizons:
  - 1
  - 5
  - 10
  - 20
  epochs: 50
  lr: 0.0005
  weight_decay: 0.0005  # INCREASED from 1e-4 to 5e-4
  grad_clip: 0.5
  val_days: 120
  log_interval: 10
  amp: true
  device: auto
  num_workers: 0
  warmup_epochs: 3
  warmup_start_factor: 0.1
  early_stopping:
    patience: 5  # Increased patience for regularized training
    metric: 20d_pak
    min_delta: 0.0
  evaluation:
    splitter: purged_kfold
    purged_kfold:
      n_splits: 5
      embargo_days: 5
  time_decay_tau_days: 120
  use_ema: true
  ema_beta: 0.999

eval:
  k_ratio: 0.10
  ndcg_beta: 1.0
  es_weights: "0.6,0.3,0.1"

selection:
  default:
    k_ratio: 0.60
    k_min: 53
    sign: 1
  horizons:
    "5":
      k_ratio: 0.60
      k_min: 53
      sign: 1
    "10":
      k_ratio: 0.60
      k_min: 53
      sign: 1
    "20":
      k_ratio: 0.60
      k_min: 53
      sign: 1

model:
  d_model: 256
  depth: 4
  patch_len: 16
  stride: 8
  n_heads: 8
  dropout: 0.3  # INCREASED from 0.2 to 0.3

loss:
  listnet:
    weight: 1.0
    tau: 0.4
    topk: null
  ranknet:
    weight: 0.5
    neg_sample: 4096
  mse:
    weight: 0.1
  turnover:
    weight: 0.001
