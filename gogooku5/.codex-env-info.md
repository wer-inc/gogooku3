# Current Environment Information (gogooku5)
# Auto-generated by Codex Launcher - Fri Nov 21 06:17:07 UTC 2025

## Hardware & Software
- **Python**: 3.12.3
- **PyTorch**: 2.8.0+cu128 (CUDA Available: True)
- **GPU**: NVIDIA A100-SXM4-80GB
- **CUDA Version**: 12.4
- **GPU Memory**: 1MB used / 81920MB total (0% utilization)
- **Available GPU Memory**: 81919MB
- **CPU**: 255 cores (AMD EPYC 7763 64-Core Processor)
- **RAM**: 1.8Ti available / 2.0Ti total
- **Disk**: 589T available (75% used)

## Optimization Opportunities
- GPU utilization is 0% - consider increasing batch size or enabling GPU-ETL
- 81919MB GPU memory available - can support larger models or batch sizes
- CUDA 12.4 detected - RAPIDS/cuDF GPU-ETL available

âœ… Project health check passed
System is healthy. Consider proactive optimization opportunities.

## Project Structure (gogooku5)
- **Root**: /workspace/gogooku3/gogooku5
- **Dataset Builder**: data/src/builder/pipelines/dataset_builder.py
- **CLI Interface**: data/src/cli/main.py
- **APEX-Ranker**: models/apex_ranker/
- **Documentation**: CLAUDE.md, AGENTS.md, MIGRATION_PLAN.md
- **Health Check**: tools/health-check.sh

## Key Workflows

### Dataset Generation
```bash
# From project root
make -C data build START=2024-01-01 END=2024-12-31

# Or with CLI
PYTHONPATH=data/src python -m cli.main build --start 2024-01-01 --end 2024-12-31
```

### Model Training (APEX-Ranker)
```bash
make -C models/apex_ranker train
```

### Dagster Orchestration
```bash
export DAGSTER_HOME=/workspace/gogooku3/gogooku5
PYTHONPATH=data/src dagster dev -m dagster_gogooku5.defs
```

---
*Note: Read .codex-env-info.md for current environment details*
