#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿å“è³ªã‚²ãƒ¼ãƒˆ & ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°

å“è³ªåŸºæº–:
- ä¾¡æ ¼ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆmin_price >= 100å††ï¼‰
- ãƒªã‚¿ãƒ¼ãƒ³ç•°å¸¸å€¤é™¤å¤–ï¼ˆ|ret_1d| <= max_ret_1dï¼‰
- ADV60ï¼ˆå¹³å‡å£²è²·ä»£é‡‘60æ—¥ã€å½“æ—¥é™¤å¤–ï¼‰>= min_adv
- æ ªä¾¡ãƒ•ãƒªãƒ¼ã‚ºæ¤œå‡ºï¼ˆåŒå€¤é€£ç¶š5æ—¥ä»¥ä¸Šã®å‰Šæ¸›ç¢ºèªï¼‰

Usage:
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰
    python scripts/filter_dataset_quality.py

    # ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ã‚¹æŒ‡å®š
    python scripts/filter_dataset_quality.py \
      --input output/ml_dataset_latest_full.parquet \
      --output output/ml_dataset_clean.parquet \
      --min-price 100 \
      --max-ret-1d 0.15 \
      --min-adv 50000000 \
      --report output/reports/quality_report.json
"""

from __future__ import annotations

import argparse
import json
import sys
from pathlib import Path

import polars as pl

# ãƒ‘ã‚¹å®šæ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ã—ã¦ä½¿ç”¨ï¼‰
try:
    from path_constants import DATASET_CLEAN, DATASET_RAW, QUALITY_REPORT
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: path_constants.py ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    DATASET_RAW = "output/ml_dataset_latest_full.parquet"
    DATASET_CLEAN = "output/ml_dataset_clean.parquet"
    QUALITY_REPORT = "output/reports/quality_report.json"

# åˆ—åå€™è£œï¼ˆè‡ªå‹•æ¤œå‡ºç”¨ï¼‰
CAND_CODE = ["code", "Code", "ticker", "symbol"]
CAND_DATE = ["timestamp", "trading_date", "date", "Date"]
CAND_PRICE = ["adj_close", "AdjClose", "close", "Close"]
CAND_VOLUME = ["volume", "Volume"]
CAND_TURNOVER = ["turnover", "TurnoverValue", "turnover_value"]


def detect_column(df: pl.DataFrame, candidates: list[str], name: str) -> str:
    """åˆ—åã‚’è‡ªå‹•æ¤œå‡º"""
    for cand in candidates:
        if cand in df.columns:
            return cand
    raise ValueError(f"Could not find {name} column in {candidates}")


def compute_adv60_trailing(
    df: pl.DataFrame,
    code_col: str,
    date_col: str,
    turnover_col: str | None,
    volume_col: str | None,
    price_col: str,
) -> pl.DataFrame:
    """
    ADV60ï¼ˆå¹³å‡å£²è²·ä»£é‡‘60æ—¥ã€å½“æ—¥é™¤å¤–ï¼‰ã‚’è¨ˆç®—

    ãƒ«ãƒƒã‚¯ã‚¢ãƒ˜ãƒƒãƒ‰é˜²æ­¢ã®ãŸã‚ã€rolling().shift(1)ã‚’ä½¿ç”¨
    turnoveråˆ—ãŒãªã„å ´åˆã¯ volume * price ã‹ã‚‰ç®—å‡º
    """
    # turnoveråˆ—ã®æº–å‚™
    if turnover_col and turnover_col in df.columns:
        df = df.with_columns(pl.col(turnover_col).alias("_turnover"))
    elif volume_col and volume_col in df.columns:
        # volume * price ã§ turnover ã‚’ç®—å‡º
        df = df.with_columns(
            (pl.col(volume_col) * pl.col(price_col)).alias("_turnover")
        )
    else:
        raise ValueError("Neither turnover nor volume column found")

    # æ•´åˆ—ãƒ»é‡è¤‡æ’é™¤
    df = df.sort([code_col, date_col]).unique([code_col, date_col], keep="first")

    # ADV60ï¼ˆå½“æ—¥é™¤å¤–ï¼‰
    df = df.with_columns(
        pl.col("_turnover")
        .rolling_mean(window_size=60)
        .shift(1)  # å½“æ—¥é™¤å¤–ï¼ˆãƒ«ãƒƒã‚¯ã‚¢ãƒ˜ãƒƒãƒ‰é˜²æ­¢ï¼‰
        .over(code_col)
        .alias("adv60_trailing")
    )

    return df.drop("_turnover")


def compute_ret_1d(df: pl.DataFrame, code_col: str, price_col: str) -> pl.DataFrame:
    """ret_1dï¼ˆ1æ—¥ãƒªã‚¿ãƒ¼ãƒ³ï¼‰ã‚’è¨ˆç®—"""
    if "ret_1d" in df.columns:
        return df

    df = df.with_columns(
        pl.col(price_col).pct_change().over(code_col).alias("ret_1d")
    )

    return df


def detect_price_freezes(
    df: pl.DataFrame,
    code_col: str,
    date_col: str,
    price_col: str,
    min_freeze_days: int = 5,
) -> dict:
    """
    æ ªä¾¡ãƒ•ãƒªãƒ¼ã‚ºï¼ˆåŒå€¤é€£ç¶š5æ—¥ä»¥ä¸Šï¼‰ã‚’æ¤œå‡º

    Returns:
        dict: {
            "total_freeze_sequences": int,  # ãƒ•ãƒªãƒ¼ã‚ºã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ•°
            "total_freeze_days": int,       # ãƒ•ãƒªãƒ¼ã‚ºåˆè¨ˆæ—¥æ•°
            "affected_codes": int,          # å½±éŸ¿éŠ˜æŸ„æ•°
        }
    """
    # åŒå€¤é€£ç¶šæ—¥æ•°ã‚’è¨ˆç®—
    df_freeze = df.sort([code_col, date_col]).with_columns(
        [
            # å‰æ—¥ã¨åŒã˜ä¾¡æ ¼ã‹ã©ã†ã‹
            (pl.col(price_col) == pl.col(price_col).shift(1))
            .over(code_col)
            .fill_null(False)
            .alias("_is_same"),
        ]
    )

    # é€£ç¶šåŒå€¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ID
    df_freeze = df_freeze.with_columns(
        [
            (~pl.col("_is_same")).cum_sum().over(code_col).alias("_freeze_group"),
        ]
    )

    # ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®é€£ç¶šæ—¥æ•°
    freeze_stats = (
        df_freeze.group_by([code_col, "_freeze_group"])
        .agg(
            [
                pl.count().alias("freeze_days"),
                pl.col("_is_same").first().alias("is_freeze"),
            ]
        )
        .filter(pl.col("is_freeze") & (pl.col("freeze_days") >= min_freeze_days))
    )

    total_sequences = freeze_stats.height
    total_days = freeze_stats["freeze_days"].sum() or 0
    affected_codes = freeze_stats[code_col].n_unique()

    return {
        "total_freeze_sequences": total_sequences,
        "total_freeze_days": int(total_days),
        "affected_codes": affected_codes,
    }


def main():
    parser = argparse.ArgumentParser(description="ãƒ‡ãƒ¼ã‚¿å“è³ªã‚²ãƒ¼ãƒˆ & ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°")
    parser.add_argument(
        "--input",
        default=DATASET_RAW,
        help=f"å…¥åŠ›parquetãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DATASET_RAW}ï¼‰",
    )
    parser.add_argument(
        "--output",
        default=DATASET_CLEAN,
        help=f"å‡ºåŠ›parquetãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DATASET_CLEAN}ï¼‰",
    )
    parser.add_argument(
        "--min-price", type=float, default=100.0, help="æœ€ä½ä¾¡æ ¼ï¼ˆå††ï¼‰"
    )
    parser.add_argument(
        "--max-ret-1d", type=float, default=0.15, help="æœ€å¤§1æ—¥ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆçµ¶å¯¾å€¤ï¼‰"
    )
    parser.add_argument(
        "--min-adv", type=float, default=50_000_000, help="æœ€ä½ADV60ï¼ˆå††ï¼‰"
    )
    parser.add_argument(
        "--freeze-reduction-ratio-max",
        type=float,
        default=0.5,
        help="ãƒ•ãƒªãƒ¼ã‚ºå‰Šæ¸›ç‡ã®æœ€å¤§å€¤ï¼ˆpost/preï¼‰",
    )
    parser.add_argument(
        "--freeze-abs-max",
        type=int,
        default=100,
        help="ãƒ•ãƒªãƒ¼ã‚ºåˆè¨ˆæ—¥æ•°ã®æœ€å¤§å€¤ï¼ˆpostï¼‰",
    )
    parser.add_argument(
        "--report",
        default=QUALITY_REPORT,
        help=f"å“è³ªãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›å…ˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {QUALITY_REPORT}ï¼‰",
    )
    args = parser.parse_args()

    print("=" * 70)
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ªã‚²ãƒ¼ãƒˆ & ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°")
    print("=" * 70)
    print(f"å…¥åŠ›: {args.input}")
    print(f"å‡ºåŠ›: {args.output}")
    print(f"æœ€ä½ä¾¡æ ¼: {args.min_price}å††")
    print(f"æœ€å¤§ãƒªã‚¿ãƒ¼ãƒ³: {args.max_ret_1d * 100:.1f}%")
    print(f"æœ€ä½ADV60: {args.min_adv / 1e8:.1f}å„„å††")
    print("=" * 70)

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = pl.read_parquet(args.input)
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {df.height:,}è¡Œ Ã— {df.width}åˆ—")

    # åˆ—åæ¤œå‡º
    code_col = detect_column(df, CAND_CODE, "code")
    date_col = detect_column(df, CAND_DATE, "date")
    price_col = detect_column(df, CAND_PRICE, "price")

    # volume/turnoverï¼ˆã©ã¡ã‚‰ã‹å¿…é ˆï¼‰
    volume_col = None
    turnover_col = None
    for cand in CAND_VOLUME:
        if cand in df.columns:
            volume_col = cand
            break
    for cand in CAND_TURNOVER:
        if cand in df.columns:
            turnover_col = cand
            break

    print("ğŸ” æ¤œå‡ºã•ã‚ŒãŸåˆ—:")
    print(f"  - Code: {code_col}")
    print(f"  - Date: {date_col}")
    print(f"  - Price: {price_col}")
    print(f"  - Volume: {volume_col or '(not found)'}")
    print(f"  - Turnover: {turnover_col or '(not found)'}")

    # Pre-filterçµ±è¨ˆ
    print("\nğŸ“ˆ Pre-filterçµ±è¨ˆ:")
    pre_rows = df.height
    pre_codes = df[code_col].n_unique()
    print(f"  - ç·è¡Œæ•°: {pre_rows:,}")
    print(f"  - éŠ˜æŸ„æ•°: {pre_codes:,}")

    # ãƒ•ãƒªãƒ¼ã‚ºæ¤œå‡ºï¼ˆPreï¼‰
    pre_freeze = detect_price_freezes(df, code_col, date_col, price_col)
    print(f"  - ãƒ•ãƒªãƒ¼ã‚ºã‚·ãƒ¼ã‚±ãƒ³ã‚¹: {pre_freeze['total_freeze_sequences']:,}")
    print(f"  - ãƒ•ãƒªãƒ¼ã‚ºæ—¥æ•°: {pre_freeze['total_freeze_days']:,}")
    print(f"  - å½±éŸ¿éŠ˜æŸ„æ•°: {pre_freeze['affected_codes']:,}")

    # ret_1dè¨ˆç®—
    df = compute_ret_1d(df, code_col, price_col)

    # ç•°å¸¸ãƒªã‚¿ãƒ¼ãƒ³çµ±è¨ˆï¼ˆPreï¼‰
    ret_extreme_10_pre = (
        df.filter(pl.col("ret_1d").abs() > 0.10).height / max(df.height, 1)
    )
    ret_extreme_15_pre = (
        df.filter(pl.col("ret_1d").abs() > 0.15).height / max(df.height, 1)
    )
    print(f"  - |ret_1d| > 10%: {ret_extreme_10_pre * 100:.2f}%")
    print(f"  - |ret_1d| > 15%: {ret_extreme_15_pre * 100:.2f}%")

    # ADV60è¨ˆç®—
    df = compute_adv60_trailing(df, code_col, date_col, turnover_col, volume_col, price_col)

    # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
    print("\nğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ä¸­...")
    df_clean = df.filter(
        (pl.col(price_col) >= args.min_price)
        & (pl.col("ret_1d").abs() <= args.max_ret_1d)
        & (pl.col("adv60_trailing") >= args.min_adv)
    )

    # Post-filterçµ±è¨ˆ
    print("\nğŸ“Š Post-filterçµ±è¨ˆ:")
    post_rows = df_clean.height
    post_codes = df_clean[code_col].n_unique()
    print(f"  - ç·è¡Œæ•°: {post_rows:,} ({(post_rows / max(pre_rows, 1)) * 100:.1f}%)")
    print(f"  - éŠ˜æŸ„æ•°: {post_codes:,} ({(post_codes / max(pre_codes, 1)) * 100:.1f}%)")

    # ãƒ•ãƒªãƒ¼ã‚ºæ¤œå‡ºï¼ˆPostï¼‰
    post_freeze = detect_price_freezes(df_clean, code_col, date_col, price_col)
    print(f"  - ãƒ•ãƒªãƒ¼ã‚ºã‚·ãƒ¼ã‚±ãƒ³ã‚¹: {post_freeze['total_freeze_sequences']:,}")
    print(f"  - ãƒ•ãƒªãƒ¼ã‚ºæ—¥æ•°: {post_freeze['total_freeze_days']:,}")
    print(f"  - å½±éŸ¿éŠ˜æŸ„æ•°: {post_freeze['affected_codes']:,}")

    # ç•°å¸¸ãƒªã‚¿ãƒ¼ãƒ³çµ±è¨ˆï¼ˆPostï¼‰
    ret_extreme_10_post = (
        df_clean.filter(pl.col("ret_1d").abs() > 0.10).height / max(df_clean.height, 1)
    )
    ret_extreme_15_post = (
        df_clean.filter(pl.col("ret_1d").abs() > 0.15).height / max(df_clean.height, 1)
    )
    print(f"  - |ret_1d| > 10%: {ret_extreme_10_post * 100:.2f}%")
    print(f"  - |ret_1d| > 15%: {ret_extreme_15_post * 100:.2f}%")

    # å“è³ªã‚²ãƒ¼ãƒˆåˆ¤å®š
    print("\nğŸš¦ å“è³ªã‚²ãƒ¼ãƒˆåˆ¤å®š:")
    issues = []

    # Check 1: ret_1d extreme values
    if ret_extreme_10_post > 0.005:  # 0.5%
        issues.append(
            f"âŒ |ret_1d| > 10% ã®å‰²åˆãŒé«˜ã„: {ret_extreme_10_post * 100:.2f}% (> 0.5%)"
        )
    else:
        print(f"  âœ… |ret_1d| > 10%: {ret_extreme_10_post * 100:.2f}% (< 0.5%)")

    if ret_extreme_15_post > 1e-6:  # â‰ˆ 0%
        issues.append(
            f"âŒ |ret_1d| > 15% ãŒå­˜åœ¨: {ret_extreme_15_post * 100:.4f}% (> 0%)"
        )
    else:
        print(f"  âœ… |ret_1d| > 15%: {ret_extreme_15_post * 100:.4f}% (â‰ˆ 0%)")

    # Check 2: price violations
    price_violations = df_clean.filter(pl.col(price_col) < args.min_price).height
    if price_violations > 0:
        issues.append(f"âŒ ä¾¡æ ¼ < {args.min_price}å††ãŒ{price_violations}ä»¶å­˜åœ¨")
    else:
        print(f"  âœ… ä¾¡æ ¼ãƒ•ã‚£ãƒ«ã‚¿: å…¨ã¦ >= {args.min_price}å††")

    # Check 3: freeze reduction
    freeze_ratio = (
        post_freeze["total_freeze_days"] / max(pre_freeze["total_freeze_days"], 1)
    )
    if freeze_ratio > args.freeze_reduction_ratio_max:
        issues.append(
            f"âŒ ãƒ•ãƒªãƒ¼ã‚ºå‰Šæ¸›ä¸è¶³: {freeze_ratio * 100:.1f}% (> {args.freeze_reduction_ratio_max * 100:.0f}%)"
        )
    else:
        print(
            f"  âœ… ãƒ•ãƒªãƒ¼ã‚ºå‰Šæ¸›: {freeze_ratio * 100:.1f}% (< {args.freeze_reduction_ratio_max * 100:.0f}%)"
        )

    if post_freeze["total_freeze_days"] > args.freeze_abs_max:
        issues.append(
            f"âŒ ãƒ•ãƒªãƒ¼ã‚ºæ—¥æ•°ãŒå¤šã„: {post_freeze['total_freeze_days']}æ—¥ (> {args.freeze_abs_max}æ—¥)"
        )
    else:
        print(
            f"  âœ… ãƒ•ãƒªãƒ¼ã‚ºæ—¥æ•°: {post_freeze['total_freeze_days']}æ—¥ (< {args.freeze_abs_max}æ—¥)"
        )

    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    report = {
        "input": args.input,
        "output": args.output,
        "filters": {
            "min_price": args.min_price,
            "max_ret_1d": args.max_ret_1d,
            "min_adv": args.min_adv,
        },
        "pre_filter": {
            "rows": pre_rows,
            "codes": pre_codes,
            "ret_extreme_10_pct": ret_extreme_10_pre,
            "ret_extreme_15_pct": ret_extreme_15_pre,
            "freeze_sequences": pre_freeze["total_freeze_sequences"],
            "freeze_days": pre_freeze["total_freeze_days"],
            "affected_codes": pre_freeze["affected_codes"],
        },
        "post_filter": {
            "rows": post_rows,
            "codes": post_codes,
            "ret_extreme_10_pct": ret_extreme_10_post,
            "ret_extreme_15_pct": ret_extreme_15_post,
            "freeze_sequences": post_freeze["total_freeze_sequences"],
            "freeze_days": post_freeze["total_freeze_days"],
            "affected_codes": post_freeze["affected_codes"],
        },
        "quality_gate": {"passed": len(issues) == 0, "issues": issues},
    }

    Path(args.report).parent.mkdir(parents=True, exist_ok=True)
    with open(args.report, "w") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    print(f"\nğŸ“ å“è³ªãƒ¬ãƒãƒ¼ãƒˆ: {args.report}")

    # å“è³ªã‚²ãƒ¼ãƒˆå¤±æ•—æ™‚ã¯çµ‚äº†
    if issues:
        print("\nâŒ å“è³ªã‚²ãƒ¼ãƒˆå¤±æ•—:")
        for issue in issues:
            print(f"  {issue}")
        sys.exit(1)

    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    Path(args.output).parent.mkdir(parents=True, exist_ok=True)
    df_clean.write_parquet(args.output)
    print(f"\nâœ… ã‚¯ãƒªãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {args.output}")
    print(f"   {post_rows:,}è¡Œ Ã— {df_clean.width}åˆ—")
    print("=" * 70)


if __name__ == "__main__":
    main()
