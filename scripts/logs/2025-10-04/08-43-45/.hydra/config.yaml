improvements:
  compile_model: false
  compile_mode: reduce-overhead
  compile_fullgraph: false
  compile_dynamic: false
  force_multiworker: true
  num_workers: 8
  persistent_workers: true
  prefetch_factor: 4
  loss_weights:
    use_rankic: true
    rankic_weight: 0.2
    cs_ic_weight: 0.15
    sharpe_weight: 0.3
  phase_loss_weights:
    phase_0: huber=0.3,quantile=1.0,sharpe=0.0
    phase_1: quantile=0.5,sharpe=0.4,rankic=0.1
    phase_2: quantile=0.4,sharpe=0.6,rankic=0.2,t_nll=0.2
    phase_3: quantile=0.3,sharpe=0.8,rankic=0.3,cs_ic=0.2
feature_categories_config: configs/atft/feature_categories_actual.yaml
model:
  name: ATFT_GAT_FAN
  hidden_size: 256
  input_dims:
    total_features: 200
    historical_features: 0
    basic_features: 200
    technical_features: 24
    ma_derived_features: 16
    returns_features: 15
    market_features: 26
    flows_features: 55
    statements_features: 18
    additional_features: 10
  variable_selection:
    enabled: true
    per_feature_group: false
  fan:
    enabled: true
  san:
    enabled: true
  architecture: atft_gat_fan
  ema_teacher:
    enabled: true
    decay: 0.999
  input_projection:
    use_layer_norm: true
    dropout: 0.1
  tft:
    lstm:
      layers: 1
      hidden_size: ${model.hidden_size}
      dropout: 0.1
      bidirectional: false
    attention:
      heads: 8
      dropout: 0.1
      use_scale: true
    variable_selection:
      hidden_size: ${model.hidden_size}
      dropout: 0.1
      use_sigmoid: true
      sparsity_coefficient: 0.01
    grn:
      hidden_size: ${model.hidden_size}
      dropout: 0.1
      use_layer_norm: true
    temporal:
      use_positional_encoding: true
      max_sequence_length: 20
  adaptive_normalization:
    fan:
      enabled: true
      window_sizes:
      - 3
      - 7
      - 14
      - 30
      aggregation: weighted_mean
      learn_weights: true
    san:
      enabled: true
      num_slices: 4
      overlap: 0.5
      slice_aggregation: learned
  gat:
    enabled: true
    alpha_min: 0.4
    architecture:
      num_layers: 2
      hidden_channels:
      - ${model.hidden_size}
      - ${model.hidden_size}
      heads:
      - 8
      - 4
      concat:
      - true
      - false
    layer_config:
      dropout: 0.2
      edge_dropout: 0.1
      negative_slope: 0.2
      add_self_loops: false
      bias: true
    edge_features:
      use_edge_attr: true
      edge_dim: 3
      edge_projection: linear
    regularization:
      edge_weight_penalty: 0.01
      attention_entropy_penalty: 0.001
  prediction_head:
    architecture:
      hidden_layers:
      - 32
      activation: relu
      dropout: 0.2
      use_batch_norm: false
    stochastic_depth:
      rate: 0.1
    output:
      point_prediction: true
      quantile_loss:
        enforce_convexity: true
        smoothing_temperature: 0.5
      quantile_prediction:
        enabled: true
        quantiles:
        - 0.05
        - 0.25
        - 0.5
        - 0.75
        - 0.95
      distribution_prediction:
        enabled: false
        type: normal
      student_t: true
  optimization:
    compression:
      gradient_checkpointing: false
      mixed_precision: true
      channels_last: true
    compile:
      enabled: true
      mode: reduce-overhead
      fullgraph: false
      dynamic: false
    inference:
      use_torch_script: false
      use_onnx: false
      optimize_for_inference: true
  initialization:
    method: xavier_uniform
    gain: 1.0
  regularization:
    weight_decay: 0.0001
    gradient_clip_val: 1.0
    gradient_clip_algorithm: norm
train:
  trainer:
    max_epochs: 1
    precision: bf16-mixed
    gradient_clip_val: 1.0
    accelerator: cuda
    devices: 1
    gradient_clip_algorithm: norm
    log_every_n_steps: 50
    val_check_interval: 1.0
    accumulate_grad_batches: 2
  optimizer:
    lr: 0.0005
    weight_decay: 1.0e-05
    name: adamw
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-08
    param_groups:
    - name: gat
      lr_multiplier: 1.0
    - name: tft
      lr_multiplier: 1.0
    - name: head
      lr_multiplier: 2.0
  scheduler:
    name: plateau
    monitor: val/rank_ic_5d
    patience: 5
    factor: 0.5
    min_lr: 1.0e-06
    mode: max
    threshold: 0.0001
    cooldown: 2
  batch:
    batch_size: 2048
    accumulate_grad_batches: 2
    shuffle: true
    num_workers: 8
    persistent_workers: true
    prefetch_factor: 4
    pin_memory: true
    drop_last: false
  early_stopping:
    monitor: val/rank_ic_5d
    mode: max
    patience: 15
    min_delta: 0.0001
    verbose: true
  loss:
    horizons:
    - 1
    - 5
    - 10
    - 20
    horizon_weights:
      1: 1.0
      5: 0.8
      10: 0.5
      20: 0.3
    components:
      quantile:
        weight: 0.3
        quantiles:
        - 0.5
      sharpe:
        weight: 0.3
        target_sharpe: 0.849
      ic:
        weight: 0.2
        use_rank_ic: true
        rank_ic_weight: 0.5
      mse:
        weight: 0.1
      huber:
        weight: 0.1
        delta: 1.0
  phases:
  - name: warmup
    epochs: 5
    lr_multiplier: 0.1
    use_gat: false
    use_fan: false
  - name: baseline
    epochs: 10
    lr_multiplier: 1.0
    use_gat: false
    use_fan: false
  - name: gat_integration
    epochs: 20
    lr_multiplier: 1.0
    use_gat: true
    use_fan: false
    freeze_baseline: false
  - name: full_model
    epochs: 40
    lr_multiplier: 1.0
    use_gat: true
    use_fan: true
    freeze_baseline: false
  - name: finetune
    epochs: 25
    lr_multiplier: 0.1
    use_gat: true
    use_fan: true
    freeze_baseline: false
    use_swa: true
  validation:
    metrics:
    - ic
    - rank_ic
    - sharpe
    - max_drawdown
    - calmar
    walk_forward:
      enabled: true
      embargo_days: 20
      n_splits: 5
  callbacks:
    model_checkpoint:
      monitor: val/rank_ic_5d
      mode: max
      save_top_k: 3
      save_last: true
    learning_rate_monitor:
      logging_interval: step
    gpu_stats_monitor:
      memory_utilization: true
      gpu_utilization: true
    swa:
      enabled: true
      swa_lrs: 0.0001
      swa_epoch_start: 0.75
      annealing_epochs: 5
    snapshot:
      enabled: true
      snapshot_epochs:
      - 60
      - 70
      - 80
      - 90
      - 100
  performance:
    compile:
      enabled: true
      mode: reduce-overhead
      fullgraph: false
      dynamic: false
    gradient_checkpointing: false
    mixed_precision: bf16
    dataloader:
      multiprocessing_context: spawn
      worker_init_fn: seed_worker
  debug:
    profiler: false
    detect_anomaly: false
    track_grad_norm: true
    log_gpu_memory: true
normalization:
  online_normalization:
    enabled: true
  cross_sectional:
    enabled: false
data:
  path: ${oc.env:OUTPUT_BASE}/ml_dataset_full.parquet
  schema:
    date_column: Date
    code_column: Code
    target_column: target
    feature_columns: null
    target_columns:
    - target_1d
    - target_5d
    - target_10d
    - target_20d
  graph_builder:
    cache_dir: graph_cache
    ewm_halflife: 30
    k: 24
    edge_threshold: 0.18
    min_edges: 75
    log_mktcap_col: log_mktcap
    lookback: 60
    method: ewm_demean
    min_obs: 40
    use_in_training: false
    return_cols:
    - return_1d
    - feat_ret_1d
    sector_col: sector33
    shrinkage_gamma: 0.1
    size_tau: 1.0
    source_glob: ${data.source.data_dir}/*.parquet
    symmetric: true
  split:
    method: walk_forward
    n_splits: 5
    embargo_days: 20
    min_train_days: 252
  selected_features_json: null
  time_series:
    sequence_length: 20
    prediction_horizons:
    - 1
    - 2
    - 3
    - 5
    - 10
    split:
      method: time_based
      train_ratio: 0.7
      val_ratio: 0.15
      test_ratio: 0.15
      gap_days: 5
  name: jpx_large_scale
  use_buffered_loader: true
  source:
    type: parquet
    data_dir: data/raw/large_scale
    file_pattern: '*.parquet'
  memory:
    chunk_size: 50000
    cache_size_gb: 15
    use_memory_map: true
  distributed:
    enabled: true
    num_workers: 4
    prefetch_factor: 2
  sampling:
    n_files_for_scaler: 10
    rows_per_file: 10000
  features:
    input_dim: 189
    basic:
      price_volume:
      - close
      - open
      - high
      - low
      - volume
      flags:
      - upper_limit
      - volume_spike
      - high_break_20d
    technical:
      momentum:
      - rsi_2
      - rsi_14
      - rsi_delta
      volatility:
      - volatility_20d
      - volatility_ratio
      - volatility_change
      - sharpe_1d
      - sharpe_5d
      - sharpe_20d
      - high_vol_flag
      - low_vol_flag
      trend:
      - adx3
      - adx7
      - adx14
      moving_averages:
      - ema_5
      - ema_10
      - ema_20
      - ema_60
      - ema_200
      macd:
      - macd_signal
      - macd_histogram
      bollinger_bands:
      - bb_pct_b
      - bb_bandwidth
    ma_derived:
      price_deviations:
      - price_ema5_dev
      - price_ema10_dev
      - price_ema20_dev
      - price_ema200_dev
      ma_gaps:
      - ma_gap_5_20
      - ma_gap_20_60
      - ma_gap_60_200
      ma_slopes:
      - ema5_slope
      - ema20_slope
      - ema60_slope
      ma_crosses:
      - ema_cross_5_20
      - ema_cross_20_60
      - ema_cross_60_200
      ma_ribbon:
      - ma_ribbon_bullish
      - ma_ribbon_bearish
      - ma_ribbon_spread
      - dist_to_200ema
    returns_ma_interaction:
      momentum:
      - momentum_5_20
      - momentum_1_5
      - momentum_10_20
      interactions:
      - ret1d_x_ema20dev
      - ret5d_x_ema20dev
      - ret1d_x_ema200dev
      - mom5d_x_ema20slope
      - mom20d_x_ema60slope
    flow:
    - smart_money_index
    - smart_money_change
    - flow_high_flag
    - flow_low_flag
    returns:
      columns:
      - returns_1d
      - returns_5d
      - returns_10d
      - returns_20d
    maturity_flags:
    - is_rsi2_valid
    - is_ema5_valid
    - is_ema10_valid
    - is_ema20_valid
    - is_ema200_valid
    - is_valid_ma
environment:
  allow_unsafe_dataloader: ${oc.env:ALLOW_UNSAFE_DATALOADER,1}
  use_rankic: ${oc.env:USE_RANKIC,1}
  cs_ic_weight: ${oc.env:CS_IC_WEIGHT,0.15}
  sharpe_weight: ${oc.env:SHARPE_WEIGHT,0.3}
  phase_loss_weights: ${oc.env:PHASE_LOSS_WEIGHTS,}
logging:
  level: INFO
  wandb:
    enabled: false
    project: atft-gat-fan-optimized
  tensorboard:
    enabled: true
    log_dir: logs/optimized
experimental:
  ddp:
    enabled: false
    backend: nccl
    find_unused_parameters: false
  advanced_augmentation:
    enabled: false
  curriculum_learning:
    enabled: false
debug:
  detect_anomaly: false
  enabled: false
  fast_dev_run: 10
  profiler: false
project:
  deterministic: true
  name: ATFT-GAT-FAN-Optimized
  seed: 42
paths:
  data: data
  logs: logs
  models: models
  root: .
mode: train
hardware:
  name: default
  device: ${oc.env:DEVICE, cuda}
  gpu_id: ${oc.env:GPU_ID, 0}
  num_workers: ${oc.env:NUM_WORKERS, 8}
  pin_memory: ${oc.env:PIN_MEMORY, true}
  mixed_precision: ${oc.env:MIXED_PRECISION, true}
  channels_last: ${oc.env:CHANNELS_LAST, true}
  a100_optimizations:
    tf32: true
    cudnn_benchmark: true
    gradient_checkpointing: false
  memory:
    max_memory_allocated: ${oc.env:MAX_MEMORY_ALLOCATED, 0.9}
    memory_fraction: ${oc.env:MEMORY_FRACTION, 0.8}
    allow_growth: ${oc.env:ALLOW_GROWTH, true}
  performance:
    prefetch_factor: ${oc.env:PREFETCH_FACTOR, 4}
    persistent_workers: ${oc.env:PERSISTENT_WORKERS, true}
    drop_last: ${oc.env:DROP_LAST, false}
