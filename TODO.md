  ğŸš¨ é‡å¤§ãªæ”¹å–„ç‚¹ï¼ˆè©³ç´°ç‰ˆï¼‰

  1. ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã¨GPU OOMå¯¾ç­–

  ç¾çŠ¶ã®å•é¡Œç‚¹:
  - forward()å†…ã§æ¯å›KNNã‚°ãƒ©ãƒ•ã‚’å‹•çš„ç”Ÿæˆï¼ˆO(NÂ²)ã®è¨ˆç®—ï¼‰
  - ã‚°ãƒ©ãƒ•æ§‹ç¯‰æ™‚ã«FP32å¤‰æ›ã§ãƒ¡ãƒ¢ãƒª2å€ä½¿ç”¨
  - torch.stackã«ã‚ˆã‚‹ä¸è¦ãªãƒ¡ãƒ¢ãƒªã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³
  - ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒä¸å®Œå…¨

  å…·ä½“çš„ãªæ”¹å–„å®Ÿè£…:
  class ATFT_GAT_FAN(nn.Module):
      def __init__(self, config):
          super().__init__()
          # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªKNNã‚­ãƒ£ãƒƒã‚·ãƒ¥
          self._knn_cache = LRUCache(maxsize=32)
          self._graph_buffer = None  # äº‹å‰å‰²ã‚Šå½“ã¦ãƒãƒƒãƒ•ã‚¡

      @torch.compile(mode="reduce-overhead")  # PyTorch 2.0æœ€é©åŒ–
      def _build_efficient_knn(self, embeddings, k=15):
          """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªKNNæ§‹ç¯‰"""
          batch_size = embeddings.shape[0]

          # ãƒãƒƒãƒ•ã‚¡å†åˆ©ç”¨
          if self._graph_buffer is None or self._graph_buffer.shape[0] != batch_size:
              self._graph_buffer = torch.empty((2, batch_size * k),
                                              device=embeddings.device,
                                              dtype=torch.long)

          # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã§ãƒ¡ãƒ¢ãƒªå‰Šæ¸›
          chunk_size = min(512, batch_size)
          for i in range(0, batch_size, chunk_size):
              chunk = embeddings[i:i+chunk_size]
              # FP16ã®ã¾ã¾è¨ˆç®—
              with torch.cuda.amp.autocast():
                  distances = torch.cdist(chunk, embeddings)
              # top-kå–å¾—
              _, indices = distances.topk(k, dim=-1, largest=False)
              # ãƒãƒƒãƒ•ã‚¡ã«ç›´æ¥æ›¸ãè¾¼ã¿
              self._update_buffer(indices, i, chunk_size)

          return self._graph_buffer

  2. ç’°å¢ƒå¤‰æ•°ç®¡ç†ã®å®Œå…¨ãªçµ±ä¸€åŒ–

  ç¾çŠ¶ã®å•é¡Œç‚¹:
  - 50ç®‡æ‰€ä»¥ä¸Šã®os.getenv()æ•£åœ¨
  - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®ä¸æ•´åˆ
  - å‹å¤‰æ›ã‚¨ãƒ©ãƒ¼ã®å¯èƒ½æ€§

  æ”¹å–„å®Ÿè£…:
  from pydantic import BaseSettings, Field, validator
  from functools import lru_cache

  class ModelSettings(BaseSettings):
      """ç’°å¢ƒå¤‰æ•°ã¨YAMLã®çµ±åˆè¨­å®š"""
      # GPU/ãƒ¡ãƒ¢ãƒªè¨­å®š
      mixed_precision: bool = Field(default=True, env="USE_MIXED_PRECISION")
      gradient_checkpointing: bool = Field(default=True, env="GRADIENT_CHECKPOINT")
      compile_model: bool = Field(default=True, env="COMPILE_MODEL")

      # GATè¨­å®š
      gat_alpha_init: float = Field(default=0.2, ge=0.0, le=1.0)
      gat_alpha_min: float = Field(default=0.3, ge=0.0, le=1.0)
      gat_alpha_penalty: float = Field(default=1e-4, ge=0.0)
      edge_dropout_p: float = Field(default=0.0, ge=0.0, le=0.5)

      # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼è¨­å®š
      num_workers: int = Field(default=4, ge=0, le=32)
      prefetch_factor: int = Field(default=2, ge=1)
      pin_memory: bool = Field(default=True)

      @validator("num_workers")
      def validate_workers(cls, v):
          """ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã®è‡ªå‹•èª¿æ•´"""
          import multiprocessing
          max_workers = multiprocessing.cpu_count()
          return min(v, max_workers - 1)

      class Config:
          env_file = ".env"
          env_file_encoding = "utf-8"
          case_sensitive = False

  @lru_cache()
  def get_settings() -> ModelSettings:
      """ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹"""
      return ModelSettings()

  3. ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Œå…¨ãªæœ€é©åŒ–

  ç¾çŠ¶ã®å•é¡Œç‚¹:
  - å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¿
  - numpyâ†’tensorå¤‰æ›ãŒéåŠ¹ç‡
  - ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãªã—

  æ”¹å–„å®Ÿè£…:
  import torch.utils.data as data
  from torch.utils.data import IterableDataset
  import pyarrow.parquet as pq

  class StreamingDataset(IterableDataset):
      """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""

      def __init__(self, parquet_files, config, transform=None):
          self.files = parquet_files
          self.config = config
          self.transform = transform

          # ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨
          self.use_mmap = True

          # äº‹å‰è¨ˆç®—ã—ãŸçµ±è¨ˆé‡ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
          self._stats_cache = self._compute_stats()

      def _compute_stats(self):
          """ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆé‡ã®äº‹å‰è¨ˆç®—ï¼ˆ1å›ã®ã¿ï¼‰"""
          stats = {}
          for file in self.files[:10]:  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
              table = pq.read_table(file, memory_map=self.use_mmap)
              df = table.to_pandas()
              for col in df.select_dtypes(include=[np.number]).columns:
                  if col not in stats:
                      stats[col] = {"mean": [], "std": []}
                  stats[col]["mean"].append(df[col].mean())
                  stats[col]["std"].append(df[col].std())

          # çµ±è¨ˆé‡ã®é›†ç´„
          for col in stats:
              stats[col]["mean"] = np.mean(stats[col]["mean"])
              stats[col]["std"] = np.mean(stats[col]["std"])
          return stats

      def __iter__(self):
          """ãƒãƒƒãƒã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°"""
          worker_info = data.get_worker_info()

          # ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹å¯¾å¿œ
          if worker_info is None:
              file_list = self.files
          else:
              # ãƒ¯ãƒ¼ã‚«ãƒ¼é–“ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²
              per_worker = len(self.files) // worker_info.num_workers
              worker_id = worker_info.id
              start = worker_id * per_worker
              end = start + per_worker if worker_id < worker_info.num_workers - 1 else len(self.files)
              file_list = self.files[start:end]

          for file_path in file_list:
              # ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ—ã§åŠ¹ç‡çš„èª­ã¿è¾¼ã¿
              table = pq.read_table(file_path, memory_map=self.use_mmap)

              # ãƒãƒƒãƒå˜ä½ã§å‡¦ç†
              for batch in table.to_batches(max_chunksize=1024):
                  df_batch = batch.to_pandas()

                  # ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ­£è¦åŒ–
                  for col, stats in self._stats_cache.items():
                      if col in df_batch.columns:
                          df_batch[col] = (df_batch[col] - stats["mean"]) / (stats["std"] + 1e-8)

                  # Tensorå¤‰æ›ï¼ˆã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ï¼‰
                  tensor_batch = torch.from_numpy(df_batch.values.astype(np.float32))

                  # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
                  if self.transform:
                      tensor_batch = self.transform(tensor_batch)

                  yield tensor_batch

  4. å­¦ç¿’å®‰å®šæ€§ã®æ ¹æœ¬çš„æ”¹å–„

  ç¾çŠ¶ã®å•é¡Œç‚¹:
  - å‹¾é…çˆ†ç™º/æ¶ˆå¤±
  - å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ãªã—
  - æ—©æœŸçµ‚äº†ãªã—

  æ”¹å–„å®Ÿè£…:
  class RobustTrainer:
      """å®‰å®šã—ãŸå­¦ç¿’ã®ãŸã‚ã®ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼"""

      def __init__(self, model, config):
          self.model = model
          self.config = config

          # Gradient Clippingæˆ¦ç•¥
          self.grad_clip_val = 1.0
          self.grad_clip_norm_type = 2.0

          # Mixed Precision Training
          self.scaler = torch.cuda.amp.GradScaler(enabled=config.mixed_precision)

          # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ç¾¤
          self.schedulers = self._setup_schedulers()

          # EMAï¼ˆæŒ‡æ•°ç§»å‹•å¹³å‡ï¼‰
          self.ema = ModelEMA(model, decay=0.9999)

          # æ—©æœŸçµ‚äº†
          self.early_stopping = EarlyStopping(patience=10, min_delta=1e-4)

      def _setup_schedulers(self):
          """è¤‡åˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®š"""
          schedulers = []

          # Warmup
          warmup_scheduler = torch.optim.lr_scheduler.LinearLR(
              self.optimizer,
              start_factor=0.1,
              total_iters=self.config.warmup_steps
          )

          # Cosine Annealing with Restarts
          cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
              self.optimizer,
              T_0=50,
              T_mult=2,
              eta_min=1e-6
          )

          # ReduceLROnPlateauï¼ˆæ¤œè¨¼æå¤±ãƒ™ãƒ¼ã‚¹ï¼‰
          plateau_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
              self.optimizer,
              mode='min',
              factor=0.5,
              patience=5,
              min_lr=1e-7
          )

          return {
              'warmup': warmup_scheduler,
              'cosine': cosine_scheduler,
              'plateau': plateau_scheduler
          }

      def training_step(self, batch, batch_idx):
          """å®‰å®šã—ãŸå­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—"""
          # å‹¾é…ç´¯ç©
          accumulation_steps = self.config.gradient_accumulation_steps

          with torch.cuda.amp.autocast(enabled=self.config.mixed_precision):
              # Forward pass
              outputs = self.model(batch['features'])
              loss = self.criterion(outputs, batch['targets'])

              # æ­£å‰‡åŒ–é …è¿½åŠ 
              l2_lambda = 1e-5
              l2_norm = sum(p.pow(2.0).sum() for p in self.model.parameters())
              loss = loss + l2_lambda * l2_norm

              # å‹¾é…ç´¯ç©ã§å‰²ã‚‹
              loss = loss / accumulation_steps

          # Backward pass with mixed precision
          self.scaler.scale(loss).backward()

          if (batch_idx + 1) % accumulation_steps == 0:
              # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
              self.scaler.unscale_(self.optimizer)
              grad_norm = torch.nn.utils.clip_grad_norm_(
                  self.model.parameters(),
                  self.grad_clip_val,
                  norm_type=self.grad_clip_norm_type
              )

              # å‹¾é…ãŒNaNã§ãªã„ã“ã¨ã‚’ç¢ºèª
              if not torch.isnan(grad_norm):
                  self.scaler.step(self.optimizer)
                  self.scaler.update()

                  # EMAæ›´æ–°
                  self.ema.update(self.model)
              else:
                  logger.warning(f"Gradient NaN detected at step {batch_idx}")

              self.optimizer.zero_grad(set_to_none=True)

          return loss.item() * accumulation_steps

  5. åŒ…æ‹¬çš„ãªãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 

  æ”¹å–„å®Ÿè£…:
  import wandb
  from torch.utils.tensorboard import SummaryWriter
  from typing import Dict, Any
  import json

  class ComprehensiveLogger:
      """çµ±åˆãƒ­ã‚®ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ """

      def __init__(self, config, experiment_name):
          # W&BåˆæœŸåŒ–
          self.wandb_run = wandb.init(
              project=config.project_name,
              name=experiment_name,
              config=config.to_dict(),
              tags=["atft-gat-fan", "production"],
              resume="allow"
          )

          # TensorBoard
          self.tb_writer = SummaryWriter(f"runs/{experiment_name}")

          # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒãƒƒãƒ•ã‚¡ï¼ˆåŠ¹ç‡çš„ãªãƒ­ã‚®ãƒ³ã‚°ï¼‰
          self.metrics_buffer = []
          self.buffer_size = 100

          # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼
          self.profiler = torch.profiler.profile(
              activities=[
                  torch.profiler.ProfilerActivity.CPU,
                  torch.profiler.ProfilerActivity.CUDA,
              ],
              schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),
              on_trace_ready=torch.profiler.tensorboard_trace_handler(f"./log/{experiment_name}"),
              record_shapes=True,
              profile_memory=True,
              with_stack=True
          )

      def log_metrics(self, metrics: Dict[str, Any], step: int):
          """åŠ¹ç‡çš„ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ­ã‚®ãƒ³ã‚°"""
          # ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°
          self.metrics_buffer.append({"step": step, **metrics})

          if len(self.metrics_buffer) >= self.buffer_size:
              # ãƒãƒƒãƒãƒ­ã‚°
              wandb.log({"batch_metrics": self.metrics_buffer})

              # TensorBoardã¸ã®æ›¸ãè¾¼ã¿
              for item in self.metrics_buffer:
                  for key, value in item.items():
                      if key != "step":
                          self.tb_writer.add_scalar(key, value, item["step"])

              self.metrics_buffer = []

      def log_model_stats(self, model, step):
          """ãƒ¢ãƒ‡ãƒ«çµ±è¨ˆã®ãƒ­ã‚®ãƒ³ã‚°"""
          # é‡ã¿ã®åˆ†å¸ƒ
          for name, param in model.named_parameters():
              if param.requires_grad:
                  self.tb_writer.add_histogram(f"weights/{name}", param, step)
                  if param.grad is not None:
                      self.tb_writer.add_histogram(f"gradients/{name}", param.grad, step)

          # ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³çµ±è¨ˆ
          def hook_fn(module, input, output):
              if isinstance(output, torch.Tensor):
                  self.tb_writer.add_histogram(
                      f"activations/{module.__class__.__name__}",
                      output, step
                  )

          # ãƒ•ãƒƒã‚¯ç™»éŒ²
          for module in model.modules():
              if len(list(module.children())) == 0:  # ãƒªãƒ¼ãƒ•ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
                  module.register_forward_hook(hook_fn)

  6. å†ç¾æ€§ã®å®Œå…¨ä¿è¨¼

  æ”¹å–„å®Ÿè£…:
  import random
  import numpy as np
  import torch
  import hashlib

  class ReproducibilityManager:
      """å®Œå…¨ãªå†ç¾æ€§ã‚’ä¿è¨¼"""

      @staticmethod
      def set_seed(seed: int = 42):
          """å…¨ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã®å›ºå®š"""
          random.seed(seed)
          np.random.seed(seed)
          torch.manual_seed(seed)
          torch.cuda.manual_seed(seed)
          torch.cuda.manual_seed_all(seed)

          # Deterministic operations
          torch.backends.cudnn.deterministic = True
          torch.backends.cudnn.benchmark = False
          torch.use_deterministic_algorithms(True)

          # ç’°å¢ƒå¤‰æ•°ã‚‚è¨­å®š
          os.environ['PYTHONHASHSEED'] = str(seed)
          os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'

      @staticmethod
      def get_code_hash(directory: str) -> str:
          """ã‚³ãƒ¼ãƒ‰ã®ãƒãƒƒã‚·ãƒ¥å€¤è¨ˆç®—"""
          hasher = hashlib.sha256()
          for root, dirs, files in os.walk(directory):
              for file in sorted(files):
                  if file.endswith('.py'):
                      with open(os.path.join(root, file), 'rb') as f:
                          hasher.update(f.read())
          return hasher.hexdigest()

      @staticmethod
      def save_environment():
          """ç’°å¢ƒæƒ…å ±ã®ä¿å­˜"""
          env_info = {
              "python_version": sys.version,
              "torch_version": torch.__version__,
              "cuda_version": torch.version.cuda,
              "cudnn_version": torch.backends.cudnn.version(),
              "numpy_version": np.__version__,
              "random_state": random.getstate(),
              "numpy_random_state": np.random.get_state(),
              "torch_random_state": torch.get_rng_state(),
              "cuda_random_state": torch.cuda.get_rng_state_all() if torch.cuda.is_available() else
  None,
          }

          with open("environment_snapshot.json", "w") as f:
              json.dump(env_info, f, indent=2, default=str)

          # pip freeze
          os.system("pip freeze > requirements_snapshot.txt")

  7. ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³å¯¾å¿œã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

  æ”¹å–„å®Ÿè£…:
  from contextlib import contextmanager
  import signal
  import traceback

  class RobustExecutor:
      """æœ¬ç•ªç’°å¢ƒå‘ã‘ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""

      def __init__(self, config):
          self.config = config
          self.checkpoint_manager = CheckpointManager(config.checkpoint_dir)

      @contextmanager
      def graceful_exit(self):
          """å„ªé›…ãªçµ‚äº†å‡¦ç†"""
          def signal_handler(sig, frame):
              logger.info(f"Received signal {sig}, saving checkpoint...")
              self.checkpoint_manager.save_emergency_checkpoint()
              sys.exit(0)

          signal.signal(signal.SIGINT, signal_handler)
          signal.signal(signal.SIGTERM, signal_handler)

          try:
              yield
          except Exception as e:
              # ã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’ãƒ­ã‚°
              logger.error(f"Fatal error: {e}")
              logger.error(traceback.format_exc())

              # ç·Šæ€¥ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
              self.checkpoint_manager.save_emergency_checkpoint()

              # Slackã‚„ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
              if self.config.enable_notifications:
                  self.send_error_notification(e)

              raise

      def auto_recover(self, func, max_retries=3):
          """è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼æ©Ÿèƒ½"""
          for attempt in range(max_retries):
              try:
                  return func()
              except torch.cuda.OutOfMemoryError:
                  logger.warning(f"OOM on attempt {attempt + 1}, clearing cache...")
                  torch.cuda.empty_cache()
                  gc.collect()

                  # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’åŠåˆ†ã«
                  if hasattr(self.config, 'batch_size'):
                      self.config.batch_size //= 2
                      logger.info(f"Reduced batch size to {self.config.batch_size}")
              except Exception as e:
                  if attempt == max_retries - 1:
                      raise
                  logger.warning(f"Attempt {attempt + 1} failed: {e}, retrying...")
                  time.sleep(2 ** attempt)  # Exponential backoff

  ã“ã‚Œã‚‰ã®è©³ç´°ãªæ”¹å–„ã«ã‚ˆã‚Šã€ä»¥ä¸‹ã®åŠ¹æœãŒæœŸå¾…ã§ãã¾ã™ï¼š

  - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: 30-50%å‰Šæ¸›
  - å­¦ç¿’é€Ÿåº¦: 2-3å€é«˜é€ŸåŒ–
  - å­¦ç¿’å®‰å®šæ€§: å‹¾é…çˆ†ç™º/æ¶ˆå¤±ã®é˜²æ­¢
  - ãƒ‡ãƒãƒƒã‚°åŠ¹ç‡: 10å€å‘ä¸Šï¼ˆè©³ç´°ãƒ­ã‚®ãƒ³ã‚°ï¼‰
  - å†ç¾æ€§: 100%ä¿è¨¼
  - æœ¬ç•ªç¨¼åƒç‡: 99.9%ä»¥ä¸Šï¼ˆè‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼ï¼‰