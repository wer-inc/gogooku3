# 2025年Q1 gogooku5データセット生成完了レポート

**生成日時**: 2025-11-17 22:33-22:40 (約7分)
**チャンク**: 2025Q1
**期間**: 2025-01-06 ～ 2025-03-31

---

## ✅ 生成結果サマリー

### 📊 データセット統計

| 項目 | 値 |
|------|-----|
| **総行数** | 218,624 行 |
| **カラム数** | 4,207 カラム |
| **銘柄数** | 3,863 銘柄 |
| **取引日数** | 57 日 |
| **平均銘柄数/日** | 3,836 銘柄 |
| **期間** | 2025-01-06 ～ 2025-03-31 |

### 💾 ファイルサイズ

- **Parquet**: 1,549.1 MB (標準フォーマット)
- **Arrow IPC**: 1,980.4 MB (高速読み込み用、3-5倍速)
- **メタデータ**: 358 KB
- **合計**: 約3.5 GB

### 📁 出力場所

```
output_g5/chunks/2025Q1/
├── ml_dataset.parquet     (1.6 GB) - メインデータセット
├── ml_dataset.arrow       (2.0 GB) - 高速読み込み用
├── metadata.json          (358 KB) - ビルドメタデータ
└── status.json            (286 B)  - ステータス情報
```

---

## 🔧 特徴量構成

### 予測ターゲット（リターン）

| ターゲット | 非NULL件数 | 説明 |
|-----------|----------|------|
| `ret_prev_1d` | 212,093 | 1日後リターン |
| `ret_prev_5d` | 196,740 | 5日後リターン |
| `ret_prev_10d` | 177,696 | 10日後リターン |
| `ret_prev_20d` | 139,850 | 20日後リターン |
| `ret_prev_60d` | 0 | 60日後リターン（期間不足）|
| `ret_prev_120d` | 0 | 120日後リターン（期間不足）|

### 主要特徴量グループ（上位15）

| グループ | カラム数 | 説明 |
|---------|---------|------|
| `mkt_*` | 455 | マーケット関連（市場全体の指標）|
| `topix_*` | 350 | TOPIX関連（指数データ）|
| `wm_*` | 244 | 加重平均関連 |
| `idx_*` | 148 | 各種インデックス |
| `idxopt_*` | 132 | インデックスオプション（NK225等）|
| `ssp_*` | 123 | セクターショートポジション |
| `is_*` | 94 | 損益計算書データ |
| `sec_*` | 94 | セクター関連 |
| `days_*` | 88 | 日数関連特徴量 |
| `close_*` | 87 | 終値関連（技術指標）|
| `volume_*` | 76 | 出来高関連 |
| `morning_*` | 68 | 午前セッション |
| `afternoon_*` | 68 | 午後セッション |
| `ema_*` | 66 | 指数移動平均 |
| `preE_*` | 66 | イベント前特徴量 |

**合計**: 4,207カラム（全特徴量 + メタデータ）

---

## 📈 データ品質

### ✅ 良好な指標

- **日付範囲**: 正確（2025年Q1をカバー）
- **銘柄カバレッジ**: 3,863銘柄（東証主要銘柄を網羅）
- **取引日数**: 57日（2025年Q1の全取引日）
- **主要リターンターゲット**: 適切に計算済み（1d, 5d, 10d, 20d）

### ⚠️ 注意事項

1. **信用取引データ（dmi_*）のNULL率**: 90%
   - **理由**: すべての銘柄で信用取引が行われているわけではない
   - **影響**: 正常な挙動（信用取引可能銘柄のみにデータが存在）

2. **長期リターン（60d, 120d）のNULL**: 100%
   - **理由**: Q1期間（3ヶ月）では60日後/120日後のデータが存在しない
   - **対策**: より長期のデータセット（通年データ）で計算可能

---

## ⚡ 生成パフォーマンス

### データ取得フェーズ（約2分）

- **並列フェッチ**: 200ワーカー
- **月次データ取得**: 8ヶ月分（2024年8月～2025年3月）
- **平均取得速度**: 約8秒/月（並列化により高速）
- **取得レコード数**: 541,146件（生データ）

### 特徴量エンジニアリングフェーズ（約5分）

- **GPU-ETL**: 有効（RMM pool 10GB）
- **GPU処理**: ローリング特徴量、相関グラフ計算
- **As-ofジョイン**: 8回（財務諸表、配当、アーニングス等）
  - 財務諸表（fs）: T+1 as-of
  - 配当（div）: T+1 as-of
  - アーニングス（earn）: T+1 as-of
  - ブレークダウン（bd）: T+1 as-of
  - 上場情報（listed）: T+1 as-of
  - 信用取引（dmi）: T+1 as-of
  - 空売り（ssp）: T+1 as-of
  - インデックスオプション（idxopt）: T+1 as-of

### 総所要時間

- **開始**: 22:33:59
- **完了**: 22:40:46
- **所要時間**: 約7分

---

## 🔍 技術詳細

### スキーマバージョン

- **バージョン**: 1.6.0
- **スキーマハッシュ**: e8eed6163ec92385

### セキュリティID（SecId）

- **SecId範囲**: 1-5088
- **Dim Security**: 5,088銘柄マスター
- **最適化**: カテゴリカル型（int32 → 8-bit encoding）

### GPU-ETL設定

- **RMM Pool**: 10GB
- **GPU**: NVIDIA A100-SXM4-80GB
- **処理**: ローリング特徴量、相関計算、グラフ構築

### キャッシュ最適化

- **スキーマミスマッチ検出**: 8ヶ月分のキャッシュを再取得
- **Raw スナップショット保存**: 各月次データを `output_g5/raw/prices/` に保存
- **Arrow IPC**: 高速読み込み用フォーマット（3-5倍速）

---

## 🎯 使用方法

### データセットの読み込み

```python
import polars as pl

# Parquet（標準）
df = pl.read_parquet("output_g5/chunks/2025Q1/ml_dataset.parquet")

# Arrow IPC（高速）
df = pl.read_ipc("output_g5/chunks/2025Q1/ml_dataset.arrow")

print(f"Rows: {len(df):,}, Columns: {len(df.columns):,}")
```

### ターゲットとフィーチャーの分離

```python
# ターゲット列
targets = ['ret_prev_1d', 'ret_prev_5d', 'ret_prev_10d', 'ret_prev_20d']

# フィーチャー列（ターゲット以外）
features = [c for c in df.columns if c not in targets + ['Date', 'Code']]

X = df.select(features)
y = df.select(targets)
```

### 訓練・検証分割

```python
# 時系列分割（最後の2週間を検証用）
train_df = df.filter(pl.col('Date') < pl.date(2025, 3, 17))
val_df = df.filter(pl.col('Date') >= pl.date(2025, 3, 17))

print(f"Train: {len(train_df):,} rows")
print(f"Val: {len(val_df):,} rows")
```

---

## 📋 次のステップ

### 推奨タスク

1. **データセットのマージ**:
   ```bash
   # 他の四半期データと結合して通年データセットを作成
   python gogooku5/data/tools/merge_chunks.py \
     --chunks-dir output_g5/chunks \
     --output output_g5/ml_dataset_2025_full.parquet
   ```

2. **データ品質検証**:
   ```bash
   # 詳細な品質チェック
   python gogooku5/data/tools/check_dataset_quality.py \
     --dataset output_g5/chunks/2025Q1/ml_dataset.parquet \
     --targets ret_prev_1d,ret_prev_5d,ret_prev_10d,ret_prev_20d
   ```

3. **モデル訓練**:
   ```bash
   # APEX-Rankerでの訓練
   cd models/apex_ranker
   make train DATASET=../../output_g5/chunks/2025Q1/ml_dataset.parquet
   ```

---

## ✅ 結論

2025年Q1のgogooku5データセットが正常に生成されました。

**主要成果**:
- ✅ 218,624行 × 4,207カラムの高品質データセット
- ✅ 3,863銘柄 × 57取引日の完全カバレッジ
- ✅ GPU-ETL最適化により約7分で生成完了
- ✅ Parquet + Arrow IPC両フォーマットで保存
- ✅ As-ofジョインによる時系列安全性確保

**今後の展望**:
- 2025年Q2-Q4データを追加生成し、通年データセット構築
- 長期リターン（60d, 120d）の計算には通年データが必要
- モデル訓練・バックテストでの活用

---

**生成完了時刻**: 2025-11-17 22:40:46 JST
**レポート作成**: 2025-11-17 22:45:00 JST

