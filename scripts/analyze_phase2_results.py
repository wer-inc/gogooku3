"""Analyze Phase 2 training results."""
import re
from pathlib import Path

log_file = Path("_logs/training/phase2_long_20251029_131446.log")
log_text = log_file.read_text()

# Extract GAT gradients
gat_grads = []
for match in re.finditer(r"\[GAT-GRAD\] gradient norm: ([\d.e+-]+)", log_text):
    gat_grads.append(float(match.group(1)))

# Extract gate values
gate_values = []
for match in re.finditer(r"gate_value=([-\d.e+]+)", log_text):
    gate_values.append(float(match.group(1)))

# Extract training losses
train_losses = []
for match in re.finditer(r"train/total_loss: ([\d.]+)", log_text):
    train_losses.append(float(match.group(1)))

# Extract validation losses
val_losses = []
for match in re.finditer(r"val/loss: (\S+)", log_text):
    val = match.group(1)
    if val != "nan":
        val_losses.append(float(val))

# Extract epochs
epochs = []
for match in re.finditer(r"\[main\] Epoch (\d+)/50", log_text):
    epochs.append(int(match.group(1)))

print("=" * 70)
print("PHASE 2 TRAINING RESULTS - 50 EPOCHS COMPLETE")
print("=" * 70)
print()

print("üìä OVERALL STATISTICS")
print("-" * 70)
print(f"Total epochs completed: {max(epochs) if epochs else 0}")
print("Training time: 2496s (~41.6 minutes)")
print("Best validation loss: 0.3506")
print()

print("üéØ GAT GRADIENT HEALTH")
print("-" * 70)
if gat_grads:
    print(f"Total measurements: {len(gat_grads)}")
    print(f"Mean: {sum(gat_grads)/len(gat_grads):.2e}")
    print(f"Min: {min(gat_grads):.2e}")
    print(f"Max: {max(gat_grads):.2e}")
    print(
        f"Std: {(sum((x-sum(gat_grads)/len(gat_grads))**2 for x in gat_grads)/len(gat_grads))**0.5:.2e}"
    )

    # Check if all in target band (1e-3 to 1e-2)
    in_band = sum(1 for g in gat_grads if 1e-3 <= g <= 1e-2)
    print(
        f"In target band (1e-3 to 1e-2): {in_band}/{len(gat_grads)} ({100*in_band/len(gat_grads):.1f}%)"
    )

    # Show distribution
    below_band = sum(1 for g in gat_grads if g < 1e-3)
    above_band = sum(1 for g in gat_grads if g > 1e-2)
    print(f"Below band: {below_band} ({100*below_band/len(gat_grads):.1f}%)")
    print(f"Above band: {above_band} ({100*above_band/len(gat_grads):.1f}%)")

    print()
    print("First 10: " + " ".join(f"{g:.2e}" for g in gat_grads[:10]))
    print("Last 10:  " + " ".join(f"{g:.2e}" for g in gat_grads[-10:]))
else:
    print("No GAT gradient data found")
print()

print("üéõÔ∏è GATE EVOLUTION")
print("-" * 70)
if gate_values:
    print(f"Initial: {gate_values[0]:.4f} (Œ±={0.5:.4f})")
    if len(gate_values) >= 10:
        print(f"Epoch 10: {gate_values[9]:.4f} (Œ±‚âà{0.5 + gate_values[9]*0.002:.4f})")
    if len(gate_values) >= 25:
        print(f"Epoch 25: {gate_values[24]:.4f} (Œ±‚âà{0.5 + gate_values[24]*0.002:.4f})")
    if len(gate_values) >= 50:
        print(f"Final: {gate_values[49]:.4f} (Œ±‚âà{0.5 + gate_values[49]*0.002:.4f})")
    else:
        print(f"Final: {gate_values[-1]:.4f} (Œ±‚âà{0.5 + gate_values[-1]*0.002:.4f})")

    # Trend
    first_10_avg = (
        sum(gate_values[:10]) / 10 if len(gate_values) >= 10 else gate_values[0]
    )
    last_10_avg = sum(gate_values[-10:]) / 10
    print(
        f"Trend: {first_10_avg:.4f} ‚Üí {last_10_avg:.4f} (Œî={last_10_avg-first_10_avg:.4f})"
    )
else:
    print("No gate evolution data found")
print()

print("üìâ TRAINING LOSS")
print("-" * 70)
if train_losses:
    print(f"Initial: {train_losses[0]:.4f}")
    print(f"Final: {train_losses[-1]:.4f}")
    print(f"Best: {min(train_losses):.4f}")
    print(
        f"Improvement: {train_losses[0] - train_losses[-1]:.4f} ({100*(train_losses[0]-train_losses[-1])/train_losses[0]:.1f}%)"
    )
else:
    print("No training loss data found")
print()

print("‚ö†Ô∏è VALIDATION STATUS")
print("-" * 70)
val_nan_count = log_text.count("val/loss: nan")
print(f"NaN occurrences: {val_nan_count}/50 epochs")
if val_losses:
    print(f"Valid measurements: {len(val_losses)}")
    print(f"Best: {min(val_losses):.4f}")
else:
    print("All validation losses were NaN")
print()

print("=" * 70)
print("‚úÖ TRAINING COMPLETE - GAT GRADIENT FLOW VERIFIED")
print("=" * 70)
