#!/usr/bin/env python3
# DEPRECATED: Moved to scripts/_archive on 2025-09-04
"""
4000éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã‚’ATFTå½¢å¼ã«å¤‰æ›ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
632éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã¨åŒã˜å½¢å¼ã«å¤‰æ›
"""

import logging
from pathlib import Path

import pandas as pd

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def convert_4000_stocks_to_atft_format():
    """4000éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã‚’ATFTå½¢å¼ã«å¤‰æ›"""

    logger.info("ğŸš€ 4000éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã‚’ATFTå½¢å¼ã«å¤‰æ›é–‹å§‹")

    # 4000éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data_4000_path = Path("output/ml_dataset_4000_stocks_extended.parquet")
    if not data_4000_path.exists():
        raise FileNotFoundError(f"4000éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_4000_path}")

    df_4000 = pd.read_parquet(data_4000_path)
    logger.info(f"ğŸ“Š 4000éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {df_4000.shape[0]:,}è¡Œ Ã— {df_4000.shape[1]}åˆ—")

    # 632éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨ã—ã¦ä½¿ç”¨ï¼‰
    data_632_path = Path("output/ml_dataset_632_stocks.parquet")
    if not data_632_path.exists():
        raise FileNotFoundError(f"632éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_632_path}")

    df_632 = pd.read_parquet(data_632_path)
    logger.info(f"ğŸ“‹ 632éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {df_632.shape[0]:,}è¡Œ Ã— {df_632.shape[1]}åˆ—")

    # å¿…è¦ãªã‚«ãƒ©ãƒ ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    column_mapping = {
        'Code': 'Code',
        'date': 'Date',
        'Close': 'Close',
        'Open': 'Open',
        'High': 'High',
        'Low': 'Low',
        'Volume': 'Volume',
        'returns_1d': 'returns_1d',
        'returns_5d': 'returns_5d',
        'returns_10d': 'returns_10d',
        'returns_20d': 'returns_20d',
        'ema_5': 'ema_5',
        'ema_10': 'ema_10',
        'ema_20': 'ema_20',
        'rsi_14': 'rsi_14'
    }

    # 4000éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã«632éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã®ã‚«ãƒ©ãƒ æ§‹é€ ã‚’é©ç”¨
    df_converted = df_4000.copy()

    # ã‚«ãƒ©ãƒ åã‚’çµ±ä¸€
    df_converted = df_converted.rename(columns=column_mapping)

    # 632éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹ãŒ4000éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã«ãªã„ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
    missing_columns = []
    for col in df_632.columns:
        if col not in df_converted.columns:
            if col in ['row_idx']:
                # row_idxã¯è‡ªå‹•ç”Ÿæˆ
                df_converted[col] = range(len(df_converted))
            elif 'target' in col.lower():
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé–¢é€£ã‚«ãƒ©ãƒ 
                if 'target' not in df_converted.columns:
                    df_converted[col] = df_converted.get('target', 0)
                else:
                    df_converted[col] = df_converted['target']
            else:
                # ãã®ä»–ã®æ¬ æã‚«ãƒ©ãƒ ã¯0ã§åŸ‹ã‚ã‚‹
                df_converted[col] = 0
                missing_columns.append(col)

    logger.info(f"âœ… æ¬ æã‚«ãƒ©ãƒ ã‚’è¿½åŠ : {len(missing_columns)}å€‹")
    if missing_columns:
        logger.info(f"   è¿½åŠ ã•ã‚ŒãŸã‚«ãƒ©ãƒ : {missing_columns[:10]}{'...' if len(missing_columns) > 10 else ''}")

    # ãƒ‡ãƒ¼ã‚¿å‹ã®çµ±ä¸€
    for col in df_converted.columns:
        if col in df_632.columns:
            # 632éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã¨åŒã˜ãƒ‡ãƒ¼ã‚¿å‹ã«åˆã‚ã›ã‚‹
            df_converted[col] = df_converted[col].astype(df_632[col].dtype)

    # æ¬ æå€¤å‡¦ç†
    df_converted = df_converted.fillna(method='ffill').fillna(method='bfill').fillna(0)

    # æœ€çµ‚ç¢ºèª
    logger.info(f"ğŸ“Š å¤‰æ›å¾Œãƒ‡ãƒ¼ã‚¿: {df_converted.shape[0]:,}è¡Œ Ã— {df_converted.shape[1]}åˆ—")
    logger.info(f"ğŸ·ï¸  éŠ˜æŸ„æ•°: {df_converted['Code'].nunique()}")

    # å¤‰æ›çµæœã‚’ä¿å­˜
    output_path = Path("output/ml_dataset_4000_atft_format.parquet")
    df_converted.to_parquet(output_path, index=False)
    logger.info(f"ğŸ’¾ å¤‰æ›ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {output_path}")

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚‚ä¿å­˜
    metadata = {
        'original_shape': df_4000.shape,
        'converted_shape': df_converted.shape,
        'num_stocks': df_converted['Code'].nunique(),
        'columns_added': len(missing_columns),
        'missing_values_after_conversion': df_converted.isnull().sum().sum()
    }

    metadata_path = Path("output/ml_dataset_4000_atft_format_metadata.json")
    import json
    with open(metadata_path, 'w') as f:
        json.dump(metadata, f, indent=2, default=str)

    logger.info(f"ğŸ“‹ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {metadata_path}")
    logger.info("âœ… 4000éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿â†’ATFTå½¢å¼å¤‰æ›å®Œäº†")

    return str(output_path)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        output_path = convert_4000_stocks_to_atft_format()
        print("\nğŸ‰ å¤‰æ›æˆåŠŸï¼")
        print(f"ğŸ“ å¤‰æ›å¾Œãƒ‡ãƒ¼ã‚¿: {output_path}")
        print("\næ¬¡ã«ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§4000éŠ˜æŸ„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã§ãã¾ã™:")
        print(f"cp {output_path} output/ml_dataset_production.parquet")
        print("python main.py complete-atft")
    except Exception as e:
        logger.error(f"âŒ å¤‰æ›å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
