# As-of Join Implementation Guide

## Phase 2 Patch D: Complete Implementation for Margin/Short/Flow Data

This guide shows how to implement T+1 as-of joins for weekly/snapshot data with actual column names from gogooku5 dataset.

---

## 1. Data Structure Overview

### Current Cache Files and Columns

**Margin (Weekly)**: `margin_weekly_*.parquet`
- `Date`: Trading date
- `Code`: Stock code
- `PublishedDate`: Publication date (T+1 trigger)
- `ShortMarginTradeVolume`, `LongMarginTradeVolume`, etc.

**Short Selling**: `short_*.parquet`
- `Date`: Trading date
- `Code`: Stock code
- `PublishedDate`: Publication date (T+1 trigger)
- `ShortSellingVolume`, `ShortSellingRatio`, etc.

**Flow/Trades**: `trades_spec_*.parquet`
- `PublishedDate`: Publication date
- `StartDate`, `EndDate`: Period
- `Section`: Market section
- `ProprietarySales`, `ForeignersPurchases`, etc.

---

## 2. Implementation Pattern

### Step 1: Add `asof_ts` to Backbone

```python
from ..features.utils import add_asof_timestamp

# In dataset_builder.py build() method, after aligned_quotes is created:
combined_df = add_asof_timestamp(aligned_quotes, date_col="date")
# Note: column name is "date" (lowercase) in pipeline, "Date" in final output
```

**What this does**:
- Converts `date` column to datetime at 15:00 JST
- Adds `asof_ts` column: when the trading day's data becomes available
- Example: `date=2025-01-06` ‚Üí `asof_ts=2025-01-06 15:00:00+09:00`

---

### Step 2: Prepare Snapshot Data with T+1 Availability

```python
from ..features.utils import prepare_snapshot_pl, interval_join_pl

# Example: Margin weekly data
margin_df = self._fetch_margin_data(start=start, end=end)

# Prepare margin data with T+1 availability
# Data published on day T becomes available at T+1 09:00 JST
margin_prepared = prepare_snapshot_pl(
    margin_df,
    published_date_col="PublishedDate",
    trading_calendar=calendar_df,  # Pass trading calendar for accurate business day calculation
    availability_hour=9,
    availability_minute=0,
)
```

**What this does**:
- Finds `PublishedDate` in margin data
- Calculates next business day using trading calendar
- Adds `available_ts` column: T+1 09:00 JST
- Example: `PublishedDate=2025-01-06` ‚Üí `available_ts=2025-01-07 09:00:00+09:00`

---

### Step 3: Perform As-of Join with T-leak Detection

```python
# Join margin data to backbone
combined_df = interval_join_pl(
    backbone=combined_df,
    snapshot=margin_prepared,
    on_code="code",
    backbone_ts="asof_ts",
    snapshot_ts="available_ts",
    strategy="backward",  # Use latest past data
    suffix="_margin",
)
```

**What this does**:
- Sorts both dataframes by `(code, timestamp)` (mandatory for join_asof)
- Joins margin data where `available_ts <= asof_ts`
- Detects T-leaks: raises ValueError if any `available_ts_margin > asof_ts`
- Adds margin columns with `_margin` suffix

---

## 3. Complete Example: dataset_builder.py Integration

```python
def build(self, *, start: str, end: str, refresh_listed: bool = False) -> Path:
    """Build the dataset with as-of joins for T+1 data availability."""

    # ... existing code (fetch quotes, calendar, etc.) ...

    aligned_quotes = self._align_quotes_with_calendar(quotes_df, calendar_df, listed_df)

    # ========================================================================
    # Phase 2 Patch D: Add asof_ts for T+1 data availability
    # ========================================================================
    combined_df = add_asof_timestamp(aligned_quotes, date_col="date")
    LOGGER.info("[PATCH D] Added asof_ts column for temporal joins (15:00 JST)")

    # ========================================================================
    # Apply as-of joins for weekly/snapshot data
    # ========================================================================

    # 1) Margin data (weekly, published with delay)
    margin_df = self._fetch_margin_data(start=start, end=end)
    if margin_df.height > 0:
        margin_prepared = prepare_snapshot_pl(
            margin_df,
            published_date_col="PublishedDate",
            trading_calendar=calendar_df,
            availability_hour=9,
        )
        combined_df = interval_join_pl(
            backbone=combined_df,
            snapshot=margin_prepared,
            on_code="code",
            suffix="_margin",
        )
        LOGGER.info("[PATCH D] Joined margin data with T+1 as-of join")

    # 2) Short selling data (daily, published with delay)
    short_df = self._fetch_short_selling_data(start=start, end=end)
    if short_df.height > 0:
        short_prepared = prepare_snapshot_pl(
            short_df,
            published_date_col="PublishedDate",
            trading_calendar=calendar_df,
            availability_hour=9,
        )
        combined_df = interval_join_pl(
            backbone=combined_df,
            snapshot=short_prepared,
            on_code="code",
            suffix="_short",
        )
        LOGGER.info("[PATCH D] Joined short selling data with T+1 as-of join")

    # 3) Flow/Trades data (weekly, section-level aggregates)
    # Note: Flow data is section-level, not stock-level
    # Join on (Section, date) instead of (code, date)
    flow_df = self.data_sources.trades_spec(start=start, end=end)
    if flow_df.height > 0:
        # Map flow data to stocks via section
        # Implementation depends on how you want to propagate section-level data to stocks
        # Option A: Broadcast section data to all stocks in that section
        # Option B: Create section-level features and join separately
        pass  # Implement based on your needs

    # ... rest of feature engineering pipeline ...

    # ========================================================================
    # Phase 2 Patch D: Remove metadata columns before finalization
    # ========================================================================
    # Remove as-of metadata columns (only needed for validation, not for training)
    meta_columns = [
        "asof_ts",
        "available_ts_margin",
        "available_ts_short",
        "PublishedDate",  # Original published dates
    ]
    combined_df = combined_df.drop([c for c in meta_columns if c in combined_df.columns])

    # ... finalize and persist ...

    return artifact.latest_symlink
```

---

## 4. Testing the Implementation

### Test Script: Verify As-of Join Correctness

```python
import polars as pl
from pathlib import Path

# Load result dataset
df = pl.read_parquet("output/ml_dataset_latest_full.parquet")

print(f"Dataset: {df.height:,} rows √ó {df.width:,} columns")

# Check for T+1 columns (should exist if as-of join was applied)
margin_cols = [c for c in df.columns if "_margin" in c or "margin" in c.lower()]
short_cols = [c for c in df.columns if "_short" in c or "short" in c.lower()]

print(f"\nüìä Margin columns: {len(margin_cols)}")
print(f"   Sample: {margin_cols[:5]}")

print(f"\nüìä Short selling columns: {len(short_cols)}")
print(f"   Sample: {short_cols[:5]}")

# Verify no metadata columns leaked into final output
metadata_cols = ["asof_ts", "available_ts", "PublishedDate"]
leaked = [c for c in metadata_cols if c in df.columns]

if leaked:
    print(f"\n‚ö†Ô∏è  WARNING: Metadata columns found in output: {leaked}")
else:
    print(f"\n‚úÖ No metadata columns in output (correctly removed)")
```

---

## 5. Expected Behavior

### Before As-of Join (Current State)
- Margin data joined by `(code, date)` directly
- **Problem**: Data published on day T is used on day T (T-leak!)
- Example: Margin data published 2025-01-06 afternoon ‚Üí used for 2025-01-06 predictions

### After As-of Join (Patch D)
- Margin data joined by `(code, asof_ts)` with T+1 availability
- **Correct**: Data published on day T is available on T+1
- Example: Margin data published 2025-01-06 afternoon ‚Üí available 2025-01-07 09:00

---

## 6. Common Pitfalls

### ‚ùå Wrong: Direct join by date

```python
# DON'T DO THIS - T-leak!
combined_df = combined_df.join(
    margin_df,
    on=["code", "date"],  # PublishedDate = Date ‚Üí T-leak!
    how="left"
)
```

### ‚úÖ Right: As-of join with T+1 availability

```python
# Correct approach
margin_prepared = prepare_snapshot_pl(margin_df, published_date_col="PublishedDate")
combined_df = interval_join_pl(
    backbone=combined_df,
    snapshot=margin_prepared,
    on_code="code",
)
```

---

## 7. Next Steps

1. ‚úÖ **Implement as-of joins** for margin, short, flow data
2. ‚úÖ **Test with small dataset** (START=2025-01-06, END=2025-01-07)
3. ‚úÖ **Verify T-leak detection** (should raise ValueError if misconfigured)
4. ‚úÖ **Run smoke test** to confirm no metadata columns in output
5. ‚úÖ **Full dataset rebuild** with as-of joins enabled
6. ‚úÖ **Mini backtest** to verify realistic return range (20-100%)

---

## 8. Environment Variables

```bash
# Enable as-of joins (controlled in dataset_builder.py)
export ENABLE_ASOF_JOINS=1

# ADV filter (optional, recommended)
export MIN_ADV_YEN=50000000

# Fast axis for large symbol counts
export FETCH_AXIS=by_date
```

---

## Contact

For questions or issues with as-of join implementation, check:
- `src/builder/features/utils/asof_join.py` - Core utilities
- `src/builder/pipelines/dataset_builder.py` - Integration example
- This guide (ASOF_JOIN_IMPLEMENTATION_GUIDE.md)
