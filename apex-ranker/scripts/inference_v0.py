#!/usr/bin/env python3
"""
APEX-Ranker v0 Inference Script

Minimal inference implementation for production deployment.
Loads a trained model and generates stock rankings for a given date.

Usage:
    python scripts/inference_v0.py \\
        --model models/apex_ranker_v0_enhanced.pt \\
        --config configs/v0_base.yaml \\
        --date 2025-10-29 \\
        --output predictions_20251029.csv

Author: Generated by Claude Code
Date: 2025-10-29
"""
from __future__ import annotations

import argparse
import warnings
from datetime import datetime
from pathlib import Path
from typing import Any

import numpy as np
import polars as pl
import torch

from apex_ranker.data import (
    FeatureSelector,
    add_cross_sectional_zscores,
    build_panel_cache,
)
from apex_ranker.models import APEXRankerV0
from apex_ranker.utils import load_config

warnings.filterwarnings("ignore")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="APEX-Ranker v0 Inference - Generate stock rankings"
    )
    parser.add_argument(
        "--model",
        required=True,
        help="Path to trained model checkpoint (.pt file)",
    )
    parser.add_argument(
        "--config",
        required=True,
        help="Path to model config YAML file",
    )
    parser.add_argument(
        "--data",
        default="output/ml_dataset_latest_full.parquet",
        help="Path to input parquet dataset (default: output/ml_dataset_latest_full.parquet)",
    )
    parser.add_argument(
        "--date",
        default=None,
        help="Target date for prediction (YYYY-MM-DD). If not specified, uses most recent date in dataset.",
    )
    parser.add_argument(
        "--top-k",
        type=int,
        default=50,
        help="Number of top-ranked stocks to output (default: 50)",
    )
    parser.add_argument(
        "--horizon",
        type=int,
        default=20,
        choices=[1, 5, 10, 20],
        help="Prediction horizon in days (default: 20)",
    )
    parser.add_argument(
        "--output",
        default=None,
        help="Output CSV file path. If not specified, prints to stdout.",
    )
    parser.add_argument(
        "--device",
        default="cuda",
        choices=["cuda", "cpu", "auto"],
        help="Device for inference (default: cuda)",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose logging",
    )
    return parser.parse_args()


def resolve_device(device_str: str) -> torch.device:
    """Resolve device string to torch.device."""
    if device_str == "auto":
        device_str = "cuda" if torch.cuda.is_available() else "cpu"
    return torch.device(device_str)


def load_model_checkpoint(
    model_path: str | Path,
    config: dict,
    device: torch.device,
) -> APEXRankerV0:
    """Load trained model from checkpoint."""
    model_path = Path(model_path)
    if not model_path.exists():
        raise FileNotFoundError(f"Model checkpoint not found: {model_path}")

    # Get feature count from config
    data_cfg = config["data"]
    groups = list(data_cfg.get("feature_groups", []))
    if data_cfg.get("use_plus30"):
        groups.append("plus30")

    feature_selector = FeatureSelector(data_cfg["feature_groups_config"])

    # Apply exclusions if specified
    exclude_features = data_cfg.get("exclude_features", None)

    selection = feature_selector.select(
        groups=groups,
        optional_groups=data_cfg.get("optional_groups", []),
        exclude_features=exclude_features,
    )
    n_features = len(selection.features)

    # Initialize model
    model_cfg = config["model"]
    horizons = config["train"]["horizons"]

    model = APEXRankerV0(
        in_features=n_features,
        horizons=horizons,
        d_model=model_cfg["d_model"],
        depth=model_cfg["depth"],
        patch_len=model_cfg["patch_len"],
        stride=model_cfg["stride"],
        n_heads=model_cfg["n_heads"],
        dropout=model_cfg.get("dropout", 0.1),
    ).to(device)

    # Load state dict
    state_dict = torch.load(model_path, map_location=device)
    model.load_state_dict(state_dict)
    model.eval()

    return model


def prepare_features(
    data_path: str | Path,
    config: dict,
    target_date: str | None = None,
    verbose: bool = False,
) -> tuple[torch.Tensor, list[str], str]:
    """
    Prepare feature tensor for inference.

    Returns:
        (features_tensor, stock_codes, actual_date)
    """
    data_path = Path(data_path)
    if not data_path.exists():
        raise FileNotFoundError(f"Dataset not found: {data_path}")

    data_cfg = config["data"]
    date_col = data_cfg["date_column"]
    code_col = data_cfg["code_column"]

    # Feature selection
    groups = list(data_cfg.get("feature_groups", []))
    if data_cfg.get("use_plus30"):
        groups.append("plus30")

    feature_selector = FeatureSelector(data_cfg["feature_groups_config"])

    # Apply exclusions
    exclude_features = data_cfg.get("exclude_features", None)
    if exclude_features and verbose:
        print(f"[Inference] Excluding {len(exclude_features)} features")

    selection = feature_selector.select(
        groups=groups,
        optional_groups=data_cfg.get("optional_groups", []),
        exclude_features=exclude_features,
    )

    # Load data
    required_columns = [date_col, code_col] + selection.features
    frame = pl.read_parquet(data_path, columns=required_columns)

    # Determine target date
    if target_date is None:
        target_date = frame[date_col].max()
        if verbose:
            print(f"[Inference] Using most recent date: {target_date}")
    else:
        target_date_parsed = datetime.strptime(target_date, "%Y-%m-%d").date()
        available_dates = frame[date_col].unique().sort()
        if target_date_parsed not in available_dates:
            closest = min(available_dates, key=lambda d: abs((d - target_date_parsed).days))
            print(f"[Warning] Date {target_date} not found. Using closest: {closest}")
            target_date = closest
        else:
            target_date = target_date_parsed

    # Apply cross-sectional normalization
    if verbose:
        print(f"[Inference] Applying cross-sectional Z-score normalization...")

    frame = add_cross_sectional_zscores(
        frame,
        columns=selection.features,
        date_col=date_col,
        clip_sigma=config.get("normalization", {}).get("clip_sigma", 5.0),
    )

    z_features = [f"{col}_cs_z" for col in selection.features]

    # Build panel cache
    lookback = data_cfg["lookback"]
    if verbose:
        print(f"[Inference] Building panel cache (lookback={lookback})")

    cache = build_panel_cache(
        frame,
        feature_cols=z_features,
        target_cols=[],  # No targets needed for inference
        mask_cols=[],
        date_col=date_col,
        code_col=code_col,
        lookback=lookback,
        min_stocks_per_day=0,  # Allow any number for inference
    )

    # Extract features for target date
    target_date_int = int(np.datetime64(target_date, "D").astype("int64"))

    if target_date_int not in cache.date_to_codes:
        raise ValueError(
            f"Target date {target_date} is not available in cache. "
            f"Need {lookback} days of lookback history."
        )

    # Get stock codes for this date
    stock_codes = cache.date_to_codes[target_date_int]

    # Extract features for each stock
    features_list = []
    valid_codes = []
    for code in stock_codes:
        payload = cache.codes[code]
        dates = payload["dates"]
        idx = np.searchsorted(dates, target_date_int)
        if idx == len(dates) or dates[idx] != target_date_int:
            continue
        start = idx - lookback + 1
        if start < 0:
            continue
        window = payload["features"][start : idx + 1]  # Shape: (lookback, n_features)
        features_list.append(window)
        valid_codes.append(code)

    features_array = np.stack(features_list, axis=0)  # Shape: (N_stocks, lookback, n_features)
    stock_codes = valid_codes

    # Convert to tensor
    features_tensor = torch.from_numpy(features_array).float()

    if verbose:
        print(f"[Inference] Loaded {len(stock_codes)} stocks for date {target_date}")
        print(f"[Inference] Feature shape: {features_tensor.shape}")

    return features_tensor, stock_codes, str(target_date)


def generate_rankings(
    model: APEXRankerV0,
    features: torch.Tensor,
    stock_codes: list[str],
    horizon: int,
    device: torch.device,
    top_k: int | None = None,
) -> pl.DataFrame:
    """
    Generate stock rankings using the model.

    Returns:
        DataFrame with columns: [Code, Rank, Score, Horizon]
    """
    # Move to device
    features = features.to(device)

    # Inference
    with torch.no_grad():
        output = model(features)  # Dict[int, torch.Tensor]

    # Extract predictions for specified horizon
    if horizon not in output:
        available = list(output.keys())
        raise ValueError(
            f"Horizon {horizon}d not available. Available horizons: {available}"
        )

    predictions = output[horizon]  # Shape: (N_stocks,)
    scores = predictions.cpu().numpy()

    # Create ranking
    ranked_indices = np.argsort(scores)[::-1]  # Descending order

    if top_k is not None:
        ranked_indices = ranked_indices[:top_k]

    ranked_codes = [stock_codes[i] for i in ranked_indices]
    ranked_scores = [float(scores[i]) for i in ranked_indices]
    ranks = list(range(1, len(ranked_codes) + 1))

    # Create DataFrame
    df = pl.DataFrame({
        "Rank": ranks,
        "Code": ranked_codes,
        "Score": ranked_scores,
        "Horizon": [f"{horizon}d"] * len(ranks),
    })

    return df


def main():
    args = parse_args()

    # Load config
    print(f"[Inference] Loading config: {args.config}")
    config = load_config(args.config)

    # Resolve device
    device = resolve_device(args.device)
    print(f"[Inference] Using device: {device}")

    # Load model
    print(f"[Inference] Loading model: {args.model}")
    model = load_model_checkpoint(args.model, config, device)
    print(f"[Inference] Model loaded successfully")

    # Prepare features
    print(f"[Inference] Preparing features from: {args.data}")
    features, stock_codes, actual_date = prepare_features(
        args.data,
        config,
        target_date=args.date,
        verbose=args.verbose,
    )

    # Generate rankings
    print(f"[Inference] Generating rankings for horizon {args.horizon}d...")
    rankings = generate_rankings(
        model,
        features,
        stock_codes,
        args.horizon,
        device,
        top_k=args.top_k,
    )

    # Add date column
    rankings = rankings.with_columns(pl.lit(actual_date).alias("Date"))
    rankings = rankings.select(["Date", "Rank", "Code", "Score", "Horizon"])

    # Output
    if args.output:
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        rankings.write_csv(args.output)
        print(f"\n[Success] Rankings saved to: {args.output}")
    else:
        print("\n" + "=" * 80)
        print(f"APEX-Ranker v0 - Top {args.top_k} Predictions ({args.horizon}d horizon)")
        print(f"Date: {actual_date}")
        print("=" * 80)
        print(rankings)

    # Summary statistics
    print(f"\n[Summary]")
    print(f"  Date: {actual_date}")
    print(f"  Total stocks: {len(stock_codes)}")
    print(f"  Top-K returned: {len(rankings)}")
    print(f"  Horizon: {args.horizon}d")
    print(f"  Score range: [{rankings['Score'].min():.4f}, {rankings['Score'].max():.4f}]")


if __name__ == "__main__":
    main()
