#!/usr/bin/env python3
"""
APEX-Ranker v0 Inference Script

Minimal inference implementation for production deployment.
Loads a trained model and generates stock rankings for a given date.

Usage:
    python scripts/inference_v0.py \\
        --model models/apex_ranker_v0_enhanced.pt \\
        --config configs/v0_base.yaml \\
        --date 2025-10-29 \\
        --output predictions_20251029.csv

Author: Generated by Claude Code
Date: 2025-10-29
"""
from __future__ import annotations

import argparse
import warnings
from datetime import datetime
from pathlib import Path

import numpy as np
import polars as pl
import torch
from _bootstrap import ensure_import_paths

ensure_import_paths()
from apex_ranker.data import (  # noqa: E402
    FeatureSelector,
    add_cross_sectional_zscores,
    build_panel_cache,
    resolve_artifact_path,
    resolve_dataset_path,
    resolve_metadata_path,
)
from apex_ranker.models import APEXRankerV0  # noqa: E402
from apex_ranker.utils import load_config  # noqa: E402

warnings.filterwarnings("ignore")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="APEX-Ranker v0 Inference - Generate stock rankings"
    )
    parser.add_argument(
        "--model",
        required=True,
        help="Path to trained model checkpoint (.pt file)",
    )
    parser.add_argument(
        "--config",
        required=True,
        help="Path to model config YAML file",
    )
    parser.add_argument(
        "--data",
        default=None,
        help="Path to input parquet dataset. When omitted the loader tries shared defaults.",
    )
    parser.add_argument(
        "--date",
        default=None,
        help="Target date for prediction (YYYY-MM-DD). If not specified, uses most recent date in dataset.",
    )
    parser.add_argument(
        "--top-k",
        type=int,
        default=50,
        help="Number of top-ranked stocks to output (default: 50)",
    )
    parser.add_argument(
        "--horizon",
        type=int,
        default=20,
        choices=[1, 5, 10, 20],
        help="Prediction horizon in days (default: 20)",
    )
    parser.add_argument(
        "--output",
        default=None,
        help="Output CSV file path. If not specified, prints to stdout.",
    )
    parser.add_argument(
        "--device",
        default="cuda",
        choices=["cuda", "cpu", "auto"],
        help="Device for inference (default: cuda)",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose logging",
    )
    return parser.parse_args()


def resolve_device(device_str: str) -> torch.device:
    """Resolve device string to torch.device."""
    if device_str == "auto":
        device_str = "cuda" if torch.cuda.is_available() else "cpu"
    return torch.device(device_str)


def load_model_checkpoint(
    model_path: str | Path,
    config: dict,
    device: torch.device,
) -> APEXRankerV0:
    """Load trained model from checkpoint."""
    config_dir = Path(config["_config_dir"])
    model_path = resolve_artifact_path(
        model_path,
        ("models/apex_ranker_v0_enhanced.pt",),
        kind="model checkpoint",
        extra_bases=[config_dir],
    )
    if not model_path.exists():
        raise FileNotFoundError(f"Model checkpoint not found: {model_path}")

    # Get feature count from config
    data_cfg = config["data"]
    groups = list(data_cfg.get("feature_groups", []))
    if data_cfg.get("use_plus30"):
        groups.append("plus30")

    config_dir = Path(config["_config_dir"])
    feature_groups_path = resolve_artifact_path(
        data_cfg.get("feature_groups_config"),
        ("models/apex_ranker/configs/feature_groups.yaml",),
        kind="feature groups config",
        extra_bases=[config_dir],
    )
    feature_selector = FeatureSelector(feature_groups_path)

    # Apply exclusions if specified
    exclude_features = data_cfg.get("exclude_features", None)

    metadata_path = None
    if data_cfg.get("metadata_path"):
        metadata_path = resolve_metadata_path(
            data_cfg["metadata_path"], extra_bases=[config_dir]
        )

    selection = feature_selector.select(
        groups=groups,
        optional_groups=data_cfg.get("optional_groups", []),
        exclude_features=exclude_features,
        metadata_path=metadata_path,
    )
    n_features = len(selection.features)

    # Initialize model
    model_cfg = config["model"]
    horizons = config["train"]["horizons"]

    model = APEXRankerV0(
        in_features=n_features,
        horizons=horizons,
        d_model=model_cfg["d_model"],
        depth=model_cfg["depth"],
        patch_len=model_cfg["patch_len"],
        stride=model_cfg["stride"],
        n_heads=model_cfg["n_heads"],
        dropout=model_cfg.get("dropout", 0.1),
    ).to(device)

    # Load state dict
    state_dict = torch.load(model_path, map_location=device)
    model.load_state_dict(state_dict)
    model.eval()

    return model


def prepare_features(
    data_path: str | Path,
    config: dict,
    target_date: str | None = None,
    verbose: bool = False,
) -> tuple[torch.Tensor, list[str], str]:
    """
    Prepare feature tensor for inference.

    Returns:
        (features_tensor, stock_codes, actual_date)
    """
    config_dir = Path(config["_config_dir"])
    if data_path is not None:
        candidate = Path(data_path)
        if candidate.exists():
            resolved_data_path = candidate
        else:
            resolved_data_path = resolve_dataset_path(
                candidate, extra_bases=[config_dir]
            )
    else:
        resolved_data_path = resolve_dataset_path(extra_bases=[config_dir])

    if verbose:
        print(f"[Inference] Using dataset: {resolved_data_path}")
    data_path = resolved_data_path

    data_cfg = config["data"]
    date_col = data_cfg["date_column"]
    code_col = data_cfg["code_column"]

    # Feature selection
    groups = list(data_cfg.get("feature_groups", []))
    if data_cfg.get("use_plus30"):
        groups.append("plus30")

    feature_groups_path = resolve_artifact_path(
        data_cfg.get("feature_groups_config"),
        ("models/apex_ranker/configs/feature_groups.yaml",),
        kind="feature groups config",
        extra_bases=[config_dir],
    )
    feature_selector = FeatureSelector(feature_groups_path)

    # Apply exclusions
    exclude_features = data_cfg.get("exclude_features", None)
    if exclude_features and verbose:
        print(f"[Inference] Excluding {len(exclude_features)} features")

    metadata_path = None
    if data_cfg.get("metadata_path"):
        metadata_path = resolve_metadata_path(
            data_cfg["metadata_path"], extra_bases=[config_dir]
        )

    selection = feature_selector.select(
        groups=groups,
        optional_groups=data_cfg.get("optional_groups", []),
        exclude_features=exclude_features,
        metadata_path=metadata_path,
    )

    # Load data
    required_columns = [date_col, code_col] + selection.features
    frame = pl.read_parquet(data_path, columns=required_columns)

    # Determine target date
    if target_date is None:
        target_date = frame[date_col].max()
        if verbose:
            print(f"[Inference] Using most recent date: {target_date}")
    else:
        target_date_parsed = datetime.strptime(target_date, "%Y-%m-%d").date()
        available_dates = frame[date_col].unique().sort()
        if target_date_parsed not in available_dates:
            closest = min(
                available_dates, key=lambda d: abs((d - target_date_parsed).days)
            )
            print(f"[Warning] Date {target_date} not found. Using closest: {closest}")
            target_date = closest
        else:
            target_date = target_date_parsed

    # Apply cross-sectional normalization
    if verbose:
        print("[Inference] Applying cross-sectional Z-score normalization...")

    frame = add_cross_sectional_zscores(
        frame,
        columns=selection.features,
        date_col=date_col,
        clip_sigma=config.get("normalization", {}).get("clip_sigma", 5.0),
    )

    z_features = [f"{col}_cs_z" for col in selection.features]

    # Build panel cache
    lookback = data_cfg["lookback"]
    if verbose:
        print(f"[Inference] Building panel cache (lookback={lookback})")

    cache = build_panel_cache(
        frame,
        feature_cols=z_features,
        target_cols=[],  # No targets needed for inference
        mask_cols=[],
        date_col=date_col,
        code_col=code_col,
        lookback=lookback,
        min_stocks_per_day=0,  # Allow any number for inference
    )

    # Extract features for target date
    target_date_int = int(np.datetime64(target_date, "D").astype("int64"))

    if target_date_int not in cache.date_to_codes:
        raise ValueError(
            f"Target date {target_date} is not available in cache. "
            f"Need {lookback} days of lookback history."
        )

    # Get stock codes for this date
    stock_codes = cache.date_to_codes[target_date_int]

    # Extract features for each stock
    features_list = []
    valid_codes = []
    for code in stock_codes:
        payload = cache.codes[code]
        dates = payload["dates"]
        idx = np.searchsorted(dates, target_date_int)
        if idx == len(dates) or dates[idx] != target_date_int:
            continue
        start = idx - lookback + 1
        if start < 0:
            continue
        window = payload["features"][start : idx + 1]  # Shape: (lookback, n_features)
        features_list.append(window)
        valid_codes.append(code)

    features_array = np.stack(
        features_list, axis=0
    )  # Shape: (N_stocks, lookback, n_features)
    stock_codes = valid_codes

    # Convert to tensor
    features_tensor = torch.from_numpy(features_array).float()

    if verbose:
        print(f"[Inference] Loaded {len(stock_codes)} stocks for date {target_date}")
        print(f"[Inference] Feature shape: {features_tensor.shape}")

    return features_tensor, stock_codes, str(target_date)


def generate_rankings(
    model: APEXRankerV0,
    features: torch.Tensor,
    stock_codes: list[str],
    horizon: int,
    device: torch.device,
    top_k: int | None = None,
) -> pl.DataFrame:
    """
    Generate stock rankings using the model.

    Returns:
        DataFrame with columns: [Code, Rank, Score, Horizon]
    """
    # Move to device
    features = features.to(device)

    # Inference
    with torch.no_grad():
        output = model(features)  # Dict[int, torch.Tensor]

    # Extract predictions for specified horizon
    if horizon not in output:
        available = list(output.keys())
        raise ValueError(
            f"Horizon {horizon}d not available. Available horizons: {available}"
        )

    predictions = output[horizon]  # Shape: (N_stocks,)
    scores = predictions.cpu().numpy()

    # Create ranking
    ranked_indices = np.argsort(scores)[::-1]  # Descending order

    if top_k is not None:
        ranked_indices = ranked_indices[:top_k]

    ranked_codes = [stock_codes[i] for i in ranked_indices]
    ranked_scores = [float(scores[i]) for i in ranked_indices]
    ranks = list(range(1, len(ranked_codes) + 1))

    # Create DataFrame
    df = pl.DataFrame(
        {
            "Rank": ranks,
            "Code": ranked_codes,
            "Score": ranked_scores,
            "Horizon": [f"{horizon}d"] * len(ranks),
        }
    )

    return df


def main():
    args = parse_args()

    # Load config
    print(f"[Inference] Loading config: {args.config}")
    config = load_config(args.config)

    # Resolve device
    device = resolve_device(args.device)
    print(f"[Inference] Using device: {device}")

    config_dir = Path(config["_config_dir"])

    # Load model
    print(f"[Inference] Loading model: {args.model}")
    model = load_model_checkpoint(args.model, config, device)
    print("[Inference] Model loaded successfully")

    # Prepare features
    dataset_path = resolve_dataset_path(args.data, extra_bases=[config_dir])
    print(f"[Inference] Preparing features from: {dataset_path}")
    features, stock_codes, actual_date = prepare_features(
        dataset_path,
        config,
        target_date=args.date,
        verbose=args.verbose,
    )

    # Generate rankings
    print(f"[Inference] Generating rankings for horizon {args.horizon}d...")
    rankings = generate_rankings(
        model,
        features,
        stock_codes,
        args.horizon,
        device,
        top_k=args.top_k,
    )

    # Add date column
    rankings = rankings.with_columns(pl.lit(actual_date).alias("Date"))
    rankings = rankings.select(["Date", "Rank", "Code", "Score", "Horizon"])

    # Output
    if args.output:
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        rankings.write_csv(args.output)
        print(f"\n[Success] Rankings saved to: {args.output}")
    else:
        print("\n" + "=" * 80)
        print(
            f"APEX-Ranker v0 - Top {args.top_k} Predictions ({args.horizon}d horizon)"
        )
        print(f"Date: {actual_date}")
        print("=" * 80)
        print(rankings)

    # Summary statistics
    print("\n[Summary]")
    print(f"  Date: {actual_date}")
    print(f"  Total stocks: {len(stock_codes)}")
    print(f"  Top-K returned: {len(rankings)}")
    print(f"  Horizon: {args.horizon}d")
    print(
        f"  Score range: [{rankings['Score'].min():.4f}, {rankings['Score'].max():.4f}]"
    )


if __name__ == "__main__":
    main()
