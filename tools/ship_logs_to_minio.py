#!/usr/bin/env python3
"""
Gogooku3 ãƒ­ã‚°ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ„ãƒ¼ãƒ«

_logs/ é…ä¸‹ã®å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’MinIOã«ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã—ã€
ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’åŠ¹ç‡çš„ã«ç®¡ç†ã™ã‚‹
"""

import argparse
import json
import os
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Dict, List, Optional
import logging
import subprocess
import tempfile

# JST timezone  
JST = timezone(timedelta(hours=9))

class LogArchiver:
    """ãƒ­ã‚°ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(
        self, 
        repo_root: Path, 
        minio_endpoint: str = "localhost:9000",
        minio_bucket: str = "gogooku",
        minio_access_key: str = "minioadmin",
        minio_secret_key: str = "minioadmin123",
        dry_run: bool = False
    ):
        self.repo_root = Path(repo_root)
        self.logs_dir = self.repo_root / "_logs"
        self.minio_endpoint = minio_endpoint
        self.minio_bucket = minio_bucket
        self.minio_access_key = minio_access_key
        self.minio_secret_key = minio_secret_key
        self.dry_run = dry_run
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'files_found': 0,
            'files_uploaded': 0,
            'files_deleted': 0,
            'bytes_uploaded': 0,
            'bytes_freed': 0,
            'errors': []
        }
        
        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def check_minio_connection(self) -> bool:
        """MinIOæ¥ç¶šç¢ºèª"""
        try:
            # mc aliasè¨­å®š
            subprocess.run([
                "mc", "alias", "set", "gogooku3-local",
                f"http://{self.minio_endpoint}",
                self.minio_access_key,
                self.minio_secret_key
            ], check=True, capture_output=True)
            
            # ãƒã‚±ãƒƒãƒˆå­˜åœ¨ç¢ºèªãƒ»ä½œæˆ
            result = subprocess.run([
                "mc", "ls", f"gogooku3-local/{self.minio_bucket}"
            ], capture_output=True)
            
            if result.returncode != 0:
                self.logger.info(f"Creating bucket: {self.minio_bucket}")
                subprocess.run([
                    "mc", "mb", f"gogooku3-local/{self.minio_bucket}"
                ], check=True)
            
            return True
            
        except subprocess.CalledProcessError as e:
            self.stats['errors'].append(f"MinIO connection failed: {e}")
            self.logger.error(f"MinIO connection failed: {e}")
            return False
        except FileNotFoundError:
            self.stats['errors'].append("mc command not found. Please install MinIO Client.")
            self.logger.error("mc command not found. Please install MinIO Client.")
            return False
    
    def find_archivable_files(self, retention_days: int = 14) -> List[Path]:
        """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢"""
        if not self.logs_dir.exists():
            return []
        
        cutoff_date = datetime.now() - timedelta(days=retention_days)
        archivable_files = []
        
        for file_path in self.logs_dir.rglob("*.jsonl.gz"):
            try:
                file_date = datetime.fromtimestamp(file_path.stat().st_mtime)
                if file_date < cutoff_date:
                    archivable_files.append(file_path)
                    self.stats['files_found'] += 1
            except OSError as e:
                self.logger.warning(f"Cannot access {file_path}: {e}")
        
        return sorted(archivable_files)
    
    def get_s3_path(self, local_path: Path) -> str:
        """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ â†’ S3ãƒ‘ã‚¹å¤‰æ›"""
        # _logs/dev/app/2025/08/29/hostname_app_file.jsonl.gz
        # â†’ logs/dev/app/2025/08/29/hostname_app_file.jsonl.gz
        
        relative_path = local_path.relative_to(self.logs_dir)
        return f"logs/{relative_path}"
    
    def upload_file(self, local_path: Path) -> bool:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        s3_path = self.get_s3_path(local_path)
        s3_url = f"gogooku3-local/{self.minio_bucket}/{s3_path}"
        
        self.logger.info(f"Uploading: {local_path} -> {s3_url}")
        
        if self.dry_run:
            self.logger.info(f"[DRY RUN] Would upload {local_path}")
            return True
        
        try:
            subprocess.run([
                "mc", "cp", str(local_path), s3_url
            ], check=True, capture_output=True)
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç¢ºèª
            result = subprocess.run([
                "mc", "stat", s3_url
            ], capture_output=True)
            
            if result.returncode == 0:
                file_size = local_path.stat().st_size
                self.stats['files_uploaded'] += 1
                self.stats['bytes_uploaded'] += file_size
                return True
            else:
                self.stats['errors'].append(f"Upload verification failed: {s3_url}")
                return False
                
        except subprocess.CalledProcessError as e:
            error_msg = f"Upload failed for {local_path}: {e}"
            self.stats['errors'].append(error_msg)
            self.logger.error(error_msg)
            return False
    
    def delete_local_file(self, local_path: Path) -> bool:
        """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤"""
        if self.dry_run:
            self.logger.info(f"[DRY RUN] Would delete {local_path}")
            return True
        
        try:
            file_size = local_path.stat().st_size
            local_path.unlink()
            
            self.stats['files_deleted'] += 1
            self.stats['bytes_freed'] += file_size
            return True
            
        except OSError as e:
            error_msg = f"Delete failed for {local_path}: {e}"
            self.stats['errors'].append(error_msg)
            self.logger.error(error_msg)
            return False
    
    def archive_files(self, retention_days: int = 14) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Ÿè¡Œ"""
        
        self.logger.info("ğŸš€ Starting log archival...")
        self.logger.info(f"Repository: {self.repo_root}")
        self.logger.info(f"MinIO endpoint: {self.minio_endpoint}")
        self.logger.info(f"Retention: {retention_days} days")
        self.logger.info(f"Dry run: {self.dry_run}")
        
        # MinIOæ¥ç¶šç¢ºèª
        if not self.check_minio_connection():
            return self.stats
        
        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        archivable_files = self.find_archivable_files(retention_days)
        self.logger.info(f"Found {len(archivable_files)} files to archive")
        
        if not archivable_files:
            self.logger.info("No files to archive")
            return self.stats
        
        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Ÿè¡Œ
        for file_path in archivable_files:
            try:
                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                if self.upload_file(file_path):
                    # ãƒ­ãƒ¼ã‚«ãƒ«å‰Šé™¤
                    self.delete_local_file(file_path)
                    
            except Exception as e:
                error_msg = f"Archival error for {file_path}: {e}"
                self.stats['errors'].append(error_msg)
                self.logger.error(error_msg)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_report()
        
        return self.stats
    
    def list_archived_files(self, days: int = 30) -> List[Dict]:
        """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º"""
        try:
            result = subprocess.run([
                "mc", "ls", "--recursive", f"gogooku3-local/{self.minio_bucket}/logs/"
            ], capture_output=True, text=True, check=True)
            
            files = []
            for line in result.stdout.strip().split('\n'):
                if line.strip():
                    # Parse mc ls output: [date] [time] [size] [path]
                    parts = line.strip().split()
                    if len(parts) >= 4:
                        date_str = parts[0]
                        time_str = parts[1]
                        size_str = parts[2] 
                        path = parts[3]
                        
                        files.append({
                            'date': date_str,
                            'time': time_str,
                            'size': size_str,
                            'path': path
                        })
            
            return files
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"Failed to list archived files: {e}")
            return []
    
    def restore_file(self, s3_path: str, local_path: Optional[Path] = None) -> bool:
        """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«å¾©æ—§"""
        if local_path is None:
            # s3_path ã‹ã‚‰ local_path ã‚’æ¨å®š
            # logs/dev/app/2025/08/29/file.jsonl.gz â†’ _logs/dev/app/2025/08/29/file.jsonl.gz
            relative_path = s3_path.replace("logs/", "", 1)
            local_path = self.logs_dir / relative_path
        
        local_path.parent.mkdir(parents=True, exist_ok=True)
        
        s3_url = f"gogooku3-local/{self.minio_bucket}/{s3_path}"
        
        self.logger.info(f"Restoring: {s3_url} -> {local_path}")
        
        if self.dry_run:
            self.logger.info(f"[DRY RUN] Would restore {s3_path}")
            return True
        
        try:
            subprocess.run([
                "mc", "cp", s3_url, str(local_path)
            ], check=True)
            
            return True
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"Restore failed: {e}")
            return False
    
    def generate_report(self):
        """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        
        report_path = self.repo_root / 'logs_archive_report.md'
        
        report_content = f"""# Gogooku3 ãƒ­ã‚°ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ¬ãƒãƒ¼ãƒˆ

**å®Ÿè¡Œæ—¥æ™‚**: {datetime.now(JST).strftime('%Y-%m-%d %H:%M:%S JST')}  
**å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰**: {'DRY RUN' if self.dry_run else 'ACTUAL ARCHIVAL'}  
**MinIO ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ**: {self.minio_endpoint}
**ãƒã‚±ãƒƒãƒˆ**: {self.minio_bucket}

## ğŸ“Š ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–çµ±è¨ˆ

- **å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {self.stats['files_found']}
- **ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿**: {self.stats['files_uploaded']}
- **å‰Šé™¤æ¸ˆã¿**: {self.stats['files_deleted']}
- **ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®¹é‡**: {self.stats['bytes_uploaded'] / 1024 / 1024:.1f} MB
- **è§£æ”¾å®¹é‡**: {self.stats['bytes_freed'] / 1024 / 1024:.1f} MB
- **ã‚¨ãƒ©ãƒ¼æ•°**: {len(self.stats['errors'])}

## ğŸ—‚ï¸ MinIOãƒ‘ã‚¹æ§‹é€ 

```
s3://{self.minio_bucket}/
â””â”€â”€ logs/
    â”œâ”€â”€ dev/
    â”‚   â”œâ”€â”€ app/YYYY/MM/DD/
    â”‚   â”œâ”€â”€ dagster/YYYY/MM/DD/
    â”‚   â””â”€â”€ ...
    â””â”€â”€ prd/
        â””â”€â”€ (åŒæ§‹é€ )
```

## ğŸ“‹ å¾©æ—§æ–¹æ³•

```bash
# ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å¾©æ—§
python tools/ship_logs_to_minio.py --restore "logs/dev/app/2025/08/29/hostname_app_file.jsonl.gz"

# ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä¸€è¦§è¡¨ç¤º
python tools/ship_logs_to_minio.py --list

# MinIO Web UIç¢ºèª
# http://localhost:9001 (minioadmin/minioadmin123)
```

## âŒ ã‚¨ãƒ©ãƒ¼ä¸€è¦§

"""

        if self.stats['errors']:
            for i, error in enumerate(self.stats['errors'], 1):
                report_content += f"{i}. {error}\n"
        else:
            report_content += "ã‚¨ãƒ©ãƒ¼ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n"

        report_content += """

## ğŸ¯ é‹ç”¨æ¨å¥¨äº‹é …

1. **å®šæœŸå®Ÿè¡Œ**: crontab ã§é€±æ¬¡å®Ÿè¡Œ (æ—¥æ›œ 3:00AM ç­‰)
2. **ç›£è¦–**: ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æˆåŠŸãƒ»å¤±æ•—ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
3. **å®¹é‡ç›£è¦–**: MinIOä½¿ç”¨å®¹é‡ãƒ»ãƒ­ãƒ¼ã‚«ãƒ«è§£æ”¾å®¹é‡ã®ç›£è¦–
4. **å¾©æ—§ãƒ†ã‚¹ãƒˆ**: æœˆæ¬¡ã§ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ã®å¾©æ—§ãƒ†ã‚¹ãƒˆ

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

- **MinIOæ¥ç¶šã‚¨ãƒ©ãƒ¼**: docker-compose ã§MinIOã‚µãƒ¼ãƒ“ã‚¹ç¢ºèª
- **mc command**: `brew install minio/stable/mc` (Mac) / `apt install minio-client` (Ubuntu)
- **æ¨©é™ã‚¨ãƒ©ãƒ¼**: MinIOã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ãƒ»ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚­ãƒ¼ç¢ºèª
- **å®¹é‡ä¸è¶³**: MinIOå´ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡ç¢ºèª

---

*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ tools/ship_logs_to_minio.py ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*
"""
        
        if not self.dry_run:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            self.logger.info(f"Report saved: {report_path}")


def main():
    parser = argparse.ArgumentParser(description="Gogooku3 ãƒ­ã‚°ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ„ãƒ¼ãƒ«")
    parser.add_argument(
        '--repo-root', 
        type=Path, 
        default=Path(__file__).parent.parent,
        help="ãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹"
    )
    parser.add_argument(
        '--minio-endpoint',
        default="localhost:9000",
        help="MinIOã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"
    )
    parser.add_argument(
        '--minio-bucket',
        default="gogooku",
        help="MinIOãƒã‚±ãƒƒãƒˆå"
    )
    parser.add_argument(
        '--retention-days',
        type=int,
        default=14,
        help="ãƒ­ãƒ¼ã‚«ãƒ«ä¿æŒæ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 14æ—¥ï¼‰"
    )
    parser.add_argument(
        '--dry-run', 
        action='store_true',
        help="å®Ÿéš›ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’ã›ãšã€å‹•ä½œäºˆå®šã‚’è¡¨ç¤º"
    )
    parser.add_argument(
        '--list',
        action='store_true',
        help="ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º"
    )
    parser.add_argument(
        '--restore',
        type=str,
        help="æŒ‡å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‹ã‚‰å¾©æ—§"
    )
    
    args = parser.parse_args()
    
    if not args.repo_root.exists():
        print(f"âŒ Repository root not found: {args.repo_root}")
        return 1
    
    archiver = LogArchiver(
        repo_root=args.repo_root,
        minio_endpoint=args.minio_endpoint,
        minio_bucket=args.minio_bucket,
        dry_run=args.dry_run
    )
    
    # ã‚³ãƒãƒ³ãƒ‰åˆ†å²
    if args.list:
        print("ğŸ“‹ Archived files:")
        files = archiver.list_archived_files()
        for f in files[:20]:  # Show first 20 files
            print(f"  {f['date']} {f['time']} {f['size']:>10} {f['path']}")
        if len(files) > 20:
            print(f"  ... and {len(files) - 20} more files")
        return 0
        
    elif args.restore:
        success = archiver.restore_file(args.restore)
        if success:
            print(f"âœ… Restored: {args.restore}")
            return 0
        else:
            print(f"âŒ Restore failed: {args.restore}")
            return 1
            
    else:
        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Ÿè¡Œ
        stats = archiver.archive_files(args.retention_days)
        
        print("\nğŸ¯ Archive Summary:")
        print(f"  Files found: {stats['files_found']}")
        print(f"  Files uploaded: {stats['files_uploaded']}")
        print(f"  Files deleted: {stats['files_deleted']}")
        print(f"  Bytes uploaded: {stats['bytes_uploaded'] / 1024 / 1024:.1f} MB")
        print(f"  Bytes freed: {stats['bytes_freed'] / 1024 / 1024:.1f} MB")
        print(f"  Errors: {len(stats['errors'])}")
        
        return 0 if len(stats['errors']) == 0 else 1


if __name__ == "__main__":
    exit(main())