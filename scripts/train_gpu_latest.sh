#!/bin/bash
# GPU Training Script for Latest Dataset
# ÊúÄÊñ∞„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅßGPUÂ≠¶Áøí„ÇíÂÆüË°å„Åô„Çã„Çπ„ÇØ„É™„Éó„Éà

set -e

# GPUÁí∞Â¢ÉË®≠ÂÆöÔºàÊ∞∏Á∂öÂåñÔºâ
export CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
export FORCE_GPU=1
export PYTORCH_CUDA_ALLOC_CONF=${PYTORCH_CUDA_ALLOC_CONF:-expandable_segments:True,max_split_size_mb:512}
export TORCH_CUDNN_V8_API_ALLOWED=1
export TORCH_CUDNN_V8_API_ENABLED=1
export TORCH_USE_RTLD_GLOBAL=YES
export OMP_NUM_THREADS=${OMP_NUM_THREADS:-16}
export NCCL_ASYNC_ERROR_HANDLING=1
export NCCL_P2P_LEVEL=${NCCL_P2P_LEVEL:-SYS}
export CUDA_DEVICE_MAX_CONNECTIONS=${CUDA_DEVICE_MAX_CONNECTIONS:-32}
export PYTHONUNBUFFERED=1
export WANDB_DISABLED=${WANDB_DISABLED:-1}
export WANDB_MODE=${WANDB_MODE:-offline}

# „Ç´„É©„ÉºÂá∫Âäõ
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m'

echo -e "${BLUE}üöÄ GPU Training with Latest Dataset${NC}"

# ÊúÄÊñ∞„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíËá™ÂãïÊ§úÂá∫
LATEST_DATASET=$(ls -t output/datasets/ml_dataset_*_full.parquet 2>/dev/null | head -1)

if [ -z "$LATEST_DATASET" ]; then
    # output/„Å´„ÇÇ„ÉÅ„Çß„ÉÉ„ÇØ
    LATEST_DATASET=$(ls -t output/ml_dataset_*_full.parquet 2>/dev/null | head -1)
fi

if [ -z "$LATEST_DATASET" ]; then
    echo -e "${YELLOW}‚ö†Ô∏è No dataset found. Please run dataset generation first:${NC}"
    echo "make dataset-full-gpu START=2020-09-19 END=2025-09-19"
    exit 1
fi

echo -e "${GREEN}‚úì Found latest dataset: $LATEST_DATASET${NC}"

# „Éá„Éï„Ç©„É´„ÉàÂºïÊï∞
RUN_SAFE_PIPELINE=${1:-""}
ADV_GRAPH=${2:-"--adv-graph-train"}
LEARNING_RATE=${3:-"2e-4"}
MAX_EPOCHS=${4:-"75"}
BATCH_SIZE=${TRAIN_BATCH_SIZE:-4096}
VAL_BATCH_SIZE=${TRAIN_VAL_BATCH_SIZE:-6144}
NUM_WORKERS=${TRAIN_NUM_WORKERS:-16}
PREFETCH=${TRAIN_PREFETCH:-8}
# Optional overrides
GRAD_ACC=${TRAIN_ACCUMULATION:-1}
PRECISION=${TRAIN_PRECISION:-16-mixed}
VAL_INTERVAL=${TRAIN_VAL_INTERVAL:-1.0}

# ÂÆüË°å„É¢„Éº„ÉâÈÅ∏Êäû
if [ "$RUN_SAFE_PIPELINE" == "--safe" ]; then
    echo -e "${BLUE}Running with SafeTrainingPipeline validation...${NC}"
    python scripts/integrated_ml_training_pipeline.py \
        --data-path "$LATEST_DATASET" \
        --run-safe-pipeline \
        $ADV_GRAPH \
        train.batch.train_batch_size=$BATCH_SIZE \
        train.batch.val_batch_size=$VAL_BATCH_SIZE \
        train.batch.test_batch_size=$VAL_BATCH_SIZE \
        train.batch.num_workers=$NUM_WORKERS \
        train.batch.prefetch_factor=$PREFETCH \
        train.trainer.accumulate_grad_batches=$GRAD_ACC \
        train.trainer.precision=$PRECISION \
        train.trainer.val_check_interval=$VAL_INTERVAL \
        train.optimizer.lr=$LEARNING_RATE \
        train.trainer.max_epochs=$MAX_EPOCHS
else
    echo -e "${BLUE}Running standard GPU training...${NC}"
    python scripts/integrated_ml_training_pipeline.py \
        --data-path "$LATEST_DATASET" \
        $ADV_GRAPH \
        train.batch.train_batch_size=$BATCH_SIZE \
        train.batch.val_batch_size=$VAL_BATCH_SIZE \
        train.batch.test_batch_size=$VAL_BATCH_SIZE \
        train.batch.num_workers=$NUM_WORKERS \
        train.batch.prefetch_factor=$PREFETCH \
        train.trainer.accumulate_grad_batches=$GRAD_ACC \
        train.trainer.precision=$PRECISION \
        train.trainer.val_check_interval=$VAL_INTERVAL \
        train.optimizer.lr=$LEARNING_RATE \
        train.trainer.max_epochs=$MAX_EPOCHS
fi

echo -e "${GREEN}‚úÖ Training completed successfully${NC}"
