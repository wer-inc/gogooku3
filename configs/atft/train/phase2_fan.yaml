# @package train
# Phase 2: FAN Integration
# Adds frequency-adaptive normalization on top of GAT

trainer:
  max_epochs: 30
  accelerator: cuda
  devices: 1
  precision: bf16-mixed
  gradient_clip_val: 1.0
  gradient_clip_algorithm: norm
  log_every_n_steps: 50
  val_check_interval: 1.0
  accumulate_grad_batches: 1

optimizer:
  name: adamw
  lr: 4e-4  # Increased for FAN learning
  betas: [0.9, 0.999]
  eps: 1e-8
  weight_decay: 1e-5

  # Per-layer learning rates
  param_groups:
    - name: fan
      lr_multiplier: 2.0  # Highest LR for new FAN layers
    - name: gat
      lr_multiplier: 0.8  # Lower for established GAT
    - name: tft
      lr_multiplier: 0.3  # Lowest for baseline TFT
    - name: head
      lr_multiplier: 1.0

scheduler:
  name: plateau
  mode: max
  monitor: val/rank_ic_5d
  patience: 10
  factor: 0.7
  min_lr: 1e-7
  threshold: 1e-4
  cooldown: 2

batch:
  batch_size: 2048
  shuffle: true
  num_workers: 4  # Increased workers
  persistent_workers: true
  prefetch_factor: 4
  pin_memory: true
  drop_last: false

# Loss configuration - more IC/RankIC emphasis
loss:
  horizons: [1, 5, 10, 20]
  horizon_weights:
    1: 1.0
    5: 0.9  # Increased focus on medium-term
    10: 0.6
    20: 0.4

  components:
    mse:
      weight: 0.2  # Further reduced

    quantile:
      weight: 0.2
      quantiles: [0.5]

    sharpe:
      weight: 0.3  # Increased
      target_sharpe: 0.849

    ic:
      weight: 0.3  # Primary component
      use_rank_ic: true
      rank_ic_weight: 0.7  # Strong RankIC emphasis

# Model config: Enable GAT + FAN
model:
  use_graph: true  # ✅ GAT continues
  gat:
    num_heads: 4
    hidden_dim: 256
    dropout: 0.1
    alpha: 0.2
    concat: true
  fan:
    enabled: true  # ✅ FAN enabled in Phase 2
    num_windows: 3  # Multi-window support (Phase 3 work)
    window_sizes: [5, 10, 20]
    use_softmax_weights: true
  san:
    enabled: false  # Not yet

# Early stopping
early_stopping:
  monitor: val/rank_ic_5d
  mode: max
  patience: 15
  min_delta: 1e-4
  verbose: true

# Validation settings
validation:
  metrics:
    - ic
    - rank_ic
    - sharpe
    - max_drawdown
    - calmar
  walk_forward:
    enabled: true
    embargo_days: 10
    n_splits: 5

# Checkpointing
callbacks:
  model_checkpoint:
    monitor: val/rank_ic_5d
    mode: max
    save_top_k: 2
    save_last: true
    filename: phase2_best

  learning_rate_monitor:
    logging_interval: step

  gpu_stats_monitor:
    memory_utilization: true
    gpu_utilization: true

# Performance optimizations
performance:
  compile:
    enabled: true
    mode: reduce-overhead
    fullgraph: false
  gradient_checkpointing: false
  mixed_precision: bf16
  dataloader:
    multiprocessing_context: spawn

debug:
  profiler: false
  detect_anomaly: false
  track_grad_norm: true
  log_gpu_memory: true
