#!/usr/bin/env python3
"""
Walk-Forward + Embargoè©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (A+ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ)
å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®å³å¯†ãªæ™‚ç³»åˆ—è©•ä¾¡
"""

import os
import sys
import argparse
import logging
from pathlib import Path
from datetime import datetime
import numpy as np
import pandas as pd
import polars as pl
import torch
from typing import Dict, List, Tuple, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.data.safety.walk_forward_v2 import WalkForwardSplitterV2
try:
    from src.metrics.financial_metrics import compute_sharpe_ratio
except ImportError:
    # Fallback implementation
    def compute_sharpe_ratio(returns: np.ndarray, risk_free_rate: float = 0.0) -> float:
        """Sharpeæ¯”ç‡ã‚’è¨ˆç®—"""
        excess_returns = returns - risk_free_rate
        return float(np.mean(excess_returns) / (np.std(excess_returns) + 1e-8))

def compute_information_coefficient(predictions: np.ndarray, targets: np.ndarray) -> float:
    """Information Coefficientã‚’è¨ˆç®—"""
    from scipy.stats import pearsonr
    
    if len(predictions) < 2:
        return 0.0
    
    corr, _ = pearsonr(predictions, targets)
    return float(corr) if not np.isnan(corr) else 0.0

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def compute_hit_rate(predictions: np.ndarray, targets: np.ndarray) -> float:
    """æ–¹å‘ä¸€è‡´ç‡ï¼ˆHit Rateï¼‰ã‚’è¨ˆç®—"""
    pred_sign = np.sign(predictions)
    target_sign = np.sign(targets)
    return float(np.mean(pred_sign == target_sign))


def compute_max_drawdown(returns: np.ndarray) -> float:
    """æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã‚’è¨ˆç®—"""
    cumulative_returns = np.cumprod(1 + returns)
    running_max = np.maximum.accumulate(cumulative_returns)
    drawdown = (cumulative_returns - running_max) / running_max
    return float(np.min(drawdown))


def compute_rank_ic(predictions: np.ndarray, targets: np.ndarray) -> float:
    """Rank Information Coefficientã‚’è¨ˆç®—"""
    from scipy.stats import spearmanr
    
    if len(predictions) < 2:
        return 0.0
    
    corr, _ = spearmanr(predictions, targets)
    return float(corr) if not np.isnan(corr) else 0.0


def load_model(model_path: str, device: str = 'cuda') -> torch.nn.Module:
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    logger.info(f"Loading model from {model_path}")
    
    # ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from src.models.architectures.atft_gat_fan import ATFT_GAT_FAN
    from omegaconf import OmegaConf

    # è¨­å®šèª­ã¿è¾¼ã¿ï¼ˆå¿…è¦æœ€å°é™ã®dataã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è£œå®Œï¼‰
    config_path = project_root / "configs" / "model" / "atft_gat_fan_v1.yaml"
    try:
        base_cfg = OmegaConf.load(config_path)
    except Exception as e:
        logger.warning(f"Failed to load model YAML ({config_path}): {e}. Using minimal fallback config.")
        base_cfg = OmegaConf.create({})
    # è£œå®Œ: data.features.input_dim ã¨ prediction_horizons
    data_stub = OmegaConf.create(
        {
            "data": {
                "features": {"input_dim": 64},
                "time_series": {"prediction_horizons": [1, 2, 3, 5, 10]},
            },
            "model": {
                "hidden_size": 64,
                "input_projection": {"use_layer_norm": True, "dropout": 0.1},
                "adaptive_normalization": {
                    "fan": {"enabled": False, "window_sizes": [5, 10, 20], "aggregation": "weighted_mean", "learn_weights": True},
                    "san": {"enabled": False, "num_slices": 1, "overlap": 0.0, "slice_aggregation": "mean"},
                },
                "tft": {
                    "variable_selection": {"dropout": 0.1, "use_sigmoid": True, "sparsity_coefficient": 0.0},
                    "attention": {"heads": 2},
                    "lstm": {"layers": 1, "dropout": 0.1},
                    "temporal": {"use_positional_encoding": True, "max_sequence_length": 20},
                },
                "gat": {"enabled": False},
                "prediction_head": {"architecture": {"hidden_layers": [], "dropout": 0.0}, "output": {"point_prediction": True, "quantile_prediction": {"enabled": False, "quantiles": [0.1, 0.5, 0.9]}}},
            },
        }
    )
    config = OmegaConf.merge(base_cfg, data_stub)

    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    model = ATFT_GAT_FAN(config)
    
    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿
    checkpoint = torch.load(model_path, map_location=device)
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model.to(device)
    model.eval()
    
    return model


def infer_batch(model: torch.nn.Module, batch_data: pl.DataFrame, device: str = 'cuda') -> np.ndarray:
    """ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æ¨è«–å®Ÿè¡Œ"""
    # ç‰¹å¾´é‡æº–å‚™ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    # æ•°å€¤åˆ—ã®ã¿ã‚’ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨ï¼ˆã‚«ãƒ†ã‚´ãƒªã‚„æ–‡å­—åˆ—ã¯é™¤å¤–ï¼‰
    numeric_types = {
        pl.Int8, pl.Int16, pl.Int32, pl.Int64,
        pl.UInt8, pl.UInt16, pl.UInt32, pl.UInt64,
        pl.Float32, pl.Float64,
    }
    candidate_cols = [c for c in batch_data.columns if c not in ['Code', 'Date', 'target', 'returns_1d']]
    feature_cols = [c for c in candidate_cols if batch_data[c].dtype in numeric_types]
    
    features = batch_data.select(feature_cols).to_numpy().astype(np.float32)
    features_tensor = torch.from_numpy(features).to(device)
    
    # ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒå°ã•ã„å ´åˆã¯ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
    min_batch_size = 20
    if features_tensor.shape[0] < min_batch_size:
        padding = torch.zeros(
            min_batch_size - features_tensor.shape[0],
            features_tensor.shape[1],
            device=device
        )
        features_tensor = torch.cat([features_tensor, padding], dim=0)
    
    # æ™‚ç³»åˆ—å½¢å¼ã«å¤‰æ›ï¼ˆç°¡æ˜“ç‰ˆï¼šå˜ä¸€æ™‚ç‚¹ã‚’è¤‡è£½ï¼‰
    seq_len = 20
    features_3d = features_tensor.unsqueeze(1).expand(-1, seq_len, -1)

    with torch.no_grad():
        # å…¥åŠ›æ¬¡å…ƒã‚’ãƒ¢ãƒ‡ãƒ«ã®æœŸå¾…æ¬¡å…ƒã«åˆã‚ã›ã‚‹ï¼ˆåˆ‡è©°ã‚/ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
        try:
            target_dim = int(getattr(model.dynamic_projection, 'in_features'))
        except Exception:
            target_dim = features_3d.shape[-1]
        cur_dim = features_3d.shape[-1]
        if cur_dim > target_dim:
            features_3d = features_3d[:, :, :target_dim]
        elif cur_dim < target_dim:
            pad = torch.zeros(features_3d.size(0), features_3d.size(1), target_dim - cur_dim, device=features_3d.device)
            features_3d = torch.cat([features_3d, pad], dim=-1)

        # GraphBuilderã«ã‚ˆã‚‹ã‚¨ãƒƒã‚¸æ§‹ç¯‰ï¼ˆæœ€å¾Œã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—è¡¨ç¾ã§KNNï¼‰
        from src.graph.graph_builder import GraphBuilder, GBConfig
        graph_builder = GraphBuilder(GBConfig())
        last_step_feats = features_3d[:, -1, :]  # (N, F)
        edge_index, edge_attr = graph_builder.build_graph(last_step_feats)
        edge_index = edge_index.to(device)
        edge_attr = edge_attr.to(device)
        
        # ãƒ¢ãƒ‡ãƒ«æ¨è«–
        predictions = model(features_3d, edge_index, edge_attr)
        
        # äºˆæ¸¬å€¤å–å¾—ï¼ˆhorizon=1ã®ã¿ï¼‰
        if isinstance(predictions, dict):
            if 'point_horizon_1' in predictions:
                pred_values = predictions['point_horizon_1'].cpu().numpy()
            else:
                # æœ€åˆã®ã‚­ãƒ¼ã‚’ä½¿ç”¨
                first_key = list(predictions.keys())[0]
                pred_values = predictions[first_key].cpu().numpy()
        else:
            pred_values = predictions.cpu().numpy()
    
    # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°éƒ¨åˆ†ã‚’é™¤å»
    actual_size = min(len(batch_data), len(pred_values))
    return pred_values[:actual_size].flatten()


def evaluate_fold(
    model: torch.nn.Module,
    train_data: pl.DataFrame,
    test_data: pl.DataFrame,
    fold: int,
    device: str = 'cuda',
    max_dates: int | None = None,
) -> Dict:
    """1ã¤ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã‚’è©•ä¾¡"""
    logger.info(f"Evaluating fold {fold}")
    logger.info(f"Train: {len(train_data)} samples, Test: {len(test_data)} samples")
    
    # æ—¥ä»˜ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦æ¨è«–
    test_dates = test_data['Date'].unique().sort()
    # åˆ¶é™ï¼ˆé«˜é€ŸåŒ–ï¼‰
    if isinstance(test_dates, pl.Series):
        test_dates = test_dates.to_list()
    if max_dates is not None and max_dates > 0:
        test_dates = test_dates[:max_dates]
    
    all_predictions = []
    all_targets = []
    
    for date in test_dates:
        date_data = test_data.filter(pl.col('Date') == date)
        
        if len(date_data) == 0:
            continue
        
        # æ¨è«–å®Ÿè¡Œ
        predictions = infer_batch(model, date_data, device)
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå–å¾—
        if 'returns_1d' in date_data.columns:
            targets = date_data['returns_1d'].to_numpy()
        else:
            targets = np.random.randn(len(predictions)) * 0.01  # ãƒ€ãƒŸãƒ¼
        
        all_predictions.extend(predictions)
        all_targets.extend(targets)
    
    # NumPyé…åˆ—ã«å¤‰æ›
    all_predictions = np.array(all_predictions)
    all_targets = np.array(all_targets)
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
    metrics = {
        'fold': fold,
        'n_samples': len(all_predictions),
        'sharpe': compute_sharpe_ratio(all_predictions),
        'hit_rate': compute_hit_rate(all_predictions, all_targets),
        'ic': compute_information_coefficient(all_predictions, all_targets),
        'rank_ic': compute_rank_ic(all_predictions, all_targets),
        'max_dd': compute_max_drawdown(all_predictions),
        'mean_return': float(np.mean(all_predictions)),
        'std_return': float(np.std(all_predictions)),
    }
    
    logger.info(f"Fold {fold} results: Sharpe={metrics['sharpe']:.3f}, "
                f"HitRate={metrics['hit_rate']:.3f}, IC={metrics['ic']:.3f}")
    
    return metrics


def main():
    parser = argparse.ArgumentParser(description="Walk-Forwardè©•ä¾¡")
    parser.add_argument("--model-path", type=str, required=True, help="ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‘ã‚¹")
    parser.add_argument("--data-path", type=str, required=True, help="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‘ã‚¹")
    parser.add_argument("--n-splits", type=int, default=3, help="WFåˆ†å‰²æ•°")
    parser.add_argument("--embargo-days", type=int, default=20, help="EmbargoæœŸé–“")
    parser.add_argument("--output-dir", type=str, default="output/wf_evaluation", help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--device", type=str, default="cuda", help="Device (cuda/cpu)")
    parser.add_argument("--max-dates", type=int, default=5, help="å„ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã§è©•ä¾¡ã™ã‚‹æœ€å¤§æ—¥æ•°ï¼ˆé«˜é€ŸåŒ–ç”¨ï¼‰")
    
    args = parser.parse_args()
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    logger.info("=" * 80)
    logger.info("Walk-Forward + Embargo Evaluation (A+ Approach)")
    logger.info("=" * 80)
    logger.info(f"Model: {args.model_path}")
    logger.info(f"Data: {args.data_path}")
    logger.info(f"N-splits: {args.n_splits}, Embargo: {args.embargo_days} days")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    logger.info("Loading dataset...")
    df = pl.read_parquet(args.data_path)
    logger.info(f"Dataset shape: {df.shape}")
    
    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    model = load_model(args.model_path, args.device)
    
    # Walk-Forwardåˆ†å‰²å™¨
    splitter = WalkForwardSplitterV2(
        n_splits=args.n_splits,
        embargo_days=args.embargo_days,
        min_train_days=252,
        min_test_days=63,
        date_column='Date',
        verbose=True
    )
    
    # å„ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã§è©•ä¾¡
    results = []
    for fold, (train_idx, test_idx) in enumerate(splitter.split(df)):
        train_data = df[train_idx]
        test_data = df[test_idx]
        
        fold_metrics = evaluate_fold(model, train_data, test_data, fold, args.device, args.max_dates)
        results.append(fold_metrics)
    
    # çµæœé›†è¨ˆ
    results_df = pd.DataFrame(results)
    
    # å¹³å‡ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
    avg_metrics = {
        'avg_sharpe': results_df['sharpe'].mean(),
        'std_sharpe': results_df['sharpe'].std(),
        'avg_hit_rate': results_df['hit_rate'].mean(),
        'avg_ic': results_df['ic'].mean(),
        'avg_rank_ic': results_df['rank_ic'].mean(),
        'avg_max_dd': results_df['max_dd'].mean(),
    }
    
    # çµæœè¡¨ç¤º
    logger.info("=" * 80)
    logger.info("Walk-Forward Evaluation Results")
    logger.info("=" * 80)
    
    for fold_result in results:
        logger.info(f"Fold {fold_result['fold']}: "
                   f"Sharpe={fold_result['sharpe']:.3f}, "
                   f"HitRate={fold_result['hit_rate']:.3f}, "
                   f"IC={fold_result['ic']:.3f}, "
                   f"RankIC={fold_result['rank_ic']:.3f}")
    
    logger.info("-" * 40)
    logger.info(f"Average Sharpe: {avg_metrics['avg_sharpe']:.3f} Â± {avg_metrics['std_sharpe']:.3f}")
    logger.info(f"Average Hit Rate: {avg_metrics['avg_hit_rate']:.3f}")
    logger.info(f"Average IC: {avg_metrics['avg_ic']:.3f}")
    logger.info(f"Average Rank IC: {avg_metrics['avg_rank_ic']:.3f}")
    logger.info(f"Average Max DD: {avg_metrics['avg_max_dd']:.3f}")
    
    # çµæœä¿å­˜
    output_file = output_dir / f"wf_evaluation_{timestamp}.csv"
    results_df.to_csv(output_file, index=False)
    logger.info(f"\nâœ… Results saved to {output_file}")
    
    # ã‚µãƒãƒªãƒ¼ä¿å­˜
    summary_file = output_dir / f"wf_summary_{timestamp}.json"
    import json
    with open(summary_file, 'w') as f:
        json.dump({
            'config': vars(args),
            'avg_metrics': avg_metrics,
            'fold_results': results,
            'timestamp': timestamp
        }, f, indent=2)
    
    logger.info(f"âœ… Summary saved to {summary_file}")
    
    # æˆåŠŸåˆ¤å®š
    if avg_metrics['avg_sharpe'] > 0.5:
        logger.info("\nğŸ‰ Evaluation passed! Sharpe > 0.5")
    else:
        logger.warning(f"\nâš ï¸ Sharpe = {avg_metrics['avg_sharpe']:.3f} < 0.5, needs improvement")
    
    return avg_metrics


if __name__ == "__main__":
    main()
